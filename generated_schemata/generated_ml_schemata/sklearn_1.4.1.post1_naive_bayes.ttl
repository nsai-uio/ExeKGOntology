@prefix ds: <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#> .
@prefix ml: <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#> .
@prefix owl: <http://www.w3.org/2002/07/owl#> .
@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .
@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .

ml:hasBinaryClassificationMethod a owl:ObjectProperty ;
    rdfs:domain ml:BinaryClassification ;
    rdfs:range ml:BernoulliNBMethod,
        ml:CategoricalNBMethod,
        ml:ComplementNBMethod,
        ml:GaussianNBMethod,
        ml:MultinomialNBMethod ;
    rdfs:subPropertyOf ml:hasTrainMethod .

ml:hasMulticlassClassificationMethod a owl:ObjectProperty ;
    rdfs:domain ml:MulticlassClassification ;
    rdfs:range ml:BernoulliNBMethod,
        ml:GaussianNBMethod,
        ml:MultinomialNBMethod ;
    rdfs:subPropertyOf ml:hasTrainMethod .

ml:hasParamAlpha a owl:DatatypeProperty ;
    rdfs:domain ml:BernoulliNBMethod,
        ml:CategoricalNBMethod,
        ml:ComplementNBMethod,
        ml:MultinomialNBMethod ;
    rdfs:range xsd:float,
        xsd:int ;
    rdfs:subPropertyOf ds:hasParameter .

ml:hasParamBinarize a owl:DatatypeProperty ;
    rdfs:domain ml:BernoulliNBMethod ;
    rdfs:range xsd:float,
        xsd:int,
        xsd:string ;
    rdfs:subPropertyOf ds:hasParameter .

ml:hasParamFitPrior a owl:DatatypeProperty ;
    rdfs:domain ml:BernoulliNBMethod,
        ml:CategoricalNBMethod,
        ml:ComplementNBMethod,
        ml:MultinomialNBMethod ;
    rdfs:range xsd:boolean ;
    rdfs:subPropertyOf ds:hasParameter .

ml:hasParamForceAlpha a owl:DatatypeProperty ;
    rdfs:domain ml:BernoulliNBMethod,
        ml:CategoricalNBMethod,
        ml:ComplementNBMethod,
        ml:MultinomialNBMethod ;
    rdfs:range xsd:boolean ;
    rdfs:subPropertyOf ds:hasParameter .

ml:hasParamMinCategories a owl:DatatypeProperty ;
    rdfs:domain ml:CategoricalNBMethod ;
    rdfs:range xsd:int ;
    rdfs:subPropertyOf ds:hasParameter .

ml:hasParamNorm a owl:DatatypeProperty ;
    rdfs:domain ml:ComplementNBMethod ;
    rdfs:range xsd:boolean ;
    rdfs:subPropertyOf ds:hasParameter .

ml:hasParamVarSmoothing a owl:DatatypeProperty ;
    rdfs:domain ml:GaussianNBMethod ;
    rdfs:range xsd:float,
        xsd:int ;
    rdfs:subPropertyOf ds:hasParameter .

ml:SklearnModule a owl:Class ;
    rdfs:subClassOf ds:Module .

ml:GaussianNBMethod a owl:Class ;
    rdfs:comment """Gaussian Naive Bayes (GaussianNB).

Can perform online updates to model parameters via :meth:`partial_fit`.
For details on algorithm used to update feature means and variance online,
see Stanford CS tech report STAN-CS-79-773 by Chan, Golub, and LeVeque:

    http://i.stanford.edu/pub/cstr/reports/cs/tr/79/773/CS-TR-79-773.pdf

Read more in the :ref:`User Guide <gaussian_naive_bayes>`.

Parameters
----------
priors : array-like of shape (n_classes,), default=None
    Prior probabilities of the classes. If specified, the priors are not
    adjusted according to the data.

var_smoothing : float, default=1e-9
    Portion of the largest variance of all features that is added to
    variances for calculation stability.

    .. versionadded:: 0.20

Attributes
----------
class_count_ : ndarray of shape (n_classes,)
    number of training samples observed in each class.

class_prior_ : ndarray of shape (n_classes,)
    probability of each class.

classes_ : ndarray of shape (n_classes,)
    class labels known to the classifier.

epsilon_ : float
    absolute additive value to variances.

n_features_in_ : int
    Number of features seen during :term:`fit`.

    .. versionadded:: 0.24

feature_names_in_ : ndarray of shape (`n_features_in_`,)
    Names of features seen during :term:`fit`. Defined only when `X`
    has feature names that are all strings.

    .. versionadded:: 1.0

var_ : ndarray of shape (n_classes, n_features)
    Variance of each feature per class.

    .. versionadded:: 1.0

theta_ : ndarray of shape (n_classes, n_features)
    mean of each feature per class.

See Also
--------
BernoulliNB : Naive Bayes classifier for multivariate Bernoulli models.
CategoricalNB : Naive Bayes classifier for categorical features.
ComplementNB : Complement Naive Bayes classifier.
MultinomialNB : Naive Bayes classifier for multinomial models.

Examples
--------
>>> import numpy as np
>>> X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])
>>> Y = np.array([1, 1, 1, 2, 2, 2])
>>> from sklearn.naive_bayes import GaussianNB
>>> clf = GaussianNB()
>>> clf.fit(X, Y)
GaussianNB()
>>> print(clf.predict([[-0.8, -1]]))
[1]
>>> clf_pf = GaussianNB()
>>> clf_pf.partial_fit(X, Y, np.unique(Y))
GaussianNB()
>>> print(clf_pf.predict([[-0.8, -1]]))
[1]""" ;
    rdfs:subClassOf ds:AtomicMethod,
        ml:NaiveBayesModule,
        ml:TrainMethod .

ml:CategoricalNBMethod a owl:Class ;
    rdfs:comment """Naive Bayes classifier for categorical features.

The categorical Naive Bayes classifier is suitable for classification with
discrete features that are categorically distributed. The categories of
each feature are drawn from a categorical distribution.

Read more in the :ref:`User Guide <categorical_naive_bayes>`.

Parameters
----------
alpha : float, default=1.0
    Additive (Laplace/Lidstone) smoothing parameter
    (set alpha=0 and force_alpha=True, for no smoothing).

force_alpha : bool, default=True
    If False and alpha is less than 1e-10, it will set alpha to
    1e-10. If True, alpha will remain unchanged. This may cause
    numerical errors if alpha is too close to 0.

    .. versionadded:: 1.2
    .. versionchanged:: 1.4
       The default value of `force_alpha` changed to `True`.

fit_prior : bool, default=True
    Whether to learn class prior probabilities or not.
    If false, a uniform prior will be used.

class_prior : array-like of shape (n_classes,), default=None
    Prior probabilities of the classes. If specified, the priors are not
    adjusted according to the data.

min_categories : int or array-like of shape (n_features,), default=None
    Minimum number of categories per feature.

    - integer: Sets the minimum number of categories per feature to
      `n_categories` for each features.
    - array-like: shape (n_features,) where `n_categories[i]` holds the
      minimum number of categories for the ith column of the input.
    - None (default): Determines the number of categories automatically
      from the training data.

    .. versionadded:: 0.24

Attributes
----------
category_count_ : list of arrays of shape (n_features,)
    Holds arrays of shape (n_classes, n_categories of respective feature)
    for each feature. Each array provides the number of samples
    encountered for each class and category of the specific feature.

class_count_ : ndarray of shape (n_classes,)
    Number of samples encountered for each class during fitting. This
    value is weighted by the sample weight when provided.

class_log_prior_ : ndarray of shape (n_classes,)
    Smoothed empirical log probability for each class.

classes_ : ndarray of shape (n_classes,)
    Class labels known to the classifier

feature_log_prob_ : list of arrays of shape (n_features,)
    Holds arrays of shape (n_classes, n_categories of respective feature)
    for each feature. Each array provides the empirical log probability
    of categories given the respective feature and class, ``P(x_i|y)``.

n_features_in_ : int
    Number of features seen during :term:`fit`.

    .. versionadded:: 0.24

feature_names_in_ : ndarray of shape (`n_features_in_`,)
    Names of features seen during :term:`fit`. Defined only when `X`
    has feature names that are all strings.

    .. versionadded:: 1.0

n_categories_ : ndarray of shape (n_features,), dtype=np.int64
    Number of categories for each feature. This value is
    inferred from the data or set by the minimum number of categories.

    .. versionadded:: 0.24

See Also
--------
BernoulliNB : Naive Bayes classifier for multivariate Bernoulli models.
ComplementNB : Complement Naive Bayes classifier.
GaussianNB : Gaussian Naive Bayes.
MultinomialNB : Naive Bayes classifier for multinomial models.

Examples
--------
>>> import numpy as np
>>> rng = np.random.RandomState(1)
>>> X = rng.randint(5, size=(6, 100))
>>> y = np.array([1, 2, 3, 4, 5, 6])
>>> from sklearn.naive_bayes import CategoricalNB
>>> clf = CategoricalNB()
>>> clf.fit(X, y)
CategoricalNB()
>>> print(clf.predict(X[2:3]))
[3]""" ;
    rdfs:subClassOf ds:AtomicMethod,
        ml:NaiveBayesModule,
        ml:TrainMethod .

ml:ComplementNBMethod a owl:Class ;
    rdfs:comment """The Complement Naive Bayes classifier described in Rennie et al. (2003).

The Complement Naive Bayes classifier was designed to correct the "severe
assumptions" made by the standard Multinomial Naive Bayes classifier. It is
particularly suited for imbalanced data sets.

Read more in the :ref:`User Guide <complement_naive_bayes>`.

.. versionadded:: 0.20

Parameters
----------
alpha : float or array-like of shape (n_features,), default=1.0
    Additive (Laplace/Lidstone) smoothing parameter
    (set alpha=0 and force_alpha=True, for no smoothing).

force_alpha : bool, default=True
    If False and alpha is less than 1e-10, it will set alpha to
    1e-10. If True, alpha will remain unchanged. This may cause
    numerical errors if alpha is too close to 0.

    .. versionadded:: 1.2
    .. versionchanged:: 1.4
       The default value of `force_alpha` changed to `True`.

fit_prior : bool, default=True
    Only used in edge case with a single class in the training set.

class_prior : array-like of shape (n_classes,), default=None
    Prior probabilities of the classes. Not used.

norm : bool, default=False
    Whether or not a second normalization of the weights is performed. The
    default behavior mirrors the implementations found in Mahout and Weka,
    which do not follow the full algorithm described in Table 9 of the
    paper.

Attributes
----------
class_count_ : ndarray of shape (n_classes,)
    Number of samples encountered for each class during fitting. This
    value is weighted by the sample weight when provided.

class_log_prior_ : ndarray of shape (n_classes,)
    Smoothed empirical log probability for each class. Only used in edge
    case with a single class in the training set.

classes_ : ndarray of shape (n_classes,)
    Class labels known to the classifier

feature_all_ : ndarray of shape (n_features,)
    Number of samples encountered for each feature during fitting. This
    value is weighted by the sample weight when provided.

feature_count_ : ndarray of shape (n_classes, n_features)
    Number of samples encountered for each (class, feature) during fitting.
    This value is weighted by the sample weight when provided.

feature_log_prob_ : ndarray of shape (n_classes, n_features)
    Empirical weights for class complements.

n_features_in_ : int
    Number of features seen during :term:`fit`.

    .. versionadded:: 0.24

feature_names_in_ : ndarray of shape (`n_features_in_`,)
    Names of features seen during :term:`fit`. Defined only when `X`
    has feature names that are all strings.

    .. versionadded:: 1.0

See Also
--------
BernoulliNB : Naive Bayes classifier for multivariate Bernoulli models.
CategoricalNB : Naive Bayes classifier for categorical features.
GaussianNB : Gaussian Naive Bayes.
MultinomialNB : Naive Bayes classifier for multinomial models.

References
----------
Rennie, J. D., Shih, L., Teevan, J., & Karger, D. R. (2003).
Tackling the poor assumptions of naive bayes text classifiers. In ICML
(Vol. 3, pp. 616-623).
https://people.csail.mit.edu/jrennie/papers/icml03-nb.pdf

Examples
--------
>>> import numpy as np
>>> rng = np.random.RandomState(1)
>>> X = rng.randint(5, size=(6, 100))
>>> y = np.array([1, 2, 3, 4, 5, 6])
>>> from sklearn.naive_bayes import ComplementNB
>>> clf = ComplementNB()
>>> clf.fit(X, y)
ComplementNB()
>>> print(clf.predict(X[2:3]))
[3]""" ;
    rdfs:subClassOf ds:AtomicMethod,
        ml:NaiveBayesModule,
        ml:TrainMethod .

ml:MultinomialNBMethod a owl:Class ;
    rdfs:comment """Naive Bayes classifier for multinomial models.

The multinomial Naive Bayes classifier is suitable for classification with
discrete features (e.g., word counts for text classification). The
multinomial distribution normally requires integer feature counts. However,
in practice, fractional counts such as tf-idf may also work.

Read more in the :ref:`User Guide <multinomial_naive_bayes>`.

Parameters
----------
alpha : float or array-like of shape (n_features,), default=1.0
    Additive (Laplace/Lidstone) smoothing parameter
    (set alpha=0 and force_alpha=True, for no smoothing).

force_alpha : bool, default=True
    If False and alpha is less than 1e-10, it will set alpha to
    1e-10. If True, alpha will remain unchanged. This may cause
    numerical errors if alpha is too close to 0.

    .. versionadded:: 1.2
    .. versionchanged:: 1.4
       The default value of `force_alpha` changed to `True`.

fit_prior : bool, default=True
    Whether to learn class prior probabilities or not.
    If false, a uniform prior will be used.

class_prior : array-like of shape (n_classes,), default=None
    Prior probabilities of the classes. If specified, the priors are not
    adjusted according to the data.

Attributes
----------
class_count_ : ndarray of shape (n_classes,)
    Number of samples encountered for each class during fitting. This
    value is weighted by the sample weight when provided.

class_log_prior_ : ndarray of shape (n_classes,)
    Smoothed empirical log probability for each class.

classes_ : ndarray of shape (n_classes,)
    Class labels known to the classifier

feature_count_ : ndarray of shape (n_classes, n_features)
    Number of samples encountered for each (class, feature)
    during fitting. This value is weighted by the sample weight when
    provided.

feature_log_prob_ : ndarray of shape (n_classes, n_features)
    Empirical log probability of features
    given a class, ``P(x_i|y)``.

n_features_in_ : int
    Number of features seen during :term:`fit`.

    .. versionadded:: 0.24

feature_names_in_ : ndarray of shape (`n_features_in_`,)
    Names of features seen during :term:`fit`. Defined only when `X`
    has feature names that are all strings.

    .. versionadded:: 1.0

See Also
--------
BernoulliNB : Naive Bayes classifier for multivariate Bernoulli models.
CategoricalNB : Naive Bayes classifier for categorical features.
ComplementNB : Complement Naive Bayes classifier.
GaussianNB : Gaussian Naive Bayes.

References
----------
C.D. Manning, P. Raghavan and H. Schuetze (2008). Introduction to
Information Retrieval. Cambridge University Press, pp. 234-265.
https://nlp.stanford.edu/IR-book/html/htmledition/naive-bayes-text-classification-1.html

Examples
--------
>>> import numpy as np
>>> rng = np.random.RandomState(1)
>>> X = rng.randint(5, size=(6, 100))
>>> y = np.array([1, 2, 3, 4, 5, 6])
>>> from sklearn.naive_bayes import MultinomialNB
>>> clf = MultinomialNB()
>>> clf.fit(X, y)
MultinomialNB()
>>> print(clf.predict(X[2:3]))
[3]""" ;
    rdfs:subClassOf ds:AtomicMethod,
        ml:NaiveBayesModule,
        ml:TrainMethod .

ml:NaiveBayesModule a owl:Class ;
    rdfs:subClassOf ml:SklearnModule .

ml:BernoulliNBMethod a owl:Class ;
    rdfs:comment """Naive Bayes classifier for multivariate Bernoulli models.

Like MultinomialNB, this classifier is suitable for discrete data. The
difference is that while MultinomialNB works with occurrence counts,
BernoulliNB is designed for binary/boolean features.

Read more in the :ref:`User Guide <bernoulli_naive_bayes>`.

Parameters
----------
alpha : float or array-like of shape (n_features,), default=1.0
    Additive (Laplace/Lidstone) smoothing parameter
    (set alpha=0 and force_alpha=True, for no smoothing).

force_alpha : bool, default=True
    If False and alpha is less than 1e-10, it will set alpha to
    1e-10. If True, alpha will remain unchanged. This may cause
    numerical errors if alpha is too close to 0.

    .. versionadded:: 1.2
    .. versionchanged:: 1.4
       The default value of `force_alpha` changed to `True`.

binarize : float or None, default=0.0
    Threshold for binarizing (mapping to booleans) of sample features.
    If None, input is presumed to already consist of binary vectors.

fit_prior : bool, default=True
    Whether to learn class prior probabilities or not.
    If false, a uniform prior will be used.

class_prior : array-like of shape (n_classes,), default=None
    Prior probabilities of the classes. If specified, the priors are not
    adjusted according to the data.

Attributes
----------
class_count_ : ndarray of shape (n_classes,)
    Number of samples encountered for each class during fitting. This
    value is weighted by the sample weight when provided.

class_log_prior_ : ndarray of shape (n_classes,)
    Log probability of each class (smoothed).

classes_ : ndarray of shape (n_classes,)
    Class labels known to the classifier

feature_count_ : ndarray of shape (n_classes, n_features)
    Number of samples encountered for each (class, feature)
    during fitting. This value is weighted by the sample weight when
    provided.

feature_log_prob_ : ndarray of shape (n_classes, n_features)
    Empirical log probability of features given a class, P(x_i|y).

n_features_in_ : int
    Number of features seen during :term:`fit`.

    .. versionadded:: 0.24

feature_names_in_ : ndarray of shape (`n_features_in_`,)
    Names of features seen during :term:`fit`. Defined only when `X`
    has feature names that are all strings.

    .. versionadded:: 1.0

See Also
--------
CategoricalNB : Naive Bayes classifier for categorical features.
ComplementNB : The Complement Naive Bayes classifier
    described in Rennie et al. (2003).
GaussianNB : Gaussian Naive Bayes (GaussianNB).
MultinomialNB : Naive Bayes classifier for multinomial models.

References
----------
C.D. Manning, P. Raghavan and H. Schuetze (2008). Introduction to
Information Retrieval. Cambridge University Press, pp. 234-265.
https://nlp.stanford.edu/IR-book/html/htmledition/the-bernoulli-model-1.html

A. McCallum and K. Nigam (1998). A comparison of event models for naive
Bayes text classification. Proc. AAAI/ICML-98 Workshop on Learning for
Text Categorization, pp. 41-48.

V. Metsis, I. Androutsopoulos and G. Paliouras (2006). Spam filtering with
naive Bayes -- Which naive Bayes? 3rd Conf. on Email and Anti-Spam (CEAS).

Examples
--------
>>> import numpy as np
>>> rng = np.random.RandomState(1)
>>> X = rng.randint(5, size=(6, 100))
>>> Y = np.array([1, 2, 3, 4, 4, 5])
>>> from sklearn.naive_bayes import BernoulliNB
>>> clf = BernoulliNB()
>>> clf.fit(X, Y)
BernoulliNB()
>>> print(clf.predict(X[2:3]))
[3]""" ;
    rdfs:subClassOf ds:AtomicMethod,
        ml:NaiveBayesModule,
        ml:TrainMethod .

