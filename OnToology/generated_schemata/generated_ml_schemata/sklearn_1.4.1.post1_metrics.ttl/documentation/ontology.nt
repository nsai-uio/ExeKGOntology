_:genid1 <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Ontology> .
# 
# 
# #################################################################
# #
# #    Object Properties
# #
# #################################################################
# 
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPerformanceCalculationMethod
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPerformanceCalculationMethod> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#ObjectProperty> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPerformanceCalculationMethod> <http://www.w3.org/2000/01/rdf-schema#subPropertyOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPerformanceCalculationMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPerformanceCalculationMethod> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PerformanceCalculation> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PerformanceCalculation> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Class> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPerformanceCalculationMethod> <http://www.w3.org/2000/01/rdf-schema#range> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#AccuracyScoreMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPerformanceCalculationMethod> <http://www.w3.org/2000/01/rdf-schema#range> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#AdjustedMutualInfoScoreMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPerformanceCalculationMethod> <http://www.w3.org/2000/01/rdf-schema#range> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#AdjustedRandScoreMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPerformanceCalculationMethod> <http://www.w3.org/2000/01/rdf-schema#range> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#AucMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPerformanceCalculationMethod> <http://www.w3.org/2000/01/rdf-schema#range> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#AveragePrecisionScoreMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPerformanceCalculationMethod> <http://www.w3.org/2000/01/rdf-schema#range> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#BalancedAccuracyScoreMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPerformanceCalculationMethod> <http://www.w3.org/2000/01/rdf-schema#range> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#BrierScoreLossMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPerformanceCalculationMethod> <http://www.w3.org/2000/01/rdf-schema#range> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#CalinskiHarabaszScoreMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPerformanceCalculationMethod> <http://www.w3.org/2000/01/rdf-schema#range> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#CheckScoringMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPerformanceCalculationMethod> <http://www.w3.org/2000/01/rdf-schema#range> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#ClassLikelihoodRatiosMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPerformanceCalculationMethod> <http://www.w3.org/2000/01/rdf-schema#range> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#ClassificationReportMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPerformanceCalculationMethod> <http://www.w3.org/2000/01/rdf-schema#range> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#CohenKappaScoreMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPerformanceCalculationMethod> <http://www.w3.org/2000/01/rdf-schema#range> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#CompletenessScoreMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPerformanceCalculationMethod> <http://www.w3.org/2000/01/rdf-schema#range> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#ConfusionMatrixMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPerformanceCalculationMethod> <http://www.w3.org/2000/01/rdf-schema#range> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#ConsensusScoreMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPerformanceCalculationMethod> <http://www.w3.org/2000/01/rdf-schema#range> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#CoverageErrorMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPerformanceCalculationMethod> <http://www.w3.org/2000/01/rdf-schema#range> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#D2AbsoluteErrorScoreMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPerformanceCalculationMethod> <http://www.w3.org/2000/01/rdf-schema#range> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#D2PinballScoreMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPerformanceCalculationMethod> <http://www.w3.org/2000/01/rdf-schema#range> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#D2TweedieScoreMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPerformanceCalculationMethod> <http://www.w3.org/2000/01/rdf-schema#range> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#DaviesBouldinScoreMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPerformanceCalculationMethod> <http://www.w3.org/2000/01/rdf-schema#range> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#DcgScoreMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPerformanceCalculationMethod> <http://www.w3.org/2000/01/rdf-schema#range> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#DetCurveMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPerformanceCalculationMethod> <http://www.w3.org/2000/01/rdf-schema#range> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#EuclideanDistancesMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPerformanceCalculationMethod> <http://www.w3.org/2000/01/rdf-schema#range> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#ExplainedVarianceScoreMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPerformanceCalculationMethod> <http://www.w3.org/2000/01/rdf-schema#range> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#F1ScoreMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPerformanceCalculationMethod> <http://www.w3.org/2000/01/rdf-schema#range> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#FbetaScoreMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPerformanceCalculationMethod> <http://www.w3.org/2000/01/rdf-schema#range> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#FowlkesMallowsScoreMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPerformanceCalculationMethod> <http://www.w3.org/2000/01/rdf-schema#range> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#GetScorerMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPerformanceCalculationMethod> <http://www.w3.org/2000/01/rdf-schema#range> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#GetScorerNamesMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPerformanceCalculationMethod> <http://www.w3.org/2000/01/rdf-schema#range> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#HammingLossMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPerformanceCalculationMethod> <http://www.w3.org/2000/01/rdf-schema#range> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#HingeLossMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPerformanceCalculationMethod> <http://www.w3.org/2000/01/rdf-schema#range> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#HomogeneityCompletenessVMeasureMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPerformanceCalculationMethod> <http://www.w3.org/2000/01/rdf-schema#range> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#HomogeneityScoreMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPerformanceCalculationMethod> <http://www.w3.org/2000/01/rdf-schema#range> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#JaccardScoreMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPerformanceCalculationMethod> <http://www.w3.org/2000/01/rdf-schema#range> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#LabelRankingAveragePrecisionScoreMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPerformanceCalculationMethod> <http://www.w3.org/2000/01/rdf-schema#range> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#LabelRankingLossMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPerformanceCalculationMethod> <http://www.w3.org/2000/01/rdf-schema#range> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#LogLossMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPerformanceCalculationMethod> <http://www.w3.org/2000/01/rdf-schema#range> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MakeScorerMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPerformanceCalculationMethod> <http://www.w3.org/2000/01/rdf-schema#range> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MatthewsCorrcoefMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPerformanceCalculationMethod> <http://www.w3.org/2000/01/rdf-schema#range> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MaxErrorMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPerformanceCalculationMethod> <http://www.w3.org/2000/01/rdf-schema#range> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MeanAbsoluteErrorMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPerformanceCalculationMethod> <http://www.w3.org/2000/01/rdf-schema#range> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MeanAbsolutePercentageErrorMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPerformanceCalculationMethod> <http://www.w3.org/2000/01/rdf-schema#range> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MeanGammaDevianceMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPerformanceCalculationMethod> <http://www.w3.org/2000/01/rdf-schema#range> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MeanPinballLossMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPerformanceCalculationMethod> <http://www.w3.org/2000/01/rdf-schema#range> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MeanPoissonDevianceMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPerformanceCalculationMethod> <http://www.w3.org/2000/01/rdf-schema#range> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MeanSquaredErrorMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPerformanceCalculationMethod> <http://www.w3.org/2000/01/rdf-schema#range> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MeanSquaredLogErrorMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPerformanceCalculationMethod> <http://www.w3.org/2000/01/rdf-schema#range> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MeanTweedieDevianceMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPerformanceCalculationMethod> <http://www.w3.org/2000/01/rdf-schema#range> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MedianAbsoluteErrorMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPerformanceCalculationMethod> <http://www.w3.org/2000/01/rdf-schema#range> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MultilabelConfusionMatrixMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPerformanceCalculationMethod> <http://www.w3.org/2000/01/rdf-schema#range> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MutualInfoScoreMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPerformanceCalculationMethod> <http://www.w3.org/2000/01/rdf-schema#range> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#NanEuclideanDistancesMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPerformanceCalculationMethod> <http://www.w3.org/2000/01/rdf-schema#range> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#NdcgScoreMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPerformanceCalculationMethod> <http://www.w3.org/2000/01/rdf-schema#range> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#NormalizedMutualInfoScoreMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPerformanceCalculationMethod> <http://www.w3.org/2000/01/rdf-schema#range> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PairConfusionMatrixMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPerformanceCalculationMethod> <http://www.w3.org/2000/01/rdf-schema#range> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PairwiseDistancesArgminMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPerformanceCalculationMethod> <http://www.w3.org/2000/01/rdf-schema#range> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PairwiseDistancesArgminMinMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPerformanceCalculationMethod> <http://www.w3.org/2000/01/rdf-schema#range> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PairwiseDistancesChunkedMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPerformanceCalculationMethod> <http://www.w3.org/2000/01/rdf-schema#range> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PairwiseDistancesMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPerformanceCalculationMethod> <http://www.w3.org/2000/01/rdf-schema#range> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PairwiseKernelsMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPerformanceCalculationMethod> <http://www.w3.org/2000/01/rdf-schema#range> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PrecisionRecallCurveMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPerformanceCalculationMethod> <http://www.w3.org/2000/01/rdf-schema#range> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PrecisionRecallFscoreSupportMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPerformanceCalculationMethod> <http://www.w3.org/2000/01/rdf-schema#range> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PrecisionScoreMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPerformanceCalculationMethod> <http://www.w3.org/2000/01/rdf-schema#range> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#R2ScoreMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPerformanceCalculationMethod> <http://www.w3.org/2000/01/rdf-schema#range> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RandScoreMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPerformanceCalculationMethod> <http://www.w3.org/2000/01/rdf-schema#range> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RecallScoreMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPerformanceCalculationMethod> <http://www.w3.org/2000/01/rdf-schema#range> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RocAucScoreMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPerformanceCalculationMethod> <http://www.w3.org/2000/01/rdf-schema#range> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RocCurveMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPerformanceCalculationMethod> <http://www.w3.org/2000/01/rdf-schema#range> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RootMeanSquaredErrorMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPerformanceCalculationMethod> <http://www.w3.org/2000/01/rdf-schema#range> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RootMeanSquaredLogErrorMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPerformanceCalculationMethod> <http://www.w3.org/2000/01/rdf-schema#range> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#SilhouetteSamplesMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPerformanceCalculationMethod> <http://www.w3.org/2000/01/rdf-schema#range> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#SilhouetteScoreMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPerformanceCalculationMethod> <http://www.w3.org/2000/01/rdf-schema#range> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#TopKAccuracyScoreMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPerformanceCalculationMethod> <http://www.w3.org/2000/01/rdf-schema#range> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#VMeasureScoreMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPerformanceCalculationMethod> <http://www.w3.org/2000/01/rdf-schema#range> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#ZeroOneLossMethod> .
# 
# 
# 
# #################################################################
# #
# #    Data properties
# #
# #################################################################
# 
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#DatatypeProperty> .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamA
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamA> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#DatatypeProperty> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamA> <http://www.w3.org/2000/01/rdf-schema#subPropertyOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamA> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#ConsensusScoreMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamA> <http://www.w3.org/2000/01/rdf-schema#range> <http://www.w3.org/2001/XMLSchema#string> .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamAdjusted
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamAdjusted> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#DatatypeProperty> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamAdjusted> <http://www.w3.org/2000/01/rdf-schema#subPropertyOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamAdjusted> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#BalancedAccuracyScoreMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamAdjusted> <http://www.w3.org/2000/01/rdf-schema#range> <http://www.w3.org/2001/XMLSchema#boolean> .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamAllowNone
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamAllowNone> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#DatatypeProperty> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamAllowNone> <http://www.w3.org/2000/01/rdf-schema#subPropertyOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamAllowNone> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#CheckScoringMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamAllowNone> <http://www.w3.org/2000/01/rdf-schema#range> <http://www.w3.org/2001/XMLSchema#boolean> .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamAlpha
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamAlpha> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#DatatypeProperty> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamAlpha> <http://www.w3.org/2000/01/rdf-schema#subPropertyOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamAlpha> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#D2PinballScoreMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamAlpha> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MeanPinballLossMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamAlpha> <http://www.w3.org/2000/01/rdf-schema#range> <http://www.w3.org/2001/XMLSchema#float> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamAlpha> <http://www.w3.org/2000/01/rdf-schema#range> <http://www.w3.org/2001/XMLSchema#int> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamAlpha> <http://www.w3.org/2000/01/rdf-schema#range> <http://www.w3.org/2001/XMLSchema#string> .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamAverage
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamAverage> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#DatatypeProperty> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamAverage> <http://www.w3.org/2000/01/rdf-schema#subPropertyOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamAverage> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#AveragePrecisionScoreMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamAverage> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#F1ScoreMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamAverage> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#FbetaScoreMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamAverage> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#JaccardScoreMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamAverage> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PrecisionRecallFscoreSupportMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamAverage> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PrecisionScoreMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamAverage> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RecallScoreMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamAverage> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RocAucScoreMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamAverage> <http://www.w3.org/2000/01/rdf-schema#range> <http://www.w3.org/2001/XMLSchema#string> .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamAverageMethod
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamAverageMethod> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#DatatypeProperty> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamAverageMethod> <http://www.w3.org/2000/01/rdf-schema#subPropertyOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamAverageMethod> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#AdjustedMutualInfoScoreMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamAverageMethod> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#NormalizedMutualInfoScoreMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamAverageMethod> <http://www.w3.org/2000/01/rdf-schema#range> <http://www.w3.org/2001/XMLSchema#string> .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamAxis
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamAxis> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#DatatypeProperty> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamAxis> <http://www.w3.org/2000/01/rdf-schema#subPropertyOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamAxis> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PairwiseDistancesArgminMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamAxis> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PairwiseDistancesArgminMinMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamAxis> <http://www.w3.org/2000/01/rdf-schema#range> <http://www.w3.org/2001/XMLSchema#int> .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamB
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamB> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#DatatypeProperty> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamB> <http://www.w3.org/2000/01/rdf-schema#subPropertyOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamB> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#ConsensusScoreMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamB> <http://www.w3.org/2000/01/rdf-schema#range> <http://www.w3.org/2001/XMLSchema#string> .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamBeta
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamBeta> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#DatatypeProperty> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamBeta> <http://www.w3.org/2000/01/rdf-schema#subPropertyOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamBeta> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#FbetaScoreMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamBeta> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#HomogeneityCompletenessVMeasureMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamBeta> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PrecisionRecallFscoreSupportMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamBeta> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#VMeasureScoreMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamBeta> <http://www.w3.org/2000/01/rdf-schema#range> <http://www.w3.org/2001/XMLSchema#float> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamBeta> <http://www.w3.org/2000/01/rdf-schema#range> <http://www.w3.org/2001/XMLSchema#int> .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamContingency
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamContingency> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#DatatypeProperty> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamContingency> <http://www.w3.org/2000/01/rdf-schema#subPropertyOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamContingency> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MutualInfoScoreMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamContingency> <http://www.w3.org/2000/01/rdf-schema#range> <http://www.w3.org/2001/XMLSchema#string> .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamCopy
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamCopy> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#DatatypeProperty> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamCopy> <http://www.w3.org/2000/01/rdf-schema#subPropertyOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamCopy> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#NanEuclideanDistancesMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamCopy> <http://www.w3.org/2000/01/rdf-schema#range> <http://www.w3.org/2001/XMLSchema#boolean> .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamDigits
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamDigits> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#DatatypeProperty> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamDigits> <http://www.w3.org/2000/01/rdf-schema#subPropertyOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamDigits> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#ClassificationReportMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamDigits> <http://www.w3.org/2000/01/rdf-schema#range> <http://www.w3.org/2001/XMLSchema#int> .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamDropIntermediate
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamDropIntermediate> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#DatatypeProperty> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamDropIntermediate> <http://www.w3.org/2000/01/rdf-schema#subPropertyOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamDropIntermediate> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PrecisionRecallCurveMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamDropIntermediate> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RocCurveMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamDropIntermediate> <http://www.w3.org/2000/01/rdf-schema#range> <http://www.w3.org/2001/XMLSchema#boolean> .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamEps
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamEps> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#DatatypeProperty> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamEps> <http://www.w3.org/2000/01/rdf-schema#subPropertyOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamEps> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#LogLossMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamEps> <http://www.w3.org/2000/01/rdf-schema#range> <http://www.w3.org/2001/XMLSchema#float> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamEps> <http://www.w3.org/2000/01/rdf-schema#range> <http://www.w3.org/2001/XMLSchema#int> .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamFilterParams
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamFilterParams> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#DatatypeProperty> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamFilterParams> <http://www.w3.org/2000/01/rdf-schema#subPropertyOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamFilterParams> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PairwiseKernelsMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamFilterParams> <http://www.w3.org/2000/01/rdf-schema#range> <http://www.w3.org/2001/XMLSchema#boolean> .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamForceAllFinite
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamForceAllFinite> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#DatatypeProperty> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamForceAllFinite> <http://www.w3.org/2000/01/rdf-schema#subPropertyOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamForceAllFinite> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PairwiseDistancesMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamForceAllFinite> <http://www.w3.org/2000/01/rdf-schema#range> <http://www.w3.org/2001/XMLSchema#boolean> .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamForceFinite
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamForceFinite> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#DatatypeProperty> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamForceFinite> <http://www.w3.org/2000/01/rdf-schema#subPropertyOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamForceFinite> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#ExplainedVarianceScoreMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamForceFinite> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#R2ScoreMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamForceFinite> <http://www.w3.org/2000/01/rdf-schema#range> <http://www.w3.org/2001/XMLSchema#boolean> .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamGreaterIsBetter
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamGreaterIsBetter> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#DatatypeProperty> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamGreaterIsBetter> <http://www.w3.org/2000/01/rdf-schema#subPropertyOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamGreaterIsBetter> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MakeScorerMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamGreaterIsBetter> <http://www.w3.org/2000/01/rdf-schema#range> <http://www.w3.org/2001/XMLSchema#boolean> .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamIgnoreTies
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamIgnoreTies> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#DatatypeProperty> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamIgnoreTies> <http://www.w3.org/2000/01/rdf-schema#subPropertyOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamIgnoreTies> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#DcgScoreMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamIgnoreTies> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#NdcgScoreMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamIgnoreTies> <http://www.w3.org/2000/01/rdf-schema#range> <http://www.w3.org/2001/XMLSchema#boolean> .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamK
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamK> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#DatatypeProperty> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamK> <http://www.w3.org/2000/01/rdf-schema#subPropertyOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamK> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#DcgScoreMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamK> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#NdcgScoreMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamK> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#TopKAccuracyScoreMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamK> <http://www.w3.org/2000/01/rdf-schema#range> <http://www.w3.org/2001/XMLSchema#int> .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamLogBase
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamLogBase> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#DatatypeProperty> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamLogBase> <http://www.w3.org/2000/01/rdf-schema#subPropertyOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamLogBase> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#DcgScoreMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamLogBase> <http://www.w3.org/2000/01/rdf-schema#range> <http://www.w3.org/2001/XMLSchema#float> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamLogBase> <http://www.w3.org/2000/01/rdf-schema#range> <http://www.w3.org/2001/XMLSchema#int> .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamMetric
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamMetric> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#DatatypeProperty> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamMetric> <http://www.w3.org/2000/01/rdf-schema#subPropertyOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamMetric> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PairwiseDistancesArgminMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamMetric> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PairwiseDistancesArgminMinMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamMetric> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PairwiseDistancesChunkedMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamMetric> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PairwiseDistancesMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamMetric> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PairwiseKernelsMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamMetric> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#SilhouetteSamplesMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamMetric> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#SilhouetteScoreMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamMetric> <http://www.w3.org/2000/01/rdf-schema#range> <http://www.w3.org/2001/XMLSchema#string> .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamMetricKwargs
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamMetricKwargs> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#DatatypeProperty> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamMetricKwargs> <http://www.w3.org/2000/01/rdf-schema#subPropertyOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamMetricKwargs> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PairwiseDistancesArgminMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamMetricKwargs> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PairwiseDistancesArgminMinMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamMetricKwargs> <http://www.w3.org/2000/01/rdf-schema#range> <http://www.w3.org/2001/XMLSchema#string> .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamMissingValues
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamMissingValues> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#DatatypeProperty> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamMissingValues> <http://www.w3.org/2000/01/rdf-schema#subPropertyOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamMissingValues> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#NanEuclideanDistancesMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamMissingValues> <http://www.w3.org/2000/01/rdf-schema#range> <http://www.w3.org/2001/XMLSchema#float> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamMissingValues> <http://www.w3.org/2000/01/rdf-schema#range> <http://www.w3.org/2001/XMLSchema#int> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamMissingValues> <http://www.w3.org/2000/01/rdf-schema#range> <http://www.w3.org/2001/XMLSchema#string> .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamMultiClass
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamMultiClass> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#DatatypeProperty> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamMultiClass> <http://www.w3.org/2000/01/rdf-schema#subPropertyOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamMultiClass> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RocAucScoreMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamMultiClass> <http://www.w3.org/2000/01/rdf-schema#range> <http://www.w3.org/2001/XMLSchema#string> .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamMultioutput
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamMultioutput> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#DatatypeProperty> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamMultioutput> <http://www.w3.org/2000/01/rdf-schema#subPropertyOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamMultioutput> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#D2AbsoluteErrorScoreMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamMultioutput> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#D2PinballScoreMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamMultioutput> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#ExplainedVarianceScoreMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamMultioutput> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MeanAbsoluteErrorMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamMultioutput> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MeanAbsolutePercentageErrorMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamMultioutput> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MeanPinballLossMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamMultioutput> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MeanSquaredErrorMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamMultioutput> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MeanSquaredLogErrorMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamMultioutput> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MedianAbsoluteErrorMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamMultioutput> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#R2ScoreMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamMultioutput> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RootMeanSquaredErrorMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamMultioutput> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RootMeanSquaredLogErrorMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamMultioutput> <http://www.w3.org/2000/01/rdf-schema#range> <http://www.w3.org/2001/XMLSchema#string> .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamNJobs
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamNJobs> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#DatatypeProperty> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamNJobs> <http://www.w3.org/2000/01/rdf-schema#subPropertyOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamNJobs> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PairwiseDistancesChunkedMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamNJobs> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PairwiseDistancesMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamNJobs> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PairwiseKernelsMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamNJobs> <http://www.w3.org/2000/01/rdf-schema#range> <http://www.w3.org/2001/XMLSchema#int> .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamNeedsProba
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamNeedsProba> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#DatatypeProperty> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamNeedsProba> <http://www.w3.org/2000/01/rdf-schema#subPropertyOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamNeedsProba> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MakeScorerMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamNeedsProba> <http://www.w3.org/2000/01/rdf-schema#range> <http://www.w3.org/2001/XMLSchema#boolean> .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamNeedsThreshold
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamNeedsThreshold> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#DatatypeProperty> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamNeedsThreshold> <http://www.w3.org/2000/01/rdf-schema#subPropertyOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamNeedsThreshold> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MakeScorerMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamNeedsThreshold> <http://www.w3.org/2000/01/rdf-schema#range> <http://www.w3.org/2001/XMLSchema#boolean> .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamNormalize
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamNormalize> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#DatatypeProperty> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamNormalize> <http://www.w3.org/2000/01/rdf-schema#subPropertyOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamNormalize> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#AccuracyScoreMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamNormalize> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#ConfusionMatrixMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamNormalize> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#LogLossMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamNormalize> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#TopKAccuracyScoreMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamNormalize> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#ZeroOneLossMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamNormalize> <http://www.w3.org/2000/01/rdf-schema#range> <http://www.w3.org/2001/XMLSchema#boolean> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamNormalize> <http://www.w3.org/2000/01/rdf-schema#range> <http://www.w3.org/2001/XMLSchema#string> .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamOutputDict
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamOutputDict> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#DatatypeProperty> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamOutputDict> <http://www.w3.org/2000/01/rdf-schema#subPropertyOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamOutputDict> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#ClassificationReportMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamOutputDict> <http://www.w3.org/2000/01/rdf-schema#range> <http://www.w3.org/2001/XMLSchema#boolean> .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamPosLabel
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamPosLabel> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#DatatypeProperty> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamPosLabel> <http://www.w3.org/2000/01/rdf-schema#subPropertyOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamPosLabel> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#AveragePrecisionScoreMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamPosLabel> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#BrierScoreLossMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamPosLabel> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#DetCurveMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamPosLabel> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#F1ScoreMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamPosLabel> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#FbetaScoreMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamPosLabel> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#JaccardScoreMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamPosLabel> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PrecisionRecallCurveMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamPosLabel> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PrecisionRecallFscoreSupportMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamPosLabel> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PrecisionScoreMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamPosLabel> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RecallScoreMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamPosLabel> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RocCurveMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamPosLabel> <http://www.w3.org/2000/01/rdf-schema#range> <http://www.w3.org/2001/XMLSchema#boolean> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamPosLabel> <http://www.w3.org/2000/01/rdf-schema#range> <http://www.w3.org/2001/XMLSchema#float> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamPosLabel> <http://www.w3.org/2000/01/rdf-schema#range> <http://www.w3.org/2001/XMLSchema#int> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamPosLabel> <http://www.w3.org/2000/01/rdf-schema#range> <http://www.w3.org/2001/XMLSchema#string> .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamPower
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamPower> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#DatatypeProperty> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamPower> <http://www.w3.org/2000/01/rdf-schema#subPropertyOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamPower> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#D2TweedieScoreMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamPower> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MeanTweedieDevianceMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamPower> <http://www.w3.org/2000/01/rdf-schema#range> <http://www.w3.org/2001/XMLSchema#float> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamPower> <http://www.w3.org/2000/01/rdf-schema#range> <http://www.w3.org/2001/XMLSchema#int> .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamPredDecision
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamPredDecision> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#DatatypeProperty> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamPredDecision> <http://www.w3.org/2000/01/rdf-schema#subPropertyOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamPredDecision> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#HingeLossMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamPredDecision> <http://www.w3.org/2000/01/rdf-schema#range> <http://www.w3.org/2001/XMLSchema#string> .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamRaiseWarning
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamRaiseWarning> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#DatatypeProperty> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamRaiseWarning> <http://www.w3.org/2000/01/rdf-schema#subPropertyOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamRaiseWarning> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#ClassLikelihoodRatiosMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamRaiseWarning> <http://www.w3.org/2000/01/rdf-schema#range> <http://www.w3.org/2001/XMLSchema#boolean> .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamRandomState
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamRandomState> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#DatatypeProperty> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamRandomState> <http://www.w3.org/2000/01/rdf-schema#subPropertyOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamRandomState> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#SilhouetteScoreMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamRandomState> <http://www.w3.org/2000/01/rdf-schema#range> <http://www.w3.org/2001/XMLSchema#int> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamRandomState> <http://www.w3.org/2000/01/rdf-schema#range> <http://www.w3.org/2001/XMLSchema#string> .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamReduceFunc
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamReduceFunc> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#DatatypeProperty> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamReduceFunc> <http://www.w3.org/2000/01/rdf-schema#subPropertyOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamReduceFunc> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PairwiseDistancesChunkedMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamReduceFunc> <http://www.w3.org/2000/01/rdf-schema#range> <http://www.w3.org/2001/XMLSchema#string> .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamResponseMethod
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamResponseMethod> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#DatatypeProperty> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamResponseMethod> <http://www.w3.org/2000/01/rdf-schema#subPropertyOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamResponseMethod> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MakeScorerMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamResponseMethod> <http://www.w3.org/2000/01/rdf-schema#range> <http://www.w3.org/2001/XMLSchema#string> .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamSampleSize
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamSampleSize> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#DatatypeProperty> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamSampleSize> <http://www.w3.org/2000/01/rdf-schema#subPropertyOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamSampleSize> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#SilhouetteScoreMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamSampleSize> <http://www.w3.org/2000/01/rdf-schema#range> <http://www.w3.org/2001/XMLSchema#int> .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamSamplewise
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamSamplewise> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#DatatypeProperty> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamSamplewise> <http://www.w3.org/2000/01/rdf-schema#subPropertyOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamSamplewise> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MultilabelConfusionMatrixMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamSamplewise> <http://www.w3.org/2000/01/rdf-schema#range> <http://www.w3.org/2001/XMLSchema#boolean> .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamScoreFunc
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamScoreFunc> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#DatatypeProperty> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamScoreFunc> <http://www.w3.org/2000/01/rdf-schema#subPropertyOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamScoreFunc> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MakeScorerMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamScoreFunc> <http://www.w3.org/2000/01/rdf-schema#range> <http://www.w3.org/2001/XMLSchema#string> .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamScoring
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamScoring> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#DatatypeProperty> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamScoring> <http://www.w3.org/2000/01/rdf-schema#subPropertyOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamScoring> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#CheckScoringMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamScoring> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#GetScorerMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamScoring> <http://www.w3.org/2000/01/rdf-schema#range> <http://www.w3.org/2001/XMLSchema#string> .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamSimilarity
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamSimilarity> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#DatatypeProperty> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamSimilarity> <http://www.w3.org/2000/01/rdf-schema#subPropertyOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamSimilarity> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#ConsensusScoreMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamSimilarity> <http://www.w3.org/2000/01/rdf-schema#range> <http://www.w3.org/2001/XMLSchema#string> .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamSparse
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamSparse> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#DatatypeProperty> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamSparse> <http://www.w3.org/2000/01/rdf-schema#subPropertyOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamSparse> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#FowlkesMallowsScoreMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamSparse> <http://www.w3.org/2000/01/rdf-schema#range> <http://www.w3.org/2001/XMLSchema#boolean> .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamSquared
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamSquared> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#DatatypeProperty> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamSquared> <http://www.w3.org/2000/01/rdf-schema#subPropertyOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamSquared> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#EuclideanDistancesMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamSquared> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MeanSquaredErrorMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamSquared> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MeanSquaredLogErrorMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamSquared> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#NanEuclideanDistancesMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamSquared> <http://www.w3.org/2000/01/rdf-schema#range> <http://www.w3.org/2001/XMLSchema#boolean> .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamWarnFor
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamWarnFor> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#DatatypeProperty> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamWarnFor> <http://www.w3.org/2000/01/rdf-schema#subPropertyOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamWarnFor> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PrecisionRecallFscoreSupportMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamWarnFor> <http://www.w3.org/2000/01/rdf-schema#range> <http://www.w3.org/2001/XMLSchema#string> .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamWeights
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamWeights> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#DatatypeProperty> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamWeights> <http://www.w3.org/2000/01/rdf-schema#subPropertyOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamWeights> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#CohenKappaScoreMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamWeights> <http://www.w3.org/2000/01/rdf-schema#range> <http://www.w3.org/2001/XMLSchema#string> .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamWorkingMemory
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamWorkingMemory> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#DatatypeProperty> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamWorkingMemory> <http://www.w3.org/2000/01/rdf-schema#subPropertyOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamWorkingMemory> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PairwiseDistancesChunkedMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamWorkingMemory> <http://www.w3.org/2000/01/rdf-schema#range> <http://www.w3.org/2001/XMLSchema#float> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamWorkingMemory> <http://www.w3.org/2000/01/rdf-schema#range> <http://www.w3.org/2001/XMLSchema#int> .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamZeroDivision
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamZeroDivision> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#DatatypeProperty> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamZeroDivision> <http://www.w3.org/2000/01/rdf-schema#subPropertyOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamZeroDivision> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#ClassificationReportMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamZeroDivision> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#F1ScoreMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamZeroDivision> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#FbetaScoreMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamZeroDivision> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#JaccardScoreMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamZeroDivision> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PrecisionRecallFscoreSupportMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamZeroDivision> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PrecisionScoreMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamZeroDivision> <http://www.w3.org/2000/01/rdf-schema#domain> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RecallScoreMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamZeroDivision> <http://www.w3.org/2000/01/rdf-schema#range> <http://www.w3.org/2001/XMLSchema#string> .
# 
# 
# 
# #################################################################
# #
# #    Classes
# #
# #################################################################
# 
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Class> .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#Module
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#Module> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Class> .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#AccuracyScoreMethod
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#AccuracyScoreMethod> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Class> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#AccuracyScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#AccuracyScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MetricsModule> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#AccuracyScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PerformanceCalculationMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PerformanceCalculationMethod> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Class> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#AccuracyScoreMethod> <http://www.w3.org/2000/01/rdf-schema#comment> "Accuracy classification score.\n\nIn multilabel classification, this function computes subset accuracy:\nthe set of labels predicted for a sample must *exactly* match the\ncorresponding set of labels in y_true.\n\nRead more in the :ref:`User Guide <accuracy_score>`.\n\nParameters\n----------\ny_true : 1d array-like, or label indicator array / sparse matrix\n    Ground truth (correct) labels.\n\ny_pred : 1d array-like, or label indicator array / sparse matrix\n    Predicted labels, as returned by a classifier.\n\nnormalize : bool, default=True\n    If ``False``, return the number of correctly classified samples.\n    Otherwise, return the fraction of correctly classified samples.\n\nsample_weight : array-like of shape (n_samples,), default=None\n    Sample weights.\n\nReturns\n-------\nscore : float\n    If ``normalize == True``, return the fraction of correctly\n    classified samples (float), else returns the number of correctly\n    classified samples (int).\n\n    The best performance is 1 with ``normalize == True`` and the number\n    of samples with ``normalize == False``.\n\nSee Also\n--------\nbalanced_accuracy_score : Compute the balanced accuracy to deal with\n    imbalanced datasets.\njaccard_score : Compute the Jaccard similarity coefficient score.\nhamming_loss : Compute the average Hamming loss or Hamming distance between\n    two sets of samples.\nzero_one_loss : Compute the Zero-one classification loss. By default, the\n    function will return the percentage of imperfectly predicted subsets.\n\nNotes\n-----\nIn binary classification, this function is equal to the `jaccard_score`\nfunction.\n\nExamples\n--------\n>>> from sklearn.metrics import accuracy_score\n>>> y_pred = [0, 2, 1, 3]\n>>> y_true = [0, 1, 2, 3]\n>>> accuracy_score(y_true, y_pred)\n0.5\n>>> accuracy_score(y_true, y_pred, normalize=False)\n2.0\n\nIn the multilabel case with binary label indicators:\n\n>>> import numpy as np\n>>> accuracy_score(np.array([[0, 1], [1, 1]]), np.ones((2, 2)))\n0.5" .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#AdjustedMutualInfoScoreMethod
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#AdjustedMutualInfoScoreMethod> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Class> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#AdjustedMutualInfoScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#AdjustedMutualInfoScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MetricsModule> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#AdjustedMutualInfoScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PerformanceCalculationMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#AdjustedMutualInfoScoreMethod> <http://www.w3.org/2000/01/rdf-schema#comment> "Adjusted Mutual Information between two clusterings.\n\nAdjusted Mutual Information (AMI) is an adjustment of the Mutual\nInformation (MI) score to account for chance. It accounts for the fact that\nthe MI is generally higher for two clusterings with a larger number of\nclusters, regardless of whether there is actually more information shared.\nFor two clusterings :math:`U` and :math:`V`, the AMI is given as::\n\n    AMI(U, V) = [MI(U, V) - E(MI(U, V))] / [avg(H(U), H(V)) - E(MI(U, V))]\n\nThis metric is independent of the absolute values of the labels:\na permutation of the class or cluster label values won't change the\nscore value in any way.\n\nThis metric is furthermore symmetric: switching :math:`U` (``label_true``)\nwith :math:`V` (``labels_pred``) will return the same score value. This can\nbe useful to measure the agreement of two independent label assignments\nstrategies on the same dataset when the real ground truth is not known.\n\nBe mindful that this function is an order of magnitude slower than other\nmetrics, such as the Adjusted Rand Index.\n\nRead more in the :ref:`User Guide <mutual_info_score>`.\n\nParameters\n----------\nlabels_true : int array-like of shape (n_samples,)\n    A clustering of the data into disjoint subsets, called :math:`U` in\n    the above formula.\n\nlabels_pred : int array-like of shape (n_samples,)\n    A clustering of the data into disjoint subsets, called :math:`V` in\n    the above formula.\n\naverage_method : {'min', 'geometric', 'arithmetic', 'max'}, default='arithmetic'\n    How to compute the normalizer in the denominator.\n\n    .. versionadded:: 0.20\n\n    .. versionchanged:: 0.22\n       The default value of ``average_method`` changed from 'max' to\n       'arithmetic'.\n\nReturns\n-------\nami: float (upperlimited by 1.0)\n   The AMI returns a value of 1 when the two partitions are identical\n   (ie perfectly matched). Random partitions (independent labellings) have\n   an expected AMI around 0 on average hence can be negative. The value is\n   in adjusted nats (based on the natural logarithm).\n\nSee Also\n--------\nadjusted_rand_score : Adjusted Rand Index.\nmutual_info_score : Mutual Information (not adjusted for chance).\n\nReferences\n----------\n.. [1] `Vinh, Epps, and Bailey, (2010). Information Theoretic Measures for\n   Clusterings Comparison: Variants, Properties, Normalization and\n   Correction for Chance, JMLR\n   <http://jmlr.csail.mit.edu/papers/volume11/vinh10a/vinh10a.pdf>`_\n\n.. [2] `Wikipedia entry for the Adjusted Mutual Information\n   <https://en.wikipedia.org/wiki/Adjusted_Mutual_Information>`_\n\nExamples\n--------\n\nPerfect labelings are both homogeneous and complete, hence have\nscore 1.0::\n\n  >>> from sklearn.metrics.cluster import adjusted_mutual_info_score\n  >>> adjusted_mutual_info_score([0, 0, 1, 1], [0, 0, 1, 1])\n  ... # doctest: +SKIP\n  1.0\n  >>> adjusted_mutual_info_score([0, 0, 1, 1], [1, 1, 0, 0])\n  ... # doctest: +SKIP\n  1.0\n\nIf classes members are completely split across different clusters,\nthe assignment is totally in-complete, hence the AMI is null::\n\n  >>> adjusted_mutual_info_score([0, 0, 0, 0], [0, 1, 2, 3])\n  ... # doctest: +SKIP\n  0.0" .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#AdjustedRandScoreMethod
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#AdjustedRandScoreMethod> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Class> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#AdjustedRandScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#AdjustedRandScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MetricsModule> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#AdjustedRandScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PerformanceCalculationMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#AdjustedRandScoreMethod> <http://www.w3.org/2000/01/rdf-schema#comment> "Rand index adjusted for chance.\n\nThe Rand Index computes a similarity measure between two clusterings\nby considering all pairs of samples and counting pairs that are\nassigned in the same or different clusters in the predicted and\ntrue clusterings.\n\nThe raw RI score is then \"adjusted for chance\" into the ARI score\nusing the following scheme::\n\n    ARI = (RI - Expected_RI) / (max(RI) - Expected_RI)\n\nThe adjusted Rand index is thus ensured to have a value close to\n0.0 for random labeling independently of the number of clusters and\nsamples and exactly 1.0 when the clusterings are identical (up to\na permutation). The adjusted Rand index is bounded below by -0.5 for\nespecially discordant clusterings.\n\nARI is a symmetric measure::\n\n    adjusted_rand_score(a, b) == adjusted_rand_score(b, a)\n\nRead more in the :ref:`User Guide <adjusted_rand_score>`.\n\nParameters\n----------\nlabels_true : array-like of shape (n_samples,), dtype=int\n    Ground truth class labels to be used as a reference.\n\nlabels_pred : array-like of shape (n_samples,), dtype=int\n    Cluster labels to evaluate.\n\nReturns\n-------\nARI : float\n   Similarity score between -0.5 and 1.0. Random labelings have an ARI\n   close to 0.0. 1.0 stands for perfect match.\n\nSee Also\n--------\nadjusted_mutual_info_score : Adjusted Mutual Information.\n\nReferences\n----------\n.. [Hubert1985] L. Hubert and P. Arabie, Comparing Partitions,\n  Journal of Classification 1985\n  https://link.springer.com/article/10.1007%2FBF01908075\n\n.. [Steinley2004] D. Steinley, Properties of the Hubert-Arabie\n  adjusted Rand index, Psychological Methods 2004\n\n.. [wk] https://en.wikipedia.org/wiki/Rand_index#Adjusted_Rand_index\n\n.. [Chacon] :doi:`Minimum adjusted Rand index for two clusterings of a given size,\n  2022, J. E. Chacn and A. I. Rastrojo <10.1007/s11634-022-00491-w>`\n\nExamples\n--------\nPerfectly matching labelings have a score of 1 even\n\n  >>> from sklearn.metrics.cluster import adjusted_rand_score\n  >>> adjusted_rand_score([0, 0, 1, 1], [0, 0, 1, 1])\n  1.0\n  >>> adjusted_rand_score([0, 0, 1, 1], [1, 1, 0, 0])\n  1.0\n\nLabelings that assign all classes members to the same clusters\nare complete but may not always be pure, hence penalized::\n\n  >>> adjusted_rand_score([0, 0, 1, 2], [0, 0, 1, 1])\n  0.57...\n\nARI is symmetric, so labelings that have pure clusters with members\ncoming from the same classes but unnecessary splits are penalized::\n\n  >>> adjusted_rand_score([0, 0, 1, 1], [0, 0, 1, 2])\n  0.57...\n\nIf classes members are completely split across different clusters, the\nassignment is totally incomplete, hence the ARI is very low::\n\n  >>> adjusted_rand_score([0, 0, 0, 0], [0, 1, 2, 3])\n  0.0\n\nARI may take a negative value for especially discordant labelings that\nare a worse choice than the expected value of random labels::\n\n  >>> adjusted_rand_score([0, 0, 1, 1], [0, 1, 0, 1])\n  -0.5" .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#AucMethod
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#AucMethod> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Class> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#AucMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#AucMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MetricsModule> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#AucMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PerformanceCalculationMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#AucMethod> <http://www.w3.org/2000/01/rdf-schema#comment> "Compute Area Under the Curve (AUC) using the trapezoidal rule.\n\nThis is a general function, given points on a curve.  For computing the\narea under the ROC-curve, see :func:`roc_auc_score`.  For an alternative\nway to summarize a precision-recall curve, see\n:func:`average_precision_score`.\n\nParameters\n----------\nx : array-like of shape (n,)\n    X coordinates. These must be either monotonic increasing or monotonic\n    decreasing.\ny : array-like of shape (n,)\n    Y coordinates.\n\nReturns\n-------\nauc : float\n    Area Under the Curve.\n\nSee Also\n--------\nroc_auc_score : Compute the area under the ROC curve.\naverage_precision_score : Compute average precision from prediction scores.\nprecision_recall_curve : Compute precision-recall pairs for different\n    probability thresholds.\n\nExamples\n--------\n>>> import numpy as np\n>>> from sklearn import metrics\n>>> y = np.array([1, 1, 2, 2])\n>>> pred = np.array([0.1, 0.4, 0.35, 0.8])\n>>> fpr, tpr, thresholds = metrics.roc_curve(y, pred, pos_label=2)\n>>> metrics.auc(fpr, tpr)\n0.75" .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#AveragePrecisionScoreMethod
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#AveragePrecisionScoreMethod> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Class> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#AveragePrecisionScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#AveragePrecisionScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MetricsModule> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#AveragePrecisionScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PerformanceCalculationMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#AveragePrecisionScoreMethod> <http://www.w3.org/2000/01/rdf-schema#comment> "Compute average precision (AP) from prediction scores.\n\nAP summarizes a precision-recall curve as the weighted mean of precisions\nachieved at each threshold, with the increase in recall from the previous\nthreshold used as the weight:\n\n.. math::\n    \\text{AP} = \\sum_n (R_n - R_{n-1}) P_n\n\nwhere :math:`P_n` and :math:`R_n` are the precision and recall at the nth\nthreshold [1]_. This implementation is not interpolated and is different\nfrom computing the area under the precision-recall curve with the\ntrapezoidal rule, which uses linear interpolation and can be too\noptimistic.\n\nRead more in the :ref:`User Guide <precision_recall_f_measure_metrics>`.\n\nParameters\n----------\ny_true : array-like of shape (n_samples,) or (n_samples, n_classes)\n    True binary labels or binary label indicators.\n\ny_score : array-like of shape (n_samples,) or (n_samples, n_classes)\n    Target scores, can either be probability estimates of the positive\n    class, confidence values, or non-thresholded measure of decisions\n    (as returned by :term:`decision_function` on some classifiers).\n\naverage : {'micro', 'samples', 'weighted', 'macro'} or None,             default='macro'\n    If ``None``, the scores for each class are returned. Otherwise,\n    this determines the type of averaging performed on the data:\n\n    ``'micro'``:\n        Calculate metrics globally by considering each element of the label\n        indicator matrix as a label.\n    ``'macro'``:\n        Calculate metrics for each label, and find their unweighted\n        mean.  This does not take label imbalance into account.\n    ``'weighted'``:\n        Calculate metrics for each label, and find their average, weighted\n        by support (the number of true instances for each label).\n    ``'samples'``:\n        Calculate metrics for each instance, and find their average.\n\n    Will be ignored when ``y_true`` is binary.\n\npos_label : int, float, bool or str, default=1\n    The label of the positive class. Only applied to binary ``y_true``.\n    For multilabel-indicator ``y_true``, ``pos_label`` is fixed to 1.\n\nsample_weight : array-like of shape (n_samples,), default=None\n    Sample weights.\n\nReturns\n-------\naverage_precision : float\n    Average precision score.\n\nSee Also\n--------\nroc_auc_score : Compute the area under the ROC curve.\nprecision_recall_curve : Compute precision-recall pairs for different\n    probability thresholds.\n\nNotes\n-----\n.. versionchanged:: 0.19\n  Instead of linearly interpolating between operating points, precisions\n  are weighted by the change in recall since the last operating point.\n\nReferences\n----------\n.. [1] `Wikipedia entry for the Average precision\n       <https://en.wikipedia.org/w/index.php?title=Information_retrieval&\n       oldid=793358396#Average_precision>`_\n\nExamples\n--------\n>>> import numpy as np\n>>> from sklearn.metrics import average_precision_score\n>>> y_true = np.array([0, 0, 1, 1])\n>>> y_scores = np.array([0.1, 0.4, 0.35, 0.8])\n>>> average_precision_score(y_true, y_scores)\n0.83...\n>>> y_true = np.array([0, 0, 1, 1, 2, 2])\n>>> y_scores = np.array([\n...     [0.7, 0.2, 0.1],\n...     [0.4, 0.3, 0.3],\n...     [0.1, 0.8, 0.1],\n...     [0.2, 0.3, 0.5],\n...     [0.4, 0.4, 0.2],\n...     [0.1, 0.2, 0.7],\n... ])\n>>> average_precision_score(y_true, y_scores)\n0.77..." .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#BalancedAccuracyScoreMethod
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#BalancedAccuracyScoreMethod> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Class> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#BalancedAccuracyScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#BalancedAccuracyScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MetricsModule> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#BalancedAccuracyScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PerformanceCalculationMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#BalancedAccuracyScoreMethod> <http://www.w3.org/2000/01/rdf-schema#comment> "Compute the balanced accuracy.\n\nThe balanced accuracy in binary and multiclass classification problems to\ndeal with imbalanced datasets. It is defined as the average of recall\nobtained on each class.\n\nThe best value is 1 and the worst value is 0 when ``adjusted=False``.\n\nRead more in the :ref:`User Guide <balanced_accuracy_score>`.\n\n.. versionadded:: 0.20\n\nParameters\n----------\ny_true : array-like of shape (n_samples,)\n    Ground truth (correct) target values.\n\ny_pred : array-like of shape (n_samples,)\n    Estimated targets as returned by a classifier.\n\nsample_weight : array-like of shape (n_samples,), default=None\n    Sample weights.\n\nadjusted : bool, default=False\n    When true, the result is adjusted for chance, so that random\n    performance would score 0, while keeping perfect performance at a score\n    of 1.\n\nReturns\n-------\nbalanced_accuracy : float\n    Balanced accuracy score.\n\nSee Also\n--------\naverage_precision_score : Compute average precision (AP) from prediction\n    scores.\nprecision_score : Compute the precision score.\nrecall_score : Compute the recall score.\nroc_auc_score : Compute Area Under the Receiver Operating Characteristic\n    Curve (ROC AUC) from prediction scores.\n\nNotes\n-----\nSome literature promotes alternative definitions of balanced accuracy. Our\ndefinition is equivalent to :func:`accuracy_score` with class-balanced\nsample weights, and shares desirable properties with the binary case.\nSee the :ref:`User Guide <balanced_accuracy_score>`.\n\nReferences\n----------\n.. [1] Brodersen, K.H.; Ong, C.S.; Stephan, K.E.; Buhmann, J.M. (2010).\n       The balanced accuracy and its posterior distribution.\n       Proceedings of the 20th International Conference on Pattern\n       Recognition, 3121-24.\n.. [2] John. D. Kelleher, Brian Mac Namee, Aoife D'Arcy, (2015).\n       `Fundamentals of Machine Learning for Predictive Data Analytics:\n       Algorithms, Worked Examples, and Case Studies\n       <https://mitpress.mit.edu/books/fundamentals-machine-learning-predictive-data-analytics>`_.\n\nExamples\n--------\n>>> from sklearn.metrics import balanced_accuracy_score\n>>> y_true = [0, 1, 0, 0, 1, 0]\n>>> y_pred = [0, 1, 0, 0, 0, 1]\n>>> balanced_accuracy_score(y_true, y_pred)\n0.625" .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#BrierScoreLossMethod
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#BrierScoreLossMethod> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Class> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#BrierScoreLossMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#BrierScoreLossMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MetricsModule> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#BrierScoreLossMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PerformanceCalculationMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#BrierScoreLossMethod> <http://www.w3.org/2000/01/rdf-schema#comment> "Compute the Brier score loss.\n\nThe smaller the Brier score loss, the better, hence the naming with \"loss\".\nThe Brier score measures the mean squared difference between the predicted\nprobability and the actual outcome. The Brier score always\ntakes on a value between zero and one, since this is the largest\npossible difference between a predicted probability (which must be\nbetween zero and one) and the actual outcome (which can take on values\nof only 0 and 1). It can be decomposed as the sum of refinement loss and\ncalibration loss.\n\nThe Brier score is appropriate for binary and categorical outcomes that\ncan be structured as true or false, but is inappropriate for ordinal\nvariables which can take on three or more values (this is because the\nBrier score assumes that all possible outcomes are equivalently\n\"distant\" from one another). Which label is considered to be the positive\nlabel is controlled via the parameter `pos_label`, which defaults to\nthe greater label unless `y_true` is all 0 or all -1, in which case\n`pos_label` defaults to 1.\n\nRead more in the :ref:`User Guide <brier_score_loss>`.\n\nParameters\n----------\ny_true : array-like of shape (n_samples,)\n    True targets.\n\ny_prob : array-like of shape (n_samples,)\n    Probabilities of the positive class.\n\nsample_weight : array-like of shape (n_samples,), default=None\n    Sample weights.\n\npos_label : int, float, bool or str, default=None\n    Label of the positive class. `pos_label` will be inferred in the\n    following manner:\n\n    * if `y_true` in {-1, 1} or {0, 1}, `pos_label` defaults to 1;\n    * else if `y_true` contains string, an error will be raised and\n      `pos_label` should be explicitly specified;\n    * otherwise, `pos_label` defaults to the greater label,\n      i.e. `np.unique(y_true)[-1]`.\n\nReturns\n-------\nscore : float\n    Brier score loss.\n\nReferences\n----------\n.. [1] `Wikipedia entry for the Brier score\n        <https://en.wikipedia.org/wiki/Brier_score>`_.\n\nExamples\n--------\n>>> import numpy as np\n>>> from sklearn.metrics import brier_score_loss\n>>> y_true = np.array([0, 1, 1, 0])\n>>> y_true_categorical = np.array([\"spam\", \"ham\", \"ham\", \"spam\"])\n>>> y_prob = np.array([0.1, 0.9, 0.8, 0.3])\n>>> brier_score_loss(y_true, y_prob)\n0.037...\n>>> brier_score_loss(y_true, 1-y_prob, pos_label=0)\n0.037...\n>>> brier_score_loss(y_true_categorical, y_prob, pos_label=\"ham\")\n0.037...\n>>> brier_score_loss(y_true, np.array(y_prob) > 0.5)\n0.0" .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#CalinskiHarabaszScoreMethod
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#CalinskiHarabaszScoreMethod> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Class> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#CalinskiHarabaszScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#CalinskiHarabaszScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MetricsModule> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#CalinskiHarabaszScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PerformanceCalculationMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#CalinskiHarabaszScoreMethod> <http://www.w3.org/2000/01/rdf-schema#comment> "Compute the Calinski and Harabasz score.\n\nIt is also known as the Variance Ratio Criterion.\n\nThe score is defined as ratio of the sum of between-cluster dispersion and\nof within-cluster dispersion.\n\nRead more in the :ref:`User Guide <calinski_harabasz_index>`.\n\nParameters\n----------\nX : array-like of shape (n_samples, n_features)\n    A list of ``n_features``-dimensional data points. Each row corresponds\n    to a single data point.\n\nlabels : array-like of shape (n_samples,)\n    Predicted labels for each sample.\n\nReturns\n-------\nscore : float\n    The resulting Calinski-Harabasz score.\n\nReferences\n----------\n.. [1] `T. Calinski and J. Harabasz, 1974. \"A dendrite method for cluster\n   analysis\". Communications in Statistics\n   <https://www.tandfonline.com/doi/abs/10.1080/03610927408827101>`_\n\nExamples\n--------\n>>> from sklearn.datasets import make_blobs\n>>> from sklearn.cluster import KMeans\n>>> from sklearn.metrics import calinski_harabasz_score\n>>> X, _ = make_blobs(random_state=0)\n>>> kmeans = KMeans(n_clusters=3, random_state=0,).fit(X)\n>>> calinski_harabasz_score(X, kmeans.labels_)\n114.8..." .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#CheckScoringMethod
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#CheckScoringMethod> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Class> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#CheckScoringMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#CheckScoringMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MetricsModule> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#CheckScoringMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PerformanceCalculationMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#CheckScoringMethod> <http://www.w3.org/2000/01/rdf-schema#comment> "Determine scorer from user options.\n\nA TypeError will be thrown if the estimator cannot be scored.\n\nParameters\n----------\nestimator : estimator object implementing 'fit'\n    The object to use to fit the data.\n\nscoring : str or callable, default=None\n    A string (see model evaluation documentation) or\n    a scorer callable object / function with signature\n    ``scorer(estimator, X, y)``.\n    If None, the provided estimator object's `score` method is used.\n\nallow_none : bool, default=False\n    If no scoring is specified and the estimator has no score function, we\n    can either return None or raise an exception.\n\nReturns\n-------\nscoring : callable\n    A scorer callable object / function with signature\n    ``scorer(estimator, X, y)``.\n\nExamples\n--------\n>>> from sklearn.datasets import load_iris\n>>> from sklearn.metrics import check_scoring\n>>> from sklearn.tree import DecisionTreeClassifier\n>>> X, y = load_iris(return_X_y=True)\n>>> classifier = DecisionTreeClassifier(max_depth=2).fit(X, y)\n>>> scorer = check_scoring(classifier, scoring='accuracy')\n>>> scorer(classifier, X, y)\n0.96..." .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#ClassLikelihoodRatiosMethod
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#ClassLikelihoodRatiosMethod> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Class> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#ClassLikelihoodRatiosMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#ClassLikelihoodRatiosMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MetricsModule> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#ClassLikelihoodRatiosMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PerformanceCalculationMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#ClassLikelihoodRatiosMethod> <http://www.w3.org/2000/01/rdf-schema#comment> "Compute binary classification positive and negative likelihood ratios.\n\nThe positive likelihood ratio is `LR+ = sensitivity / (1 - specificity)`\nwhere the sensitivity or recall is the ratio `tp / (tp + fn)` and the\nspecificity is `tn / (tn + fp)`. The negative likelihood ratio is `LR- = (1\n- sensitivity) / specificity`. Here `tp` is the number of true positives,\n`fp` the number of false positives, `tn` is the number of true negatives and\n`fn` the number of false negatives. Both class likelihood ratios can be used\nto obtain post-test probabilities given a pre-test probability.\n\n`LR+` ranges from 1 to infinity. A `LR+` of 1 indicates that the probability\nof predicting the positive class is the same for samples belonging to either\nclass; therefore, the test is useless. The greater `LR+` is, the more a\npositive prediction is likely to be a true positive when compared with the\npre-test probability. A value of `LR+` lower than 1 is invalid as it would\nindicate that the odds of a sample being a true positive decrease with\nrespect to the pre-test odds.\n\n`LR-` ranges from 0 to 1. The closer it is to 0, the lower the probability\nof a given sample to be a false negative. A `LR-` of 1 means the test is\nuseless because the odds of having the condition did not change after the\ntest. A value of `LR-` greater than 1 invalidates the classifier as it\nindicates an increase in the odds of a sample belonging to the positive\nclass after being classified as negative. This is the case when the\nclassifier systematically predicts the opposite of the true label.\n\nA typical application in medicine is to identify the positive/negative class\nto the presence/absence of a disease, respectively; the classifier being a\ndiagnostic test; the pre-test probability of an individual having the\ndisease can be the prevalence of such disease (proportion of a particular\npopulation found to be affected by a medical condition); and the post-test\nprobabilities would be the probability that the condition is truly present\ngiven a positive test result.\n\nRead more in the :ref:`User Guide <class_likelihood_ratios>`.\n\nParameters\n----------\ny_true : 1d array-like, or label indicator array / sparse matrix\n    Ground truth (correct) target values.\n\ny_pred : 1d array-like, or label indicator array / sparse matrix\n    Estimated targets as returned by a classifier.\n\nlabels : array-like, default=None\n    List of labels to index the matrix. This may be used to select the\n    positive and negative classes with the ordering `labels=[negative_class,\n    positive_class]`. If `None` is given, those that appear at least once in\n    `y_true` or `y_pred` are used in sorted order.\n\nsample_weight : array-like of shape (n_samples,), default=None\n    Sample weights.\n\nraise_warning : bool, default=True\n    Whether or not a case-specific warning message is raised when there is a\n    zero division. Even if the error is not raised, the function will return\n    nan in such cases.\n\nReturns\n-------\n(positive_likelihood_ratio, negative_likelihood_ratio) : tuple\n    A tuple of two float, the first containing the Positive likelihood ratio\n    and the second the Negative likelihood ratio.\n\nWarns\n-----\nWhen `false positive == 0`, the positive likelihood ratio is undefined.\nWhen `true negative == 0`, the negative likelihood ratio is undefined.\nWhen `true positive + false negative == 0` both ratios are undefined.\nIn such cases, `UserWarning` will be raised if raise_warning=True.\n\nReferences\n----------\n.. [1] `Wikipedia entry for the Likelihood ratios in diagnostic testing\n       <https://en.wikipedia.org/wiki/Likelihood_ratios_in_diagnostic_testing>`_.\n\nExamples\n--------\n>>> import numpy as np\n>>> from sklearn.metrics import class_likelihood_ratios\n>>> class_likelihood_ratios([0, 1, 0, 1, 0], [1, 1, 0, 0, 0])\n(1.5, 0.75)\n>>> y_true = np.array([\"non-cat\", \"cat\", \"non-cat\", \"cat\", \"non-cat\"])\n>>> y_pred = np.array([\"cat\", \"cat\", \"non-cat\", \"non-cat\", \"non-cat\"])\n>>> class_likelihood_ratios(y_true, y_pred)\n(1.33..., 0.66...)\n>>> y_true = np.array([\"non-zebra\", \"zebra\", \"non-zebra\", \"zebra\", \"non-zebra\"])\n>>> y_pred = np.array([\"zebra\", \"zebra\", \"non-zebra\", \"non-zebra\", \"non-zebra\"])\n>>> class_likelihood_ratios(y_true, y_pred)\n(1.5, 0.75)\n\nTo avoid ambiguities, use the notation `labels=[negative_class,\npositive_class]`\n\n>>> y_true = np.array([\"non-cat\", \"cat\", \"non-cat\", \"cat\", \"non-cat\"])\n>>> y_pred = np.array([\"cat\", \"cat\", \"non-cat\", \"non-cat\", \"non-cat\"])\n>>> class_likelihood_ratios(y_true, y_pred, labels=[\"non-cat\", \"cat\"])\n(1.5, 0.75)" .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#ClassificationReportMethod
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#ClassificationReportMethod> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Class> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#ClassificationReportMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#ClassificationReportMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MetricsModule> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#ClassificationReportMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PerformanceCalculationMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#ClassificationReportMethod> <http://www.w3.org/2000/01/rdf-schema#comment> "Build a text report showing the main classification metrics.\n\nRead more in the :ref:`User Guide <classification_report>`.\n\nParameters\n----------\ny_true : 1d array-like, or label indicator array / sparse matrix\n    Ground truth (correct) target values.\n\ny_pred : 1d array-like, or label indicator array / sparse matrix\n    Estimated targets as returned by a classifier.\n\nlabels : array-like of shape (n_labels,), default=None\n    Optional list of label indices to include in the report.\n\ntarget_names : array-like of shape (n_labels,), default=None\n    Optional display names matching the labels (same order).\n\nsample_weight : array-like of shape (n_samples,), default=None\n    Sample weights.\n\ndigits : int, default=2\n    Number of digits for formatting output floating point values.\n    When ``output_dict`` is ``True``, this will be ignored and the\n    returned values will not be rounded.\n\noutput_dict : bool, default=False\n    If True, return output as dict.\n\n    .. versionadded:: 0.20\n\nzero_division : {\"warn\", 0.0, 1.0, np.nan}, default=\"warn\"\n    Sets the value to return when there is a zero division. If set to\n    \"warn\", this acts as 0, but warnings are also raised.\n\n    .. versionadded:: 1.3\n       `np.nan` option was added.\n\nReturns\n-------\nreport : str or dict\n    Text summary of the precision, recall, F1 score for each class.\n    Dictionary returned if output_dict is True. Dictionary has the\n    following structure::\n\n        {'label 1': {'precision':0.5,\n                     'recall':1.0,\n                     'f1-score':0.67,\n                     'support':1},\n         'label 2': { ... },\n          ...\n        }\n\n    The reported averages include macro average (averaging the unweighted\n    mean per label), weighted average (averaging the support-weighted mean\n    per label), and sample average (only for multilabel classification).\n    Micro average (averaging the total true positives, false negatives and\n    false positives) is only shown for multi-label or multi-class\n    with a subset of classes, because it corresponds to accuracy\n    otherwise and would be the same for all metrics.\n    See also :func:`precision_recall_fscore_support` for more details\n    on averages.\n\n    Note that in binary classification, recall of the positive class\n    is also known as \"sensitivity\"; recall of the negative class is\n    \"specificity\".\n\nSee Also\n--------\nprecision_recall_fscore_support: Compute precision, recall, F-measure and\n    support for each class.\nconfusion_matrix: Compute confusion matrix to evaluate the accuracy of a\n    classification.\nmultilabel_confusion_matrix: Compute a confusion matrix for each class or sample.\n\nExamples\n--------\n>>> from sklearn.metrics import classification_report\n>>> y_true = [0, 1, 2, 2, 2]\n>>> y_pred = [0, 0, 2, 2, 1]\n>>> target_names = ['class 0', 'class 1', 'class 2']\n>>> print(classification_report(y_true, y_pred, target_names=target_names))\n              precision    recall  f1-score   support\n<BLANKLINE>\n     class 0       0.50      1.00      0.67         1\n     class 1       0.00      0.00      0.00         1\n     class 2       1.00      0.67      0.80         3\n<BLANKLINE>\n    accuracy                           0.60         5\n   macro avg       0.50      0.56      0.49         5\nweighted avg       0.70      0.60      0.61         5\n<BLANKLINE>\n>>> y_pred = [1, 1, 0]\n>>> y_true = [1, 1, 1]\n>>> print(classification_report(y_true, y_pred, labels=[1, 2, 3]))\n              precision    recall  f1-score   support\n<BLANKLINE>\n           1       1.00      0.67      0.80         3\n           2       0.00      0.00      0.00         0\n           3       0.00      0.00      0.00         0\n<BLANKLINE>\n   micro avg       1.00      0.67      0.80         3\n   macro avg       0.33      0.22      0.27         3\nweighted avg       1.00      0.67      0.80         3\n<BLANKLINE>" .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#CohenKappaScoreMethod
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#CohenKappaScoreMethod> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Class> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#CohenKappaScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#CohenKappaScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MetricsModule> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#CohenKappaScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PerformanceCalculationMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#CohenKappaScoreMethod> <http://www.w3.org/2000/01/rdf-schema#comment> "Compute Cohen's kappa: a statistic that measures inter-annotator agreement.\n\nThis function computes Cohen's kappa [1]_, a score that expresses the level\nof agreement between two annotators on a classification problem. It is\ndefined as\n\n.. math::\n    \\kappa = (p_o - p_e) / (1 - p_e)\n\nwhere :math:`p_o` is the empirical probability of agreement on the label\nassigned to any sample (the observed agreement ratio), and :math:`p_e` is\nthe expected agreement when both annotators assign labels randomly.\n:math:`p_e` is estimated using a per-annotator empirical prior over the\nclass labels [2]_.\n\nRead more in the :ref:`User Guide <cohen_kappa>`.\n\nParameters\n----------\ny1 : array-like of shape (n_samples,)\n    Labels assigned by the first annotator.\n\ny2 : array-like of shape (n_samples,)\n    Labels assigned by the second annotator. The kappa statistic is\n    symmetric, so swapping ``y1`` and ``y2`` doesn't change the value.\n\nlabels : array-like of shape (n_classes,), default=None\n    List of labels to index the matrix. This may be used to select a\n    subset of labels. If `None`, all labels that appear at least once in\n    ``y1`` or ``y2`` are used.\n\nweights : {'linear', 'quadratic'}, default=None\n    Weighting type to calculate the score. `None` means no weighted;\n    \"linear\" means linear weighted; \"quadratic\" means quadratic weighted.\n\nsample_weight : array-like of shape (n_samples,), default=None\n    Sample weights.\n\nReturns\n-------\nkappa : float\n    The kappa statistic, which is a number between -1 and 1. The maximum\n    value means complete agreement; zero or lower means chance agreement.\n\nReferences\n----------\n.. [1] :doi:`J. Cohen (1960). \"A coefficient of agreement for nominal scales\".\n       Educational and Psychological Measurement 20(1):37-46.\n       <10.1177/001316446002000104>`\n.. [2] `R. Artstein and M. Poesio (2008). \"Inter-coder agreement for\n       computational linguistics\". Computational Linguistics 34(4):555-596\n       <https://www.mitpressjournals.org/doi/pdf/10.1162/coli.07-034-R2>`_.\n.. [3] `Wikipedia entry for the Cohen's kappa\n        <https://en.wikipedia.org/wiki/Cohen%27s_kappa>`_.\n\nExamples\n--------\n>>> from sklearn.metrics import cohen_kappa_score\n>>> y1 = [\"negative\", \"positive\", \"negative\", \"neutral\", \"positive\"]\n>>> y2 = [\"negative\", \"positive\", \"negative\", \"neutral\", \"negative\"]\n>>> cohen_kappa_score(y1, y2)\n0.6875" .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#CompletenessScoreMethod
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#CompletenessScoreMethod> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Class> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#CompletenessScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#CompletenessScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MetricsModule> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#CompletenessScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PerformanceCalculationMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#CompletenessScoreMethod> <http://www.w3.org/2000/01/rdf-schema#comment> "Compute completeness metric of a cluster labeling given a ground truth.\n\nA clustering result satisfies completeness if all the data points\nthat are members of a given class are elements of the same cluster.\n\nThis metric is independent of the absolute values of the labels:\na permutation of the class or cluster label values won't change the\nscore value in any way.\n\nThis metric is not symmetric: switching ``label_true`` with ``label_pred``\nwill return the :func:`homogeneity_score` which will be different in\ngeneral.\n\nRead more in the :ref:`User Guide <homogeneity_completeness>`.\n\nParameters\n----------\nlabels_true : array-like of shape (n_samples,)\n    Ground truth class labels to be used as a reference.\n\nlabels_pred : array-like of shape (n_samples,)\n    Cluster labels to evaluate.\n\nReturns\n-------\ncompleteness : float\n   Score between 0.0 and 1.0. 1.0 stands for perfectly complete labeling.\n\nSee Also\n--------\nhomogeneity_score : Homogeneity metric of cluster labeling.\nv_measure_score : V-Measure (NMI with arithmetic mean option).\n\nReferences\n----------\n\n.. [1] `Andrew Rosenberg and Julia Hirschberg, 2007. V-Measure: A\n   conditional entropy-based external cluster evaluation measure\n   <https://aclweb.org/anthology/D/D07/D07-1043.pdf>`_\n\nExamples\n--------\n\nPerfect labelings are complete::\n\n  >>> from sklearn.metrics.cluster import completeness_score\n  >>> completeness_score([0, 0, 1, 1], [1, 1, 0, 0])\n  1.0\n\nNon-perfect labelings that assign all classes members to the same clusters\nare still complete::\n\n  >>> print(completeness_score([0, 0, 1, 1], [0, 0, 0, 0]))\n  1.0\n  >>> print(completeness_score([0, 1, 2, 3], [0, 0, 1, 1]))\n  0.999...\n\nIf classes members are split across different clusters, the\nassignment cannot be complete::\n\n  >>> print(completeness_score([0, 0, 1, 1], [0, 1, 0, 1]))\n  0.0\n  >>> print(completeness_score([0, 0, 0, 0], [0, 1, 2, 3]))\n  0.0" .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#ConfusionMatrixMethod
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#ConfusionMatrixMethod> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Class> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#ConfusionMatrixMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#ConfusionMatrixMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MetricsModule> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#ConfusionMatrixMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PerformanceCalculationMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#ConfusionMatrixMethod> <http://www.w3.org/2000/01/rdf-schema#comment> "Compute confusion matrix to evaluate the accuracy of a classification.\n\nBy definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\nis equal to the number of observations known to be in group :math:`i` and\npredicted to be in group :math:`j`.\n\nThus in binary classification, the count of true negatives is\n:math:`C_{0,0}`, false negatives is :math:`C_{1,0}`, true positives is\n:math:`C_{1,1}` and false positives is :math:`C_{0,1}`.\n\nRead more in the :ref:`User Guide <confusion_matrix>`.\n\nParameters\n----------\ny_true : array-like of shape (n_samples,)\n    Ground truth (correct) target values.\n\ny_pred : array-like of shape (n_samples,)\n    Estimated targets as returned by a classifier.\n\nlabels : array-like of shape (n_classes), default=None\n    List of labels to index the matrix. This may be used to reorder\n    or select a subset of labels.\n    If ``None`` is given, those that appear at least once\n    in ``y_true`` or ``y_pred`` are used in sorted order.\n\nsample_weight : array-like of shape (n_samples,), default=None\n    Sample weights.\n\n    .. versionadded:: 0.18\n\nnormalize : {'true', 'pred', 'all'}, default=None\n    Normalizes confusion matrix over the true (rows), predicted (columns)\n    conditions or all the population. If None, confusion matrix will not be\n    normalized.\n\nReturns\n-------\nC : ndarray of shape (n_classes, n_classes)\n    Confusion matrix whose i-th row and j-th\n    column entry indicates the number of\n    samples with true label being i-th class\n    and predicted label being j-th class.\n\nSee Also\n--------\nConfusionMatrixDisplay.from_estimator : Plot the confusion matrix\n    given an estimator, the data, and the label.\nConfusionMatrixDisplay.from_predictions : Plot the confusion matrix\n    given the true and predicted labels.\nConfusionMatrixDisplay : Confusion Matrix visualization.\n\nReferences\n----------\n.. [1] `Wikipedia entry for the Confusion matrix\n       <https://en.wikipedia.org/wiki/Confusion_matrix>`_\n       (Wikipedia and other references may use a different\n       convention for axes).\n\nExamples\n--------\n>>> from sklearn.metrics import confusion_matrix\n>>> y_true = [2, 0, 2, 2, 0, 1]\n>>> y_pred = [0, 0, 2, 2, 0, 2]\n>>> confusion_matrix(y_true, y_pred)\narray([[2, 0, 0],\n       [0, 0, 1],\n       [1, 0, 2]])\n\n>>> y_true = [\"cat\", \"ant\", \"cat\", \"cat\", \"ant\", \"bird\"]\n>>> y_pred = [\"ant\", \"ant\", \"cat\", \"cat\", \"ant\", \"cat\"]\n>>> confusion_matrix(y_true, y_pred, labels=[\"ant\", \"bird\", \"cat\"])\narray([[2, 0, 0],\n       [0, 0, 1],\n       [1, 0, 2]])\n\nIn the binary case, we can extract true positives, etc. as follows:\n\n>>> tn, fp, fn, tp = confusion_matrix([0, 1, 0, 1], [1, 1, 1, 0]).ravel()\n>>> (tn, fp, fn, tp)\n(0, 2, 1, 1)" .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#ConsensusScoreMethod
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#ConsensusScoreMethod> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Class> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#ConsensusScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#ConsensusScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MetricsModule> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#ConsensusScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PerformanceCalculationMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#ConsensusScoreMethod> <http://www.w3.org/2000/01/rdf-schema#comment> "The similarity of two sets of biclusters.\n\nSimilarity between individual biclusters is computed. Then the\nbest matching between sets is found using the Hungarian algorithm.\nThe final score is the sum of similarities divided by the size of\nthe larger set.\n\nRead more in the :ref:`User Guide <biclustering>`.\n\nParameters\n----------\na : tuple (rows, columns)\n    Tuple of row and column indicators for a set of biclusters.\n\nb : tuple (rows, columns)\n    Another set of biclusters like ``a``.\n\nsimilarity : 'jaccard' or callable, default='jaccard'\n    May be the string \"jaccard\" to use the Jaccard coefficient, or\n    any function that takes four arguments, each of which is a 1d\n    indicator vector: (a_rows, a_columns, b_rows, b_columns).\n\nReturns\n-------\nconsensus_score : float\n   Consensus score, a non-negative value, sum of similarities\n   divided by size of larger set.\n\nReferences\n----------\n\n* Hochreiter, Bodenhofer, et. al., 2010. `FABIA: factor analysis\n  for bicluster acquisition\n  <https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2881408/>`__.\n\nExamples\n--------\n>>> from sklearn.metrics import consensus_score\n>>> a = ([[True, False], [False, True]], [[False, True], [True, False]])\n>>> b = ([[False, True], [True, False]], [[True, False], [False, True]])\n>>> consensus_score(a, b, similarity='jaccard')\n1.0" .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#CoverageErrorMethod
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#CoverageErrorMethod> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Class> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#CoverageErrorMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#CoverageErrorMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MetricsModule> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#CoverageErrorMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PerformanceCalculationMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#CoverageErrorMethod> <http://www.w3.org/2000/01/rdf-schema#comment> "Coverage error measure.\n\nCompute how far we need to go through the ranked scores to cover all\ntrue labels. The best value is equal to the average number\nof labels in ``y_true`` per sample.\n\nTies in ``y_scores`` are broken by giving maximal rank that would have\nbeen assigned to all tied values.\n\nNote: Our implementation's score is 1 greater than the one given in\nTsoumakas et al., 2010. This extends it to handle the degenerate case\nin which an instance has 0 true labels.\n\nRead more in the :ref:`User Guide <coverage_error>`.\n\nParameters\n----------\ny_true : array-like of shape (n_samples, n_labels)\n    True binary labels in binary indicator format.\n\ny_score : array-like of shape (n_samples, n_labels)\n    Target scores, can either be probability estimates of the positive\n    class, confidence values, or non-thresholded measure of decisions\n    (as returned by \"decision_function\" on some classifiers).\n\nsample_weight : array-like of shape (n_samples,), default=None\n    Sample weights.\n\nReturns\n-------\ncoverage_error : float\n    The coverage error.\n\nReferences\n----------\n.. [1] Tsoumakas, G., Katakis, I., & Vlahavas, I. (2010).\n       Mining multi-label data. In Data mining and knowledge discovery\n       handbook (pp. 667-685). Springer US.\n\nExamples\n--------\n>>> from sklearn.metrics import coverage_error\n>>> y_true = [[1, 0, 0], [0, 1, 1]]\n>>> y_score = [[1, 0, 0], [0, 1, 1]]\n>>> coverage_error(y_true, y_score)\n1.5" .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#D2AbsoluteErrorScoreMethod
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#D2AbsoluteErrorScoreMethod> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Class> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#D2AbsoluteErrorScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#D2AbsoluteErrorScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MetricsModule> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#D2AbsoluteErrorScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PerformanceCalculationMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#D2AbsoluteErrorScoreMethod> <http://www.w3.org/2000/01/rdf-schema#comment> ":math:`D^2` regression score function, fraction of absolute error explained.\n\nBest possible score is 1.0 and it can be negative (because the model can be\narbitrarily worse). A model that always uses the empirical median of `y_true`\nas constant prediction, disregarding the input features,\ngets a :math:`D^2` score of 0.0.\n\nRead more in the :ref:`User Guide <d2_score>`.\n\n.. versionadded:: 1.1\n\nParameters\n----------\ny_true : array-like of shape (n_samples,) or (n_samples, n_outputs)\n    Ground truth (correct) target values.\n\ny_pred : array-like of shape (n_samples,) or (n_samples, n_outputs)\n    Estimated target values.\n\nsample_weight : array-like of shape (n_samples,), default=None\n    Sample weights.\n\nmultioutput : {'raw_values', 'uniform_average'} or array-like of shape             (n_outputs,), default='uniform_average'\n    Defines aggregating of multiple output values.\n    Array-like value defines weights used to average scores.\n\n    'raw_values' :\n        Returns a full set of errors in case of multioutput input.\n\n    'uniform_average' :\n        Scores of all outputs are averaged with uniform weight.\n\nReturns\n-------\nscore : float or ndarray of floats\n    The :math:`D^2` score with an absolute error deviance\n    or ndarray of scores if 'multioutput' is 'raw_values'.\n\nNotes\n-----\nLike :math:`R^2`, :math:`D^2` score may be negative\n(it need not actually be the square of a quantity D).\n\nThis metric is not well-defined for single samples and will return a NaN\nvalue if n_samples is less than two.\n\n References\n----------\n.. [1] Eq. (3.11) of Hastie, Trevor J., Robert Tibshirani and Martin J.\n       Wainwright. \"Statistical Learning with Sparsity: The Lasso and\n       Generalizations.\" (2015). https://hastie.su.domains/StatLearnSparsity/\n\nExamples\n--------\n>>> from sklearn.metrics import d2_absolute_error_score\n>>> y_true = [3, -0.5, 2, 7]\n>>> y_pred = [2.5, 0.0, 2, 8]\n>>> d2_absolute_error_score(y_true, y_pred)\n0.764...\n>>> y_true = [[0.5, 1], [-1, 1], [7, -6]]\n>>> y_pred = [[0, 2], [-1, 2], [8, -5]]\n>>> d2_absolute_error_score(y_true, y_pred, multioutput='uniform_average')\n0.691...\n>>> d2_absolute_error_score(y_true, y_pred, multioutput='raw_values')\narray([0.8125    , 0.57142857])\n>>> y_true = [1, 2, 3]\n>>> y_pred = [1, 2, 3]\n>>> d2_absolute_error_score(y_true, y_pred)\n1.0\n>>> y_true = [1, 2, 3]\n>>> y_pred = [2, 2, 2]\n>>> d2_absolute_error_score(y_true, y_pred)\n0.0\n>>> y_true = [1, 2, 3]\n>>> y_pred = [3, 2, 1]\n>>> d2_absolute_error_score(y_true, y_pred)\n-1.0" .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#D2PinballScoreMethod
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#D2PinballScoreMethod> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Class> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#D2PinballScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#D2PinballScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MetricsModule> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#D2PinballScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PerformanceCalculationMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#D2PinballScoreMethod> <http://www.w3.org/2000/01/rdf-schema#comment> ":math:`D^2` regression score function, fraction of pinball loss explained.\n\nBest possible score is 1.0 and it can be negative (because the model can be\narbitrarily worse). A model that always uses the empirical alpha-quantile of\n`y_true` as constant prediction, disregarding the input features,\ngets a :math:`D^2` score of 0.0.\n\nRead more in the :ref:`User Guide <d2_score>`.\n\n.. versionadded:: 1.1\n\nParameters\n----------\ny_true : array-like of shape (n_samples,) or (n_samples, n_outputs)\n    Ground truth (correct) target values.\n\ny_pred : array-like of shape (n_samples,) or (n_samples, n_outputs)\n    Estimated target values.\n\nsample_weight : array-like of shape (n_samples,), default=None\n    Sample weights.\n\nalpha : float, default=0.5\n    Slope of the pinball deviance. It determines the quantile level alpha\n    for which the pinball deviance and also D2 are optimal.\n    The default `alpha=0.5` is equivalent to `d2_absolute_error_score`.\n\nmultioutput : {'raw_values', 'uniform_average'} or array-like of shape             (n_outputs,), default='uniform_average'\n    Defines aggregating of multiple output values.\n    Array-like value defines weights used to average scores.\n\n    'raw_values' :\n        Returns a full set of errors in case of multioutput input.\n\n    'uniform_average' :\n        Scores of all outputs are averaged with uniform weight.\n\nReturns\n-------\nscore : float or ndarray of floats\n    The :math:`D^2` score with a pinball deviance\n    or ndarray of scores if `multioutput='raw_values'`.\n\nNotes\n-----\nLike :math:`R^2`, :math:`D^2` score may be negative\n(it need not actually be the square of a quantity D).\n\nThis metric is not well-defined for a single point and will return a NaN\nvalue if n_samples is less than two.\n\n References\n----------\n.. [1] Eq. (7) of `Koenker, Roger; Machado, Jos A. F. (1999).\n       \"Goodness of Fit and Related Inference Processes for Quantile Regression\"\n       <https://doi.org/10.1080/01621459.1999.10473882>`_\n.. [2] Eq. (3.11) of Hastie, Trevor J., Robert Tibshirani and Martin J.\n       Wainwright. \"Statistical Learning with Sparsity: The Lasso and\n       Generalizations.\" (2015). https://hastie.su.domains/StatLearnSparsity/\n\nExamples\n--------\n>>> from sklearn.metrics import d2_pinball_score\n>>> y_true = [1, 2, 3]\n>>> y_pred = [1, 3, 3]\n>>> d2_pinball_score(y_true, y_pred)\n0.5\n>>> d2_pinball_score(y_true, y_pred, alpha=0.9)\n0.772...\n>>> d2_pinball_score(y_true, y_pred, alpha=0.1)\n-1.045...\n>>> d2_pinball_score(y_true, y_true, alpha=0.1)\n1.0" .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#D2TweedieScoreMethod
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#D2TweedieScoreMethod> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Class> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#D2TweedieScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#D2TweedieScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MetricsModule> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#D2TweedieScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PerformanceCalculationMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#D2TweedieScoreMethod> <http://www.w3.org/2000/01/rdf-schema#comment> ":math:`D^2` regression score function, fraction of Tweedie deviance explained.\n\nBest possible score is 1.0 and it can be negative (because the model can be\narbitrarily worse). A model that always uses the empirical mean of `y_true` as\nconstant prediction, disregarding the input features, gets a D^2 score of 0.0.\n\nRead more in the :ref:`User Guide <d2_score>`.\n\n.. versionadded:: 1.0\n\nParameters\n----------\ny_true : array-like of shape (n_samples,)\n    Ground truth (correct) target values.\n\ny_pred : array-like of shape (n_samples,)\n    Estimated target values.\n\nsample_weight : array-like of shape (n_samples,), default=None\n    Sample weights.\n\npower : float, default=0\n    Tweedie power parameter. Either power <= 0 or power >= 1.\n\n    The higher `p` the less weight is given to extreme\n    deviations between true and predicted targets.\n\n    - power < 0: Extreme stable distribution. Requires: y_pred > 0.\n    - power = 0 : Normal distribution, output corresponds to r2_score.\n      y_true and y_pred can be any real numbers.\n    - power = 1 : Poisson distribution. Requires: y_true >= 0 and\n      y_pred > 0.\n    - 1 < p < 2 : Compound Poisson distribution. Requires: y_true >= 0\n      and y_pred > 0.\n    - power = 2 : Gamma distribution. Requires: y_true > 0 and y_pred > 0.\n    - power = 3 : Inverse Gaussian distribution. Requires: y_true > 0\n      and y_pred > 0.\n    - otherwise : Positive stable distribution. Requires: y_true > 0\n      and y_pred > 0.\n\nReturns\n-------\nz : float or ndarray of floats\n    The D^2 score.\n\nNotes\n-----\nThis is not a symmetric function.\n\nLike R^2, D^2 score may be negative (it need not actually be the square of\na quantity D).\n\nThis metric is not well-defined for single samples and will return a NaN\nvalue if n_samples is less than two.\n\nReferences\n----------\n.. [1] Eq. (3.11) of Hastie, Trevor J., Robert Tibshirani and Martin J.\n       Wainwright. \"Statistical Learning with Sparsity: The Lasso and\n       Generalizations.\" (2015). https://hastie.su.domains/StatLearnSparsity/\n\nExamples\n--------\n>>> from sklearn.metrics import d2_tweedie_score\n>>> y_true = [0.5, 1, 2.5, 7]\n>>> y_pred = [1, 1, 5, 3.5]\n>>> d2_tweedie_score(y_true, y_pred)\n0.285...\n>>> d2_tweedie_score(y_true, y_pred, power=1)\n0.487...\n>>> d2_tweedie_score(y_true, y_pred, power=2)\n0.630...\n>>> d2_tweedie_score(y_true, y_true, power=2)\n1.0" .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#DaviesBouldinScoreMethod
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#DaviesBouldinScoreMethod> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Class> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#DaviesBouldinScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#DaviesBouldinScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MetricsModule> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#DaviesBouldinScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PerformanceCalculationMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#DaviesBouldinScoreMethod> <http://www.w3.org/2000/01/rdf-schema#comment> "Compute the Davies-Bouldin score.\n\nThe score is defined as the average similarity measure of each cluster with\nits most similar cluster, where similarity is the ratio of within-cluster\ndistances to between-cluster distances. Thus, clusters which are farther\napart and less dispersed will result in a better score.\n\nThe minimum score is zero, with lower values indicating better clustering.\n\nRead more in the :ref:`User Guide <davies-bouldin_index>`.\n\n.. versionadded:: 0.20\n\nParameters\n----------\nX : array-like of shape (n_samples, n_features)\n    A list of ``n_features``-dimensional data points. Each row corresponds\n    to a single data point.\n\nlabels : array-like of shape (n_samples,)\n    Predicted labels for each sample.\n\nReturns\n-------\nscore: float\n    The resulting Davies-Bouldin score.\n\nReferences\n----------\n.. [1] Davies, David L.; Bouldin, Donald W. (1979).\n   `\"A Cluster Separation Measure\"\n   <https://ieeexplore.ieee.org/document/4766909>`__.\n   IEEE Transactions on Pattern Analysis and Machine Intelligence.\n   PAMI-1 (2): 224-227\n\nExamples\n--------\n>>> from sklearn.metrics import davies_bouldin_score\n>>> X = [[0, 1], [1, 1], [3, 4]]\n>>> labels = [0, 0, 1]\n>>> davies_bouldin_score(X, labels)\n0.12..." .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#DcgScoreMethod
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#DcgScoreMethod> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Class> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#DcgScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#DcgScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MetricsModule> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#DcgScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PerformanceCalculationMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#DcgScoreMethod> <http://www.w3.org/2000/01/rdf-schema#comment> "Compute Discounted Cumulative Gain.\n\nSum the true scores ranked in the order induced by the predicted scores,\nafter applying a logarithmic discount.\n\nThis ranking metric yields a high value if true labels are ranked high by\n``y_score``.\n\nUsually the Normalized Discounted Cumulative Gain (NDCG, computed by\nndcg_score) is preferred.\n\nParameters\n----------\ny_true : array-like of shape (n_samples, n_labels)\n    True targets of multilabel classification, or true scores of entities\n    to be ranked.\n\ny_score : array-like of shape (n_samples, n_labels)\n    Target scores, can either be probability estimates, confidence values,\n    or non-thresholded measure of decisions (as returned by\n    \"decision_function\" on some classifiers).\n\nk : int, default=None\n    Only consider the highest k scores in the ranking. If None, use all\n    outputs.\n\nlog_base : float, default=2\n    Base of the logarithm used for the discount. A low value means a\n    sharper discount (top results are more important).\n\nsample_weight : array-like of shape (n_samples,), default=None\n    Sample weights. If `None`, all samples are given the same weight.\n\nignore_ties : bool, default=False\n    Assume that there are no ties in y_score (which is likely to be the\n    case if y_score is continuous) for efficiency gains.\n\nReturns\n-------\ndiscounted_cumulative_gain : float\n    The averaged sample DCG scores.\n\nSee Also\n--------\nndcg_score : The Discounted Cumulative Gain divided by the Ideal Discounted\n    Cumulative Gain (the DCG obtained for a perfect ranking), in order to\n    have a score between 0 and 1.\n\nReferences\n----------\n`Wikipedia entry for Discounted Cumulative Gain\n<https://en.wikipedia.org/wiki/Discounted_cumulative_gain>`_.\n\nJarvelin, K., & Kekalainen, J. (2002).\nCumulated gain-based evaluation of IR techniques. ACM Transactions on\nInformation Systems (TOIS), 20(4), 422-446.\n\nWang, Y., Wang, L., Li, Y., He, D., Chen, W., & Liu, T. Y. (2013, May).\nA theoretical analysis of NDCG ranking measures. In Proceedings of the 26th\nAnnual Conference on Learning Theory (COLT 2013).\n\nMcSherry, F., & Najork, M. (2008, March). Computing information retrieval\nperformance measures efficiently in the presence of tied scores. In\nEuropean conference on information retrieval (pp. 414-421). Springer,\nBerlin, Heidelberg.\n\nExamples\n--------\n>>> import numpy as np\n>>> from sklearn.metrics import dcg_score\n>>> # we have groud-truth relevance of some answers to a query:\n>>> true_relevance = np.asarray([[10, 0, 0, 1, 5]])\n>>> # we predict scores for the answers\n>>> scores = np.asarray([[.1, .2, .3, 4, 70]])\n>>> dcg_score(true_relevance, scores)\n9.49...\n>>> # we can set k to truncate the sum; only top k answers contribute\n>>> dcg_score(true_relevance, scores, k=2)\n5.63...\n>>> # now we have some ties in our prediction\n>>> scores = np.asarray([[1, 0, 0, 0, 1]])\n>>> # by default ties are averaged, so here we get the average true\n>>> # relevance of our top predictions: (10 + 5) / 2 = 7.5\n>>> dcg_score(true_relevance, scores, k=1)\n7.5\n>>> # we can choose to ignore ties for faster results, but only\n>>> # if we know there aren't ties in our scores, otherwise we get\n>>> # wrong results:\n>>> dcg_score(true_relevance,\n...           scores, k=1, ignore_ties=True)\n5.0" .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#DetCurveMethod
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#DetCurveMethod> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Class> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#DetCurveMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#DetCurveMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MetricsModule> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#DetCurveMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PerformanceCalculationMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#DetCurveMethod> <http://www.w3.org/2000/01/rdf-schema#comment> "Compute error rates for different probability thresholds.\n\n.. note::\n   This metric is used for evaluation of ranking and error tradeoffs of\n   a binary classification task.\n\nRead more in the :ref:`User Guide <det_curve>`.\n\n.. versionadded:: 0.24\n\nParameters\n----------\ny_true : ndarray of shape (n_samples,)\n    True binary labels. If labels are not either {-1, 1} or {0, 1}, then\n    pos_label should be explicitly given.\n\ny_score : ndarray of shape of (n_samples,)\n    Target scores, can either be probability estimates of the positive\n    class, confidence values, or non-thresholded measure of decisions\n    (as returned by \"decision_function\" on some classifiers).\n\npos_label : int, float, bool or str, default=None\n    The label of the positive class.\n    When ``pos_label=None``, if `y_true` is in {-1, 1} or {0, 1},\n    ``pos_label`` is set to 1, otherwise an error will be raised.\n\nsample_weight : array-like of shape (n_samples,), default=None\n    Sample weights.\n\nReturns\n-------\nfpr : ndarray of shape (n_thresholds,)\n    False positive rate (FPR) such that element i is the false positive\n    rate of predictions with score >= thresholds[i]. This is occasionally\n    referred to as false acceptance probability or fall-out.\n\nfnr : ndarray of shape (n_thresholds,)\n    False negative rate (FNR) such that element i is the false negative\n    rate of predictions with score >= thresholds[i]. This is occasionally\n    referred to as false rejection or miss rate.\n\nthresholds : ndarray of shape (n_thresholds,)\n    Decreasing score values.\n\nSee Also\n--------\nDetCurveDisplay.from_estimator : Plot DET curve given an estimator and\n    some data.\nDetCurveDisplay.from_predictions : Plot DET curve given the true and\n    predicted labels.\nDetCurveDisplay : DET curve visualization.\nroc_curve : Compute Receiver operating characteristic (ROC) curve.\nprecision_recall_curve : Compute precision-recall curve.\n\nExamples\n--------\n>>> import numpy as np\n>>> from sklearn.metrics import det_curve\n>>> y_true = np.array([0, 0, 1, 1])\n>>> y_scores = np.array([0.1, 0.4, 0.35, 0.8])\n>>> fpr, fnr, thresholds = det_curve(y_true, y_scores)\n>>> fpr\narray([0.5, 0.5, 0. ])\n>>> fnr\narray([0. , 0.5, 0.5])\n>>> thresholds\narray([0.35, 0.4 , 0.8 ])" .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#EuclideanDistancesMethod
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#EuclideanDistancesMethod> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Class> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#EuclideanDistancesMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#EuclideanDistancesMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MetricsModule> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#EuclideanDistancesMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PerformanceCalculationMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#EuclideanDistancesMethod> <http://www.w3.org/2000/01/rdf-schema#comment> "Compute the distance matrix between each pair from a vector array X and Y.\n\nFor efficiency reasons, the euclidean distance between a pair of row\nvector x and y is computed as::\n\n    dist(x, y) = sqrt(dot(x, x) - 2 * dot(x, y) + dot(y, y))\n\nThis formulation has two advantages over other ways of computing distances.\nFirst, it is computationally efficient when dealing with sparse data.\nSecond, if one argument varies but the other remains unchanged, then\n`dot(x, x)` and/or `dot(y, y)` can be pre-computed.\n\nHowever, this is not the most precise way of doing this computation,\nbecause this equation potentially suffers from \"catastrophic cancellation\".\nAlso, the distance matrix returned by this function may not be exactly\nsymmetric as required by, e.g., ``scipy.spatial.distance`` functions.\n\nRead more in the :ref:`User Guide <metrics>`.\n\nParameters\n----------\nX : {array-like, sparse matrix} of shape (n_samples_X, n_features)\n    An array where each row is a sample and each column is a feature.\n\nY : {array-like, sparse matrix} of shape (n_samples_Y, n_features),             default=None\n    An array where each row is a sample and each column is a feature.\n    If `None`, method uses `Y=X`.\n\nY_norm_squared : array-like of shape (n_samples_Y,) or (n_samples_Y, 1)             or (1, n_samples_Y), default=None\n    Pre-computed dot-products of vectors in Y (e.g.,\n    ``(Y**2).sum(axis=1)``)\n    May be ignored in some cases, see the note below.\n\nsquared : bool, default=False\n    Return squared Euclidean distances.\n\nX_norm_squared : array-like of shape (n_samples_X,) or (n_samples_X, 1)             or (1, n_samples_X), default=None\n    Pre-computed dot-products of vectors in X (e.g.,\n    ``(X**2).sum(axis=1)``)\n    May be ignored in some cases, see the note below.\n\nReturns\n-------\ndistances : ndarray of shape (n_samples_X, n_samples_Y)\n    Returns the distances between the row vectors of `X`\n    and the row vectors of `Y`.\n\nSee Also\n--------\npaired_distances : Distances between pairs of elements of X and Y.\n\nNotes\n-----\nTo achieve a better accuracy, `X_norm_squared`and `Y_norm_squared` may be\nunused if they are passed as `np.float32`.\n\nExamples\n--------\n>>> from sklearn.metrics.pairwise import euclidean_distances\n>>> X = [[0, 1], [1, 1]]\n>>> # distance between rows of X\n>>> euclidean_distances(X, X)\narray([[0., 1.],\n       [1., 0.]])\n>>> # get distance to origin\n>>> euclidean_distances(X, [[0, 0]])\narray([[1.        ],\n       [1.41421356]])" .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#ExplainedVarianceScoreMethod
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#ExplainedVarianceScoreMethod> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Class> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#ExplainedVarianceScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#ExplainedVarianceScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MetricsModule> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#ExplainedVarianceScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PerformanceCalculationMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#ExplainedVarianceScoreMethod> <http://www.w3.org/2000/01/rdf-schema#comment> "Explained variance regression score function.\n\nBest possible score is 1.0, lower values are worse.\n\nIn the particular case when ``y_true`` is constant, the explained variance\nscore is not finite: it is either ``NaN`` (perfect predictions) or\n``-Inf`` (imperfect predictions). To prevent such non-finite numbers to\npollute higher-level experiments such as a grid search cross-validation,\nby default these cases are replaced with 1.0 (perfect predictions) or 0.0\n(imperfect predictions) respectively. If ``force_finite``\nis set to ``False``, this score falls back on the original :math:`R^2`\ndefinition.\n\n.. note::\n   The Explained Variance score is similar to the\n   :func:`R^2 score <r2_score>`, with the notable difference that it\n   does not account for systematic offsets in the prediction. Most often\n   the :func:`R^2 score <r2_score>` should be preferred.\n\nRead more in the :ref:`User Guide <explained_variance_score>`.\n\nParameters\n----------\ny_true : array-like of shape (n_samples,) or (n_samples, n_outputs)\n    Ground truth (correct) target values.\n\ny_pred : array-like of shape (n_samples,) or (n_samples, n_outputs)\n    Estimated target values.\n\nsample_weight : array-like of shape (n_samples,), default=None\n    Sample weights.\n\nmultioutput : {'raw_values', 'uniform_average', 'variance_weighted'} or             array-like of shape (n_outputs,), default='uniform_average'\n    Defines aggregating of multiple output scores.\n    Array-like value defines weights used to average scores.\n\n    'raw_values' :\n        Returns a full set of scores in case of multioutput input.\n\n    'uniform_average' :\n        Scores of all outputs are averaged with uniform weight.\n\n    'variance_weighted' :\n        Scores of all outputs are averaged, weighted by the variances\n        of each individual output.\n\nforce_finite : bool, default=True\n    Flag indicating if ``NaN`` and ``-Inf`` scores resulting from constant\n    data should be replaced with real numbers (``1.0`` if prediction is\n    perfect, ``0.0`` otherwise). Default is ``True``, a convenient setting\n    for hyperparameters' search procedures (e.g. grid search\n    cross-validation).\n\n    .. versionadded:: 1.1\n\nReturns\n-------\nscore : float or ndarray of floats\n    The explained variance or ndarray if 'multioutput' is 'raw_values'.\n\nSee Also\n--------\nr2_score :\n    Similar metric, but accounting for systematic offsets in\n    prediction.\n\nNotes\n-----\nThis is not a symmetric function.\n\nExamples\n--------\n>>> from sklearn.metrics import explained_variance_score\n>>> y_true = [3, -0.5, 2, 7]\n>>> y_pred = [2.5, 0.0, 2, 8]\n>>> explained_variance_score(y_true, y_pred)\n0.957...\n>>> y_true = [[0.5, 1], [-1, 1], [7, -6]]\n>>> y_pred = [[0, 2], [-1, 2], [8, -5]]\n>>> explained_variance_score(y_true, y_pred, multioutput='uniform_average')\n0.983...\n>>> y_true = [-2, -2, -2]\n>>> y_pred = [-2, -2, -2]\n>>> explained_variance_score(y_true, y_pred)\n1.0\n>>> explained_variance_score(y_true, y_pred, force_finite=False)\nnan\n>>> y_true = [-2, -2, -2]\n>>> y_pred = [-2, -2, -2 + 1e-8]\n>>> explained_variance_score(y_true, y_pred)\n0.0\n>>> explained_variance_score(y_true, y_pred, force_finite=False)\n-inf" .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#F1ScoreMethod
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#F1ScoreMethod> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Class> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#F1ScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#F1ScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MetricsModule> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#F1ScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PerformanceCalculationMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#F1ScoreMethod> <http://www.w3.org/2000/01/rdf-schema#comment> "Compute the F1 score, also known as balanced F-score or F-measure.\n\nThe F1 score can be interpreted as a harmonic mean of the precision and\nrecall, where an F1 score reaches its best value at 1 and worst score at 0.\nThe relative contribution of precision and recall to the F1 score are\nequal. The formula for the F1 score is:\n\n.. math::\n    \\text{F1} = \\frac{2 * \\text{TP}}{2 * \\text{TP} + \\text{FP} + \\text{FN}}\n\nWhere :math:`\\text{TP}` is the number of true positives, :math:`\\text{FN}` is the\nnumber of false negatives, and :math:`\\text{FP}` is the number of false positives.\nF1 is by default\ncalculated as 0.0 when there are no true positives, false negatives, or\nfalse positives.\n\nSupport beyond :term:`binary` targets is achieved by treating :term:`multiclass`\nand :term:`multilabel` data as a collection of binary problems, one for each\nlabel. For the :term:`binary` case, setting `average='binary'` will return\nF1 score for `pos_label`. If `average` is not `'binary'`, `pos_label` is ignored\nand F1 score for both classes are computed, then averaged or both returned (when\n`average=None`). Similarly, for :term:`multiclass` and :term:`multilabel` targets,\nF1 score for all `labels` are either returned or averaged depending on the\n`average` parameter. Use `labels` specify the set of labels to calculate F1 score\nfor.\n\nRead more in the :ref:`User Guide <precision_recall_f_measure_metrics>`.\n\nParameters\n----------\ny_true : 1d array-like, or label indicator array / sparse matrix\n    Ground truth (correct) target values.\n\ny_pred : 1d array-like, or label indicator array / sparse matrix\n    Estimated targets as returned by a classifier.\n\nlabels : array-like, default=None\n    The set of labels to include when `average != 'binary'`, and their\n    order if `average is None`. Labels present in the data can be\n    excluded, for example in multiclass classification to exclude a \"negative\n    class\". Labels not present in the data can be included and will be\n    \"assigned\" 0 samples. For multilabel targets, labels are column indices.\n    By default, all labels in `y_true` and `y_pred` are used in sorted order.\n\n    .. versionchanged:: 0.17\n       Parameter `labels` improved for multiclass problem.\n\npos_label : int, float, bool or str, default=1\n    The class to report if `average='binary'` and the data is binary,\n    otherwise this parameter is ignored.\n    For multiclass or multilabel targets, set `labels=[pos_label]` and\n    `average != 'binary'` to report metrics for one label only.\n\naverage : {'micro', 'macro', 'samples', 'weighted', 'binary'} or None,             default='binary'\n    This parameter is required for multiclass/multilabel targets.\n    If ``None``, the scores for each class are returned. Otherwise, this\n    determines the type of averaging performed on the data:\n\n    ``'binary'``:\n        Only report results for the class specified by ``pos_label``.\n        This is applicable only if targets (``y_{true,pred}``) are binary.\n    ``'micro'``:\n        Calculate metrics globally by counting the total true positives,\n        false negatives and false positives.\n    ``'macro'``:\n        Calculate metrics for each label, and find their unweighted\n        mean.  This does not take label imbalance into account.\n    ``'weighted'``:\n        Calculate metrics for each label, and find their average weighted\n        by support (the number of true instances for each label). This\n        alters 'macro' to account for label imbalance; it can result in an\n        F-score that is not between precision and recall.\n    ``'samples'``:\n        Calculate metrics for each instance, and find their average (only\n        meaningful for multilabel classification where this differs from\n        :func:`accuracy_score`).\n\nsample_weight : array-like of shape (n_samples,), default=None\n    Sample weights.\n\nzero_division : {\"warn\", 0.0, 1.0, np.nan}, default=\"warn\"\n    Sets the value to return when there is a zero division, i.e. when all\n    predictions and labels are negative.\n\n    Notes:\n    - If set to \"warn\", this acts like 0, but a warning is also raised.\n    - If set to `np.nan`, such values will be excluded from the average.\n\n    .. versionadded:: 1.3\n       `np.nan` option was added.\n\nReturns\n-------\nf1_score : float or array of float, shape = [n_unique_labels]\n    F1 score of the positive class in binary classification or weighted\n    average of the F1 scores of each class for the multiclass task.\n\nSee Also\n--------\nfbeta_score : Compute the F-beta score.\nprecision_recall_fscore_support : Compute the precision, recall, F-score,\n    and support.\njaccard_score : Compute the Jaccard similarity coefficient score.\nmultilabel_confusion_matrix : Compute a confusion matrix for each class or\n    sample.\n\nNotes\n-----\nWhen ``true positive + false positive + false negative == 0`` (i.e. a class\nis completely absent from both ``y_true`` or ``y_pred``), f-score is\nundefined. In such cases, by default f-score will be set to 0.0, and\n``UndefinedMetricWarning`` will be raised. This behavior can be modified by\nsetting the ``zero_division`` parameter.\n\nReferences\n----------\n.. [1] `Wikipedia entry for the F1-score\n       <https://en.wikipedia.org/wiki/F1_score>`_.\n\nExamples\n--------\n>>> import numpy as np\n>>> from sklearn.metrics import f1_score\n>>> y_true = [0, 1, 2, 0, 1, 2]\n>>> y_pred = [0, 2, 1, 0, 0, 1]\n>>> f1_score(y_true, y_pred, average='macro')\n0.26...\n>>> f1_score(y_true, y_pred, average='micro')\n0.33...\n>>> f1_score(y_true, y_pred, average='weighted')\n0.26...\n>>> f1_score(y_true, y_pred, average=None)\narray([0.8, 0. , 0. ])\n\n>>> # binary classification\n>>> y_true_empty = [0, 0, 0, 0, 0, 0]\n>>> y_pred_empty = [0, 0, 0, 0, 0, 0]\n>>> f1_score(y_true_empty, y_pred_empty)\n0.0...\n>>> f1_score(y_true_empty, y_pred_empty, zero_division=1.0)\n1.0...\n>>> f1_score(y_true_empty, y_pred_empty, zero_division=np.nan)\nnan...\n\n>>> # multilabel classification\n>>> y_true = [[0, 0, 0], [1, 1, 1], [0, 1, 1]]\n>>> y_pred = [[0, 0, 0], [1, 1, 1], [1, 1, 0]]\n>>> f1_score(y_true, y_pred, average=None)\narray([0.66666667, 1.        , 0.66666667])" .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#FbetaScoreMethod
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#FbetaScoreMethod> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Class> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#FbetaScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#FbetaScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MetricsModule> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#FbetaScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PerformanceCalculationMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#FbetaScoreMethod> <http://www.w3.org/2000/01/rdf-schema#comment> "Compute the F-beta score.\n\nThe F-beta score is the weighted harmonic mean of precision and recall,\nreaching its optimal value at 1 and its worst value at 0.\n\nThe `beta` parameter represents the ratio of recall importance to\nprecision importance. `beta > 1` gives more weight to recall, while\n`beta < 1` favors precision. For example, `beta = 2` makes recall twice\nas important as precision, while `beta = 0.5` does the opposite.\nAsymptotically, `beta -> +inf` considers only recall, and `beta -> 0`\nonly precision.\n\nThe formula for F-beta score is:\n\n.. math::\n\n   F_\\beta = \\frac{(1 + \\beta^2) \\text{tp}}\n                    {(1 + \\beta^2) \\text{tp} + \\text{fp} + \\beta^2 \\text{fn}}\n\nWhere :math:`\\text{tp}` is the number of true positives, :math:`\\text{fp}` is the\nnumber of false positives, and :math:`\\text{fn}` is the number of false negatives.\n\nSupport beyond term:`binary` targets is achieved by treating :term:`multiclass`\nand :term:`multilabel` data as a collection of binary problems, one for each\nlabel. For the :term:`binary` case, setting `average='binary'` will return\nF-beta score for `pos_label`. If `average` is not `'binary'`, `pos_label` is\nignored and F-beta score for both classes are computed, then averaged or both\nreturned (when `average=None`). Similarly, for :term:`multiclass` and\n:term:`multilabel` targets, F-beta score for all `labels` are either returned or\naveraged depending on the `average` parameter. Use `labels` specify the set of\nlabels to calculate F-beta score for.\n\nRead more in the :ref:`User Guide <precision_recall_f_measure_metrics>`.\n\nParameters\n----------\ny_true : 1d array-like, or label indicator array / sparse matrix\n    Ground truth (correct) target values.\n\ny_pred : 1d array-like, or label indicator array / sparse matrix\n    Estimated targets as returned by a classifier.\n\nbeta : float\n    Determines the weight of recall in the combined score.\n\nlabels : array-like, default=None\n    The set of labels to include when `average != 'binary'`, and their\n    order if `average is None`. Labels present in the data can be\n    excluded, for example in multiclass classification to exclude a \"negative\n    class\". Labels not present in the data can be included and will be\n    \"assigned\" 0 samples. For multilabel targets, labels are column indices.\n    By default, all labels in `y_true` and `y_pred` are used in sorted order.\n\n    .. versionchanged:: 0.17\n       Parameter `labels` improved for multiclass problem.\n\npos_label : int, float, bool or str, default=1\n    The class to report if `average='binary'` and the data is binary,\n    otherwise this parameter is ignored.\n    For multiclass or multilabel targets, set `labels=[pos_label]` and\n    `average != 'binary'` to report metrics for one label only.\n\naverage : {'micro', 'macro', 'samples', 'weighted', 'binary'} or None,             default='binary'\n    This parameter is required for multiclass/multilabel targets.\n    If ``None``, the scores for each class are returned. Otherwise, this\n    determines the type of averaging performed on the data:\n\n    ``'binary'``:\n        Only report results for the class specified by ``pos_label``.\n        This is applicable only if targets (``y_{true,pred}``) are binary.\n    ``'micro'``:\n        Calculate metrics globally by counting the total true positives,\n        false negatives and false positives.\n    ``'macro'``:\n        Calculate metrics for each label, and find their unweighted\n        mean.  This does not take label imbalance into account.\n    ``'weighted'``:\n        Calculate metrics for each label, and find their average weighted\n        by support (the number of true instances for each label). This\n        alters 'macro' to account for label imbalance; it can result in an\n        F-score that is not between precision and recall.\n    ``'samples'``:\n        Calculate metrics for each instance, and find their average (only\n        meaningful for multilabel classification where this differs from\n        :func:`accuracy_score`).\n\nsample_weight : array-like of shape (n_samples,), default=None\n    Sample weights.\n\nzero_division : {\"warn\", 0.0, 1.0, np.nan}, default=\"warn\"\n    Sets the value to return when there is a zero division, i.e. when all\n    predictions and labels are negative.\n\n    Notes:\n    - If set to \"warn\", this acts like 0, but a warning is also raised.\n    - If set to `np.nan`, such values will be excluded from the average.\n\n    .. versionadded:: 1.3\n       `np.nan` option was added.\n\nReturns\n-------\nfbeta_score : float (if average is not None) or array of float, shape =        [n_unique_labels]\n    F-beta score of the positive class in binary classification or weighted\n    average of the F-beta score of each class for the multiclass task.\n\nSee Also\n--------\nprecision_recall_fscore_support : Compute the precision, recall, F-score,\n    and support.\nmultilabel_confusion_matrix : Compute a confusion matrix for each class or\n    sample.\n\nNotes\n-----\nWhen ``true positive + false positive + false negative == 0``, f-score\nreturns 0.0 and raises ``UndefinedMetricWarning``. This behavior can be\nmodified by setting ``zero_division``.\n\nReferences\n----------\n.. [1] R. Baeza-Yates and B. Ribeiro-Neto (2011).\n       Modern Information Retrieval. Addison Wesley, pp. 327-328.\n\n.. [2] `Wikipedia entry for the F1-score\n       <https://en.wikipedia.org/wiki/F1_score>`_.\n\nExamples\n--------\n>>> import numpy as np\n>>> from sklearn.metrics import fbeta_score\n>>> y_true = [0, 1, 2, 0, 1, 2]\n>>> y_pred = [0, 2, 1, 0, 0, 1]\n>>> fbeta_score(y_true, y_pred, average='macro', beta=0.5)\n0.23...\n>>> fbeta_score(y_true, y_pred, average='micro', beta=0.5)\n0.33...\n>>> fbeta_score(y_true, y_pred, average='weighted', beta=0.5)\n0.23...\n>>> fbeta_score(y_true, y_pred, average=None, beta=0.5)\narray([0.71..., 0.        , 0.        ])\n>>> y_pred_empty = [0, 0, 0, 0, 0, 0]\n>>> fbeta_score(y_true, y_pred_empty,\n...             average=\"macro\", zero_division=np.nan, beta=0.5)\n0.12..." .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#FowlkesMallowsScoreMethod
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#FowlkesMallowsScoreMethod> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Class> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#FowlkesMallowsScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#FowlkesMallowsScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MetricsModule> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#FowlkesMallowsScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PerformanceCalculationMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#FowlkesMallowsScoreMethod> <http://www.w3.org/2000/01/rdf-schema#comment> "Measure the similarity of two clusterings of a set of points.\n\n.. versionadded:: 0.18\n\nThe Fowlkes-Mallows index (FMI) is defined as the geometric mean between of\nthe precision and recall::\n\n    FMI = TP / sqrt((TP + FP) * (TP + FN))\n\nWhere ``TP`` is the number of **True Positive** (i.e. the number of pair of\npoints that belongs in the same clusters in both ``labels_true`` and\n``labels_pred``), ``FP`` is the number of **False Positive** (i.e. the\nnumber of pair of points that belongs in the same clusters in\n``labels_true`` and not in ``labels_pred``) and ``FN`` is the number of\n**False Negative** (i.e. the number of pair of points that belongs in the\nsame clusters in ``labels_pred`` and not in ``labels_True``).\n\nThe score ranges from 0 to 1. A high value indicates a good similarity\nbetween two clusters.\n\nRead more in the :ref:`User Guide <fowlkes_mallows_scores>`.\n\nParameters\n----------\nlabels_true : array-like of shape (n_samples,), dtype=int\n    A clustering of the data into disjoint subsets.\n\nlabels_pred : array-like of shape (n_samples,), dtype=int\n    A clustering of the data into disjoint subsets.\n\nsparse : bool, default=False\n    Compute contingency matrix internally with sparse matrix.\n\nReturns\n-------\nscore : float\n   The resulting Fowlkes-Mallows score.\n\nReferences\n----------\n.. [1] `E. B. Fowkles and C. L. Mallows, 1983. \"A method for comparing two\n   hierarchical clusterings\". Journal of the American Statistical\n   Association\n   <https://www.tandfonline.com/doi/abs/10.1080/01621459.1983.10478008>`_\n\n.. [2] `Wikipedia entry for the Fowlkes-Mallows Index\n       <https://en.wikipedia.org/wiki/Fowlkes-Mallows_index>`_\n\nExamples\n--------\n\nPerfect labelings are both homogeneous and complete, hence have\nscore 1.0::\n\n  >>> from sklearn.metrics.cluster import fowlkes_mallows_score\n  >>> fowlkes_mallows_score([0, 0, 1, 1], [0, 0, 1, 1])\n  1.0\n  >>> fowlkes_mallows_score([0, 0, 1, 1], [1, 1, 0, 0])\n  1.0\n\nIf classes members are completely split across different clusters,\nthe assignment is totally random, hence the FMI is null::\n\n  >>> fowlkes_mallows_score([0, 0, 0, 0], [0, 1, 2, 3])\n  0.0" .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#GetScorerMethod
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#GetScorerMethod> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Class> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#GetScorerMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#GetScorerMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MetricsModule> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#GetScorerMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PerformanceCalculationMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#GetScorerMethod> <http://www.w3.org/2000/01/rdf-schema#comment> "Get a scorer from string.\n\nRead more in the :ref:`User Guide <scoring_parameter>`.\n:func:`~sklearn.metrics.get_scorer_names` can be used to retrieve the names\nof all available scorers.\n\nParameters\n----------\nscoring : str, callable or None\n    Scoring method as string. If callable it is returned as is.\n    If None, returns None.\n\nReturns\n-------\nscorer : callable\n    The scorer.\n\nNotes\n-----\nWhen passed a string, this function always returns a copy of the scorer\nobject. Calling `get_scorer` twice for the same scorer results in two\nseparate scorer objects.\n\nExamples\n--------\n>>> import numpy as np\n>>> from sklearn.dummy import DummyClassifier\n>>> from sklearn.metrics import get_scorer\n>>> X = np.reshape([0, 1, -1, -0.5, 2], (-1, 1))\n>>> y = np.array([0, 1, 1, 0, 1])\n>>> classifier = DummyClassifier(strategy=\"constant\", constant=0).fit(X, y)\n>>> accuracy = get_scorer(\"accuracy\")\n>>> accuracy(classifier, X, y)\n0.4" .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#GetScorerNamesMethod
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#GetScorerNamesMethod> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Class> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#GetScorerNamesMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#GetScorerNamesMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MetricsModule> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#GetScorerNamesMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PerformanceCalculationMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#GetScorerNamesMethod> <http://www.w3.org/2000/01/rdf-schema#comment> "Get the names of all available scorers.\n\nThese names can be passed to :func:`~sklearn.metrics.get_scorer` to\nretrieve the scorer object.\n\nReturns\n-------\nlist of str\n    Names of all available scorers.\n\nExamples\n--------\n>>> from sklearn.metrics import get_scorer_names\n>>> all_scorers = get_scorer_names()\n>>> type(all_scorers)\n<class 'list'>\n>>> all_scorers[:3]\n['accuracy', 'adjusted_mutual_info_score', 'adjusted_rand_score']\n>>> \"roc_auc\" in all_scorers\nTrue" .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#HammingLossMethod
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#HammingLossMethod> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Class> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#HammingLossMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#HammingLossMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MetricsModule> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#HammingLossMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PerformanceCalculationMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#HammingLossMethod> <http://www.w3.org/2000/01/rdf-schema#comment> "Compute the average Hamming loss.\n\nThe Hamming loss is the fraction of labels that are incorrectly predicted.\n\nRead more in the :ref:`User Guide <hamming_loss>`.\n\nParameters\n----------\ny_true : 1d array-like, or label indicator array / sparse matrix\n    Ground truth (correct) labels.\n\ny_pred : 1d array-like, or label indicator array / sparse matrix\n    Predicted labels, as returned by a classifier.\n\nsample_weight : array-like of shape (n_samples,), default=None\n    Sample weights.\n\n    .. versionadded:: 0.18\n\nReturns\n-------\nloss : float or int\n    Return the average Hamming loss between element of ``y_true`` and\n    ``y_pred``.\n\nSee Also\n--------\naccuracy_score : Compute the accuracy score. By default, the function will\n    return the fraction of correct predictions divided by the total number\n    of predictions.\njaccard_score : Compute the Jaccard similarity coefficient score.\nzero_one_loss : Compute the Zero-one classification loss. By default, the\n    function will return the percentage of imperfectly predicted subsets.\n\nNotes\n-----\nIn multiclass classification, the Hamming loss corresponds to the Hamming\ndistance between ``y_true`` and ``y_pred`` which is equivalent to the\nsubset ``zero_one_loss`` function, when `normalize` parameter is set to\nTrue.\n\nIn multilabel classification, the Hamming loss is different from the\nsubset zero-one loss. The zero-one loss considers the entire set of labels\nfor a given sample incorrect if it does not entirely match the true set of\nlabels. Hamming loss is more forgiving in that it penalizes only the\nindividual labels.\n\nThe Hamming loss is upperbounded by the subset zero-one loss, when\n`normalize` parameter is set to True. It is always between 0 and 1,\nlower being better.\n\nReferences\n----------\n.. [1] Grigorios Tsoumakas, Ioannis Katakis. Multi-Label Classification:\n       An Overview. International Journal of Data Warehousing & Mining,\n       3(3), 1-13, July-September 2007.\n\n.. [2] `Wikipedia entry on the Hamming distance\n       <https://en.wikipedia.org/wiki/Hamming_distance>`_.\n\nExamples\n--------\n>>> from sklearn.metrics import hamming_loss\n>>> y_pred = [1, 2, 3, 4]\n>>> y_true = [2, 2, 3, 4]\n>>> hamming_loss(y_true, y_pred)\n0.25\n\nIn the multilabel case with binary label indicators:\n\n>>> import numpy as np\n>>> hamming_loss(np.array([[0, 1], [1, 1]]), np.zeros((2, 2)))\n0.75" .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#HingeLossMethod
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#HingeLossMethod> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Class> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#HingeLossMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#HingeLossMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MetricsModule> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#HingeLossMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PerformanceCalculationMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#HingeLossMethod> <http://www.w3.org/2000/01/rdf-schema#comment> "Average hinge loss (non-regularized).\n\nIn binary class case, assuming labels in y_true are encoded with +1 and -1,\nwhen a prediction mistake is made, ``margin = y_true * pred_decision`` is\nalways negative (since the signs disagree), implying ``1 - margin`` is\nalways greater than 1.  The cumulated hinge loss is therefore an upper\nbound of the number of mistakes made by the classifier.\n\nIn multiclass case, the function expects that either all the labels are\nincluded in y_true or an optional labels argument is provided which\ncontains all the labels. The multilabel margin is calculated according\nto Crammer-Singer's method. As in the binary case, the cumulated hinge loss\nis an upper bound of the number of mistakes made by the classifier.\n\nRead more in the :ref:`User Guide <hinge_loss>`.\n\nParameters\n----------\ny_true : array-like of shape (n_samples,)\n    True target, consisting of integers of two values. The positive label\n    must be greater than the negative label.\n\npred_decision : array-like of shape (n_samples,) or (n_samples, n_classes)\n    Predicted decisions, as output by decision_function (floats).\n\nlabels : array-like, default=None\n    Contains all the labels for the problem. Used in multiclass hinge loss.\n\nsample_weight : array-like of shape (n_samples,), default=None\n    Sample weights.\n\nReturns\n-------\nloss : float\n    Average hinge loss.\n\nReferences\n----------\n.. [1] `Wikipedia entry on the Hinge loss\n       <https://en.wikipedia.org/wiki/Hinge_loss>`_.\n\n.. [2] Koby Crammer, Yoram Singer. On the Algorithmic\n       Implementation of Multiclass Kernel-based Vector\n       Machines. Journal of Machine Learning Research 2,\n       (2001), 265-292.\n\n.. [3] `L1 AND L2 Regularization for Multiclass Hinge Loss Models\n       by Robert C. Moore, John DeNero\n       <https://storage.googleapis.com/pub-tools-public-publication-data/pdf/37362.pdf>`_.\n\nExamples\n--------\n>>> from sklearn import svm\n>>> from sklearn.metrics import hinge_loss\n>>> X = [[0], [1]]\n>>> y = [-1, 1]\n>>> est = svm.LinearSVC(dual=\"auto\", random_state=0)\n>>> est.fit(X, y)\nLinearSVC(dual='auto', random_state=0)\n>>> pred_decision = est.decision_function([[-2], [3], [0.5]])\n>>> pred_decision\narray([-2.18...,  2.36...,  0.09...])\n>>> hinge_loss([-1, 1, 1], pred_decision)\n0.30...\n\nIn the multiclass case:\n\n>>> import numpy as np\n>>> X = np.array([[0], [1], [2], [3]])\n>>> Y = np.array([0, 1, 2, 3])\n>>> labels = np.array([0, 1, 2, 3])\n>>> est = svm.LinearSVC(dual=\"auto\")\n>>> est.fit(X, Y)\nLinearSVC(dual='auto')\n>>> pred_decision = est.decision_function([[-1], [2], [3]])\n>>> y_true = [0, 2, 3]\n>>> hinge_loss(y_true, pred_decision, labels=labels)\n0.56..." .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#HomogeneityCompletenessVMeasureMethod
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#HomogeneityCompletenessVMeasureMethod> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Class> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#HomogeneityCompletenessVMeasureMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#HomogeneityCompletenessVMeasureMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MetricsModule> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#HomogeneityCompletenessVMeasureMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PerformanceCalculationMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#HomogeneityCompletenessVMeasureMethod> <http://www.w3.org/2000/01/rdf-schema#comment> "Compute the homogeneity and completeness and V-Measure scores at once.\n\nThose metrics are based on normalized conditional entropy measures of\nthe clustering labeling to evaluate given the knowledge of a Ground\nTruth class labels of the same samples.\n\nA clustering result satisfies homogeneity if all of its clusters\ncontain only data points which are members of a single class.\n\nA clustering result satisfies completeness if all the data points\nthat are members of a given class are elements of the same cluster.\n\nBoth scores have positive values between 0.0 and 1.0, larger values\nbeing desirable.\n\nThose 3 metrics are independent of the absolute values of the labels:\na permutation of the class or cluster label values won't change the\nscore values in any way.\n\nV-Measure is furthermore symmetric: swapping ``labels_true`` and\n``label_pred`` will give the same score. This does not hold for\nhomogeneity and completeness. V-Measure is identical to\n:func:`normalized_mutual_info_score` with the arithmetic averaging\nmethod.\n\nRead more in the :ref:`User Guide <homogeneity_completeness>`.\n\nParameters\n----------\nlabels_true : array-like of shape (n_samples,)\n    Ground truth class labels to be used as a reference.\n\nlabels_pred : array-like of shape (n_samples,)\n    Gluster labels to evaluate.\n\nbeta : float, default=1.0\n    Ratio of weight attributed to ``homogeneity`` vs ``completeness``.\n    If ``beta`` is greater than 1, ``completeness`` is weighted more\n    strongly in the calculation. If ``beta`` is less than 1,\n    ``homogeneity`` is weighted more strongly.\n\nReturns\n-------\nhomogeneity : float\n    Score between 0.0 and 1.0. 1.0 stands for perfectly homogeneous labeling.\n\ncompleteness : float\n    Score between 0.0 and 1.0. 1.0 stands for perfectly complete labeling.\n\nv_measure : float\n    Harmonic mean of the first two.\n\nSee Also\n--------\nhomogeneity_score : Homogeneity metric of cluster labeling.\ncompleteness_score : Completeness metric of cluster labeling.\nv_measure_score : V-Measure (NMI with arithmetic mean option).\n\nExamples\n--------\n>>> from sklearn.metrics import homogeneity_completeness_v_measure\n>>> y_true, y_pred = [0, 0, 1, 1, 2, 2], [0, 0, 1, 2, 2, 2]\n>>> homogeneity_completeness_v_measure(y_true, y_pred)\n(0.71..., 0.77..., 0.73...)" .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#HomogeneityScoreMethod
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#HomogeneityScoreMethod> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Class> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#HomogeneityScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#HomogeneityScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MetricsModule> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#HomogeneityScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PerformanceCalculationMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#HomogeneityScoreMethod> <http://www.w3.org/2000/01/rdf-schema#comment> "Homogeneity metric of a cluster labeling given a ground truth.\n\nA clustering result satisfies homogeneity if all of its clusters\ncontain only data points which are members of a single class.\n\nThis metric is independent of the absolute values of the labels:\na permutation of the class or cluster label values won't change the\nscore value in any way.\n\nThis metric is not symmetric: switching ``label_true`` with ``label_pred``\nwill return the :func:`completeness_score` which will be different in\ngeneral.\n\nRead more in the :ref:`User Guide <homogeneity_completeness>`.\n\nParameters\n----------\nlabels_true : array-like of shape (n_samples,)\n    Ground truth class labels to be used as a reference.\n\nlabels_pred : array-like of shape (n_samples,)\n    Cluster labels to evaluate.\n\nReturns\n-------\nhomogeneity : float\n   Score between 0.0 and 1.0. 1.0 stands for perfectly homogeneous labeling.\n\nSee Also\n--------\ncompleteness_score : Completeness metric of cluster labeling.\nv_measure_score : V-Measure (NMI with arithmetic mean option).\n\nReferences\n----------\n\n.. [1] `Andrew Rosenberg and Julia Hirschberg, 2007. V-Measure: A\n   conditional entropy-based external cluster evaluation measure\n   <https://aclweb.org/anthology/D/D07/D07-1043.pdf>`_\n\nExamples\n--------\n\nPerfect labelings are homogeneous::\n\n  >>> from sklearn.metrics.cluster import homogeneity_score\n  >>> homogeneity_score([0, 0, 1, 1], [1, 1, 0, 0])\n  1.0\n\nNon-perfect labelings that further split classes into more clusters can be\nperfectly homogeneous::\n\n  >>> print(\"%.6f\" % homogeneity_score([0, 0, 1, 1], [0, 0, 1, 2]))\n  1.000000\n  >>> print(\"%.6f\" % homogeneity_score([0, 0, 1, 1], [0, 1, 2, 3]))\n  1.000000\n\nClusters that include samples from different classes do not make for an\nhomogeneous labeling::\n\n  >>> print(\"%.6f\" % homogeneity_score([0, 0, 1, 1], [0, 1, 0, 1]))\n  0.0...\n  >>> print(\"%.6f\" % homogeneity_score([0, 0, 1, 1], [0, 0, 0, 0]))\n  0.0..." .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#JaccardScoreMethod
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#JaccardScoreMethod> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Class> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#JaccardScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#JaccardScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MetricsModule> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#JaccardScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PerformanceCalculationMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#JaccardScoreMethod> <http://www.w3.org/2000/01/rdf-schema#comment> "Jaccard similarity coefficient score.\n\nThe Jaccard index [1], or Jaccard similarity coefficient, defined as\nthe size of the intersection divided by the size of the union of two label\nsets, is used to compare set of predicted labels for a sample to the\ncorresponding set of labels in ``y_true``.\n\nSupport beyond term:`binary` targets is achieved by treating :term:`multiclass`\nand :term:`multilabel` data as a collection of binary problems, one for each\nlabel. For the :term:`binary` case, setting `average='binary'` will return the\nJaccard similarity coefficient for `pos_label`. If `average` is not `'binary'`,\n`pos_label` is ignored and scores for both classes are computed, then averaged or\nboth returned (when `average=None`). Similarly, for :term:`multiclass` and\n:term:`multilabel` targets, scores for all `labels` are either returned or\naveraged depending on the `average` parameter. Use `labels` specify the set of\nlabels to calculate the score for.\n\nRead more in the :ref:`User Guide <jaccard_similarity_score>`.\n\nParameters\n----------\ny_true : 1d array-like, or label indicator array / sparse matrix\n    Ground truth (correct) labels.\n\ny_pred : 1d array-like, or label indicator array / sparse matrix\n    Predicted labels, as returned by a classifier.\n\nlabels : array-like of shape (n_classes,), default=None\n    The set of labels to include when `average != 'binary'`, and their\n    order if `average is None`. Labels present in the data can be\n    excluded, for example in multiclass classification to exclude a \"negative\n    class\". Labels not present in the data can be included and will be\n    \"assigned\" 0 samples. For multilabel targets, labels are column indices.\n    By default, all labels in `y_true` and `y_pred` are used in sorted order.\n\npos_label : int, float, bool or str, default=1\n    The class to report if `average='binary'` and the data is binary,\n    otherwise this parameter is ignored.\n    For multiclass or multilabel targets, set `labels=[pos_label]` and\n    `average != 'binary'` to report metrics for one label only.\n\naverage : {'micro', 'macro', 'samples', 'weighted',             'binary'} or None, default='binary'\n    If ``None``, the scores for each class are returned. Otherwise, this\n    determines the type of averaging performed on the data:\n\n    ``'binary'``:\n        Only report results for the class specified by ``pos_label``.\n        This is applicable only if targets (``y_{true,pred}``) are binary.\n    ``'micro'``:\n        Calculate metrics globally by counting the total true positives,\n        false negatives and false positives.\n    ``'macro'``:\n        Calculate metrics for each label, and find their unweighted\n        mean.  This does not take label imbalance into account.\n    ``'weighted'``:\n        Calculate metrics for each label, and find their average, weighted\n        by support (the number of true instances for each label). This\n        alters 'macro' to account for label imbalance.\n    ``'samples'``:\n        Calculate metrics for each instance, and find their average (only\n        meaningful for multilabel classification).\n\nsample_weight : array-like of shape (n_samples,), default=None\n    Sample weights.\n\nzero_division : \"warn\", {0.0, 1.0}, default=\"warn\"\n    Sets the value to return when there is a zero division, i.e. when there\n    there are no negative values in predictions and labels. If set to\n    \"warn\", this acts like 0, but a warning is also raised.\n\nReturns\n-------\nscore : float or ndarray of shape (n_unique_labels,), dtype=np.float64\n    The Jaccard score. When `average` is not `None`, a single scalar is\n    returned.\n\nSee Also\n--------\naccuracy_score : Function for calculating the accuracy score.\nf1_score : Function for calculating the F1 score.\nmultilabel_confusion_matrix : Function for computing a confusion matrix                                  for each class or sample.\n\nNotes\n-----\n:func:`jaccard_score` may be a poor metric if there are no\npositives for some samples or classes. Jaccard is undefined if there are\nno true or predicted labels, and our implementation will return a score\nof 0 with a warning.\n\nReferences\n----------\n.. [1] `Wikipedia entry for the Jaccard index\n       <https://en.wikipedia.org/wiki/Jaccard_index>`_.\n\nExamples\n--------\n>>> import numpy as np\n>>> from sklearn.metrics import jaccard_score\n>>> y_true = np.array([[0, 1, 1],\n...                    [1, 1, 0]])\n>>> y_pred = np.array([[1, 1, 1],\n...                    [1, 0, 0]])\n\nIn the binary case:\n\n>>> jaccard_score(y_true[0], y_pred[0])\n0.6666...\n\nIn the 2D comparison case (e.g. image similarity):\n\n>>> jaccard_score(y_true, y_pred, average=\"micro\")\n0.6\n\nIn the multilabel case:\n\n>>> jaccard_score(y_true, y_pred, average='samples')\n0.5833...\n>>> jaccard_score(y_true, y_pred, average='macro')\n0.6666...\n>>> jaccard_score(y_true, y_pred, average=None)\narray([0.5, 0.5, 1. ])\n\nIn the multiclass case:\n\n>>> y_pred = [0, 2, 1, 2]\n>>> y_true = [0, 1, 2, 2]\n>>> jaccard_score(y_true, y_pred, average=None)\narray([1. , 0. , 0.33...])" .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#LabelRankingAveragePrecisionScoreMethod
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#LabelRankingAveragePrecisionScoreMethod> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Class> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#LabelRankingAveragePrecisionScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#LabelRankingAveragePrecisionScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MetricsModule> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#LabelRankingAveragePrecisionScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PerformanceCalculationMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#LabelRankingAveragePrecisionScoreMethod> <http://www.w3.org/2000/01/rdf-schema#comment> "Compute ranking-based average precision.\n\nLabel ranking average precision (LRAP) is the average over each ground\ntruth label assigned to each sample, of the ratio of true vs. total\nlabels with lower score.\n\nThis metric is used in multilabel ranking problem, where the goal\nis to give better rank to the labels associated to each sample.\n\nThe obtained score is always strictly greater than 0 and\nthe best value is 1.\n\nRead more in the :ref:`User Guide <label_ranking_average_precision>`.\n\nParameters\n----------\ny_true : {array-like, sparse matrix} of shape (n_samples, n_labels)\n    True binary labels in binary indicator format.\n\ny_score : array-like of shape (n_samples, n_labels)\n    Target scores, can either be probability estimates of the positive\n    class, confidence values, or non-thresholded measure of decisions\n    (as returned by \"decision_function\" on some classifiers).\n\nsample_weight : array-like of shape (n_samples,), default=None\n    Sample weights.\n\n    .. versionadded:: 0.20\n\nReturns\n-------\nscore : float\n    Ranking-based average precision score.\n\nExamples\n--------\n>>> import numpy as np\n>>> from sklearn.metrics import label_ranking_average_precision_score\n>>> y_true = np.array([[1, 0, 0], [0, 0, 1]])\n>>> y_score = np.array([[0.75, 0.5, 1], [1, 0.2, 0.1]])\n>>> label_ranking_average_precision_score(y_true, y_score)\n0.416..." .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#LabelRankingLossMethod
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#LabelRankingLossMethod> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Class> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#LabelRankingLossMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#LabelRankingLossMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MetricsModule> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#LabelRankingLossMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PerformanceCalculationMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#LabelRankingLossMethod> <http://www.w3.org/2000/01/rdf-schema#comment> "Compute Ranking loss measure.\n\nCompute the average number of label pairs that are incorrectly ordered\ngiven y_score weighted by the size of the label set and the number of\nlabels not in the label set.\n\nThis is similar to the error set size, but weighted by the number of\nrelevant and irrelevant labels. The best performance is achieved with\na ranking loss of zero.\n\nRead more in the :ref:`User Guide <label_ranking_loss>`.\n\n.. versionadded:: 0.17\n   A function *label_ranking_loss*\n\nParameters\n----------\ny_true : {array-like, sparse matrix} of shape (n_samples, n_labels)\n    True binary labels in binary indicator format.\n\ny_score : array-like of shape (n_samples, n_labels)\n    Target scores, can either be probability estimates of the positive\n    class, confidence values, or non-thresholded measure of decisions\n    (as returned by \"decision_function\" on some classifiers).\n\nsample_weight : array-like of shape (n_samples,), default=None\n    Sample weights.\n\nReturns\n-------\nloss : float\n    Average number of label pairs that are incorrectly ordered given\n    y_score weighted by the size of the label set and the number of labels not\n    in the label set.\n\nReferences\n----------\n.. [1] Tsoumakas, G., Katakis, I., & Vlahavas, I. (2010).\n       Mining multi-label data. In Data mining and knowledge discovery\n       handbook (pp. 667-685). Springer US.\n\nExamples\n--------\n>>> from sklearn.metrics import label_ranking_loss\n>>> y_true = [[1, 0, 0], [0, 0, 1]]\n>>> y_score = [[0.75, 0.5, 1], [1, 0.2, 0.1]]\n>>> label_ranking_loss(y_true, y_score)\n0.75..." .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#LogLossMethod
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#LogLossMethod> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Class> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#LogLossMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#LogLossMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MetricsModule> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#LogLossMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PerformanceCalculationMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#LogLossMethod> <http://www.w3.org/2000/01/rdf-schema#comment> "Log loss, aka logistic loss or cross-entropy loss.\n\nThis is the loss function used in (multinomial) logistic regression\nand extensions of it such as neural networks, defined as the negative\nlog-likelihood of a logistic model that returns ``y_pred`` probabilities\nfor its training data ``y_true``.\nThe log loss is only defined for two or more labels.\nFor a single sample with true label :math:`y \\in \\{0,1\\}` and\na probability estimate :math:`p = \\operatorname{Pr}(y = 1)`, the log\nloss is:\n\n.. math::\n    L_{\\log}(y, p) = -(y \\log (p) + (1 - y) \\log (1 - p))\n\nRead more in the :ref:`User Guide <log_loss>`.\n\nParameters\n----------\ny_true : array-like or label indicator matrix\n    Ground truth (correct) labels for n_samples samples.\n\ny_pred : array-like of float, shape = (n_samples, n_classes) or (n_samples,)\n    Predicted probabilities, as returned by a classifier's\n    predict_proba method. If ``y_pred.shape = (n_samples,)``\n    the probabilities provided are assumed to be that of the\n    positive class. The labels in ``y_pred`` are assumed to be\n    ordered alphabetically, as done by\n    :class:`~sklearn.preprocessing.LabelBinarizer`.\n\neps : float or \"auto\", default=\"auto\"\n    Log loss is undefined for p=0 or p=1, so probabilities are\n    clipped to `max(eps, min(1 - eps, p))`. The default will depend on the\n    data type of `y_pred` and is set to `np.finfo(y_pred.dtype).eps`.\n\n    .. versionadded:: 1.2\n\n    .. versionchanged:: 1.2\n       The default value changed from `1e-15` to `\"auto\"` that is\n       equivalent to `np.finfo(y_pred.dtype).eps`.\n\n    .. deprecated:: 1.3\n       `eps` is deprecated in 1.3 and will be removed in 1.5.\n\nnormalize : bool, default=True\n    If true, return the mean loss per sample.\n    Otherwise, return the sum of the per-sample losses.\n\nsample_weight : array-like of shape (n_samples,), default=None\n    Sample weights.\n\nlabels : array-like, default=None\n    If not provided, labels will be inferred from y_true. If ``labels``\n    is ``None`` and ``y_pred`` has shape (n_samples,) the labels are\n    assumed to be binary and are inferred from ``y_true``.\n\n    .. versionadded:: 0.18\n\nReturns\n-------\nloss : float\n    Log loss, aka logistic loss or cross-entropy loss.\n\nNotes\n-----\nThe logarithm used is the natural logarithm (base-e).\n\nReferences\n----------\nC.M. Bishop (2006). Pattern Recognition and Machine Learning. Springer,\np. 209.\n\nExamples\n--------\n>>> from sklearn.metrics import log_loss\n>>> log_loss([\"spam\", \"ham\", \"ham\", \"spam\"],\n...          [[.1, .9], [.9, .1], [.8, .2], [.35, .65]])\n0.21616..." .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MakeScorerMethod
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MakeScorerMethod> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Class> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MakeScorerMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MakeScorerMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MetricsModule> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MakeScorerMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PerformanceCalculationMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MakeScorerMethod> <http://www.w3.org/2000/01/rdf-schema#comment> "Make a scorer from a performance metric or loss function.\n\nA scorer is a wrapper around an arbitrary metric or loss function that is called\nwith the signature `scorer(estimator, X, y_true, **kwargs)`.\n\nIt is accepted in all scikit-learn estimators or functions allowing a `scoring`\nparameter.\n\nThe parameter `response_method` allows to specify which method of the estimator\nshould be used to feed the scoring/loss function.\n\nRead more in the :ref:`User Guide <scoring>`.\n\nParameters\n----------\nscore_func : callable\n    Score function (or loss function) with signature\n    ``score_func(y, y_pred, **kwargs)``.\n\nresponse_method : {\"predict_proba\", \"decision_function\", \"predict\"} or             list/tuple of such str, default=None\n\n    Specifies the response method to use get prediction from an estimator\n    (i.e. :term:`predict_proba`, :term:`decision_function` or\n    :term:`predict`). Possible choices are:\n\n    - if `str`, it corresponds to the name to the method to return;\n    - if a list or tuple of `str`, it provides the method names in order of\n      preference. The method returned corresponds to the first method in\n      the list and which is implemented by `estimator`.\n    - if `None`, it is equivalent to `\"predict\"`.\n\n    .. versionadded:: 1.4\n\ngreater_is_better : bool, default=True\n    Whether `score_func` is a score function (default), meaning high is\n    good, or a loss function, meaning low is good. In the latter case, the\n    scorer object will sign-flip the outcome of the `score_func`.\n\nneeds_proba : bool, default=False\n    Whether `score_func` requires `predict_proba` to get probability\n    estimates out of a classifier.\n\n    If True, for binary `y_true`, the score function is supposed to accept\n    a 1D `y_pred` (i.e., probability of the positive class, shape\n    `(n_samples,)`).\n\n    .. deprecated:: 1.4\n       `needs_proba` is deprecated in version 1.4 and will be removed in\n       1.6. Use `response_method=\"predict_proba\"` instead.\n\nneeds_threshold : bool, default=False\n    Whether `score_func` takes a continuous decision certainty.\n    This only works for binary classification using estimators that\n    have either a `decision_function` or `predict_proba` method.\n\n    If True, for binary `y_true`, the score function is supposed to accept\n    a 1D `y_pred` (i.e., probability of the positive class or the decision\n    function, shape `(n_samples,)`).\n\n    For example `average_precision` or the area under the roc curve\n    can not be computed using discrete predictions alone.\n\n    .. deprecated:: 1.4\n       `needs_threshold` is deprecated in version 1.4 and will be removed\n       in 1.6. Use `response_method=(\"decision_function\", \"predict_proba\")`\n       instead to preserve the same behaviour.\n\n**kwargs : additional arguments\n    Additional parameters to be passed to `score_func`.\n\nReturns\n-------\nscorer : callable\n    Callable object that returns a scalar score; greater is better.\n\nExamples\n--------\n>>> from sklearn.metrics import fbeta_score, make_scorer\n>>> ftwo_scorer = make_scorer(fbeta_score, beta=2)\n>>> ftwo_scorer\nmake_scorer(fbeta_score, response_method='predict', beta=2)\n>>> from sklearn.model_selection import GridSearchCV\n>>> from sklearn.svm import LinearSVC\n>>> grid = GridSearchCV(LinearSVC(), param_grid={'C': [1, 10]},\n...                     scoring=ftwo_scorer)" .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MatthewsCorrcoefMethod
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MatthewsCorrcoefMethod> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Class> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MatthewsCorrcoefMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MatthewsCorrcoefMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MetricsModule> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MatthewsCorrcoefMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PerformanceCalculationMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MatthewsCorrcoefMethod> <http://www.w3.org/2000/01/rdf-schema#comment> "Compute the Matthews correlation coefficient (MCC).\n\nThe Matthews correlation coefficient is used in machine learning as a\nmeasure of the quality of binary and multiclass classifications. It takes\ninto account true and false positives and negatives and is generally\nregarded as a balanced measure which can be used even if the classes are of\nvery different sizes. The MCC is in essence a correlation coefficient value\nbetween -1 and +1. A coefficient of +1 represents a perfect prediction, 0\nan average random prediction and -1 an inverse prediction.  The statistic\nis also known as the phi coefficient. [source: Wikipedia]\n\nBinary and multiclass labels are supported.  Only in the binary case does\nthis relate to information about true and false positives and negatives.\nSee references below.\n\nRead more in the :ref:`User Guide <matthews_corrcoef>`.\n\nParameters\n----------\ny_true : array-like of shape (n_samples,)\n    Ground truth (correct) target values.\n\ny_pred : array-like of shape (n_samples,)\n    Estimated targets as returned by a classifier.\n\nsample_weight : array-like of shape (n_samples,), default=None\n    Sample weights.\n\n    .. versionadded:: 0.18\n\nReturns\n-------\nmcc : float\n    The Matthews correlation coefficient (+1 represents a perfect\n    prediction, 0 an average random prediction and -1 and inverse\n    prediction).\n\nReferences\n----------\n.. [1] :doi:`Baldi, Brunak, Chauvin, Andersen and Nielsen, (2000). Assessing the\n   accuracy of prediction algorithms for classification: an overview.\n   <10.1093/bioinformatics/16.5.412>`\n\n.. [2] `Wikipedia entry for the Matthews Correlation Coefficient\n   <https://en.wikipedia.org/wiki/Matthews_correlation_coefficient>`_.\n\n.. [3] `Gorodkin, (2004). Comparing two K-category assignments by a\n    K-category correlation coefficient\n    <https://www.sciencedirect.com/science/article/pii/S1476927104000799>`_.\n\n.. [4] `Jurman, Riccadonna, Furlanello, (2012). A Comparison of MCC and CEN\n    Error Measures in MultiClass Prediction\n    <https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0041882>`_.\n\nExamples\n--------\n>>> from sklearn.metrics import matthews_corrcoef\n>>> y_true = [+1, +1, +1, -1]\n>>> y_pred = [+1, -1, +1, +1]\n>>> matthews_corrcoef(y_true, y_pred)\n-0.33..." .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MaxErrorMethod
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MaxErrorMethod> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Class> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MaxErrorMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MaxErrorMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MetricsModule> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MaxErrorMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PerformanceCalculationMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MaxErrorMethod> <http://www.w3.org/2000/01/rdf-schema#comment> "The max_error metric calculates the maximum residual error.\n\nRead more in the :ref:`User Guide <max_error>`.\n\nParameters\n----------\ny_true : array-like of shape (n_samples,)\n    Ground truth (correct) target values.\n\ny_pred : array-like of shape (n_samples,)\n    Estimated target values.\n\nReturns\n-------\nmax_error : float\n    A positive floating point value (the best value is 0.0).\n\nExamples\n--------\n>>> from sklearn.metrics import max_error\n>>> y_true = [3, 2, 7, 1]\n>>> y_pred = [4, 2, 7, 1]\n>>> max_error(y_true, y_pred)\n1" .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MeanAbsoluteErrorMethod
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MeanAbsoluteErrorMethod> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Class> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MeanAbsoluteErrorMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MeanAbsoluteErrorMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MetricsModule> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MeanAbsoluteErrorMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PerformanceCalculationMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MeanAbsoluteErrorMethod> <http://www.w3.org/2000/01/rdf-schema#comment> "Mean absolute error regression loss.\n\nRead more in the :ref:`User Guide <mean_absolute_error>`.\n\nParameters\n----------\ny_true : array-like of shape (n_samples,) or (n_samples, n_outputs)\n    Ground truth (correct) target values.\n\ny_pred : array-like of shape (n_samples,) or (n_samples, n_outputs)\n    Estimated target values.\n\nsample_weight : array-like of shape (n_samples,), default=None\n    Sample weights.\n\nmultioutput : {'raw_values', 'uniform_average'}  or array-like of shape             (n_outputs,), default='uniform_average'\n    Defines aggregating of multiple output values.\n    Array-like value defines weights used to average errors.\n\n    'raw_values' :\n        Returns a full set of errors in case of multioutput input.\n\n    'uniform_average' :\n        Errors of all outputs are averaged with uniform weight.\n\nReturns\n-------\nloss : float or ndarray of floats\n    If multioutput is 'raw_values', then mean absolute error is returned\n    for each output separately.\n    If multioutput is 'uniform_average' or an ndarray of weights, then the\n    weighted average of all output errors is returned.\n\n    MAE output is non-negative floating point. The best value is 0.0.\n\nExamples\n--------\n>>> from sklearn.metrics import mean_absolute_error\n>>> y_true = [3, -0.5, 2, 7]\n>>> y_pred = [2.5, 0.0, 2, 8]\n>>> mean_absolute_error(y_true, y_pred)\n0.5\n>>> y_true = [[0.5, 1], [-1, 1], [7, -6]]\n>>> y_pred = [[0, 2], [-1, 2], [8, -5]]\n>>> mean_absolute_error(y_true, y_pred)\n0.75\n>>> mean_absolute_error(y_true, y_pred, multioutput='raw_values')\narray([0.5, 1. ])\n>>> mean_absolute_error(y_true, y_pred, multioutput=[0.3, 0.7])\n0.85..." .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MeanAbsolutePercentageErrorMethod
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MeanAbsolutePercentageErrorMethod> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Class> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MeanAbsolutePercentageErrorMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MeanAbsolutePercentageErrorMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MetricsModule> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MeanAbsolutePercentageErrorMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PerformanceCalculationMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MeanAbsolutePercentageErrorMethod> <http://www.w3.org/2000/01/rdf-schema#comment> "Mean absolute percentage error (MAPE) regression loss.\n\nNote here that the output is not a percentage in the range [0, 100]\nand a value of 100 does not mean 100% but 1e2. Furthermore, the output\ncan be arbitrarily high when `y_true` is small (which is specific to the\nmetric) or when `abs(y_true - y_pred)` is large (which is common for most\nregression metrics). Read more in the\n:ref:`User Guide <mean_absolute_percentage_error>`.\n\n.. versionadded:: 0.24\n\nParameters\n----------\ny_true : array-like of shape (n_samples,) or (n_samples, n_outputs)\n    Ground truth (correct) target values.\n\ny_pred : array-like of shape (n_samples,) or (n_samples, n_outputs)\n    Estimated target values.\n\nsample_weight : array-like of shape (n_samples,), default=None\n    Sample weights.\n\nmultioutput : {'raw_values', 'uniform_average'} or array-like\n    Defines aggregating of multiple output values.\n    Array-like value defines weights used to average errors.\n    If input is list then the shape must be (n_outputs,).\n\n    'raw_values' :\n        Returns a full set of errors in case of multioutput input.\n\n    'uniform_average' :\n        Errors of all outputs are averaged with uniform weight.\n\nReturns\n-------\nloss : float or ndarray of floats\n    If multioutput is 'raw_values', then mean absolute percentage error\n    is returned for each output separately.\n    If multioutput is 'uniform_average' or an ndarray of weights, then the\n    weighted average of all output errors is returned.\n\n    MAPE output is non-negative floating point. The best value is 0.0.\n    But note that bad predictions can lead to arbitrarily large\n    MAPE values, especially if some `y_true` values are very close to zero.\n    Note that we return a large value instead of `inf` when `y_true` is zero.\n\nExamples\n--------\n>>> from sklearn.metrics import mean_absolute_percentage_error\n>>> y_true = [3, -0.5, 2, 7]\n>>> y_pred = [2.5, 0.0, 2, 8]\n>>> mean_absolute_percentage_error(y_true, y_pred)\n0.3273...\n>>> y_true = [[0.5, 1], [-1, 1], [7, -6]]\n>>> y_pred = [[0, 2], [-1, 2], [8, -5]]\n>>> mean_absolute_percentage_error(y_true, y_pred)\n0.5515...\n>>> mean_absolute_percentage_error(y_true, y_pred, multioutput=[0.3, 0.7])\n0.6198...\n>>> # the value when some element of the y_true is zero is arbitrarily high because\n>>> # of the division by epsilon\n>>> y_true = [1., 0., 2.4, 7.]\n>>> y_pred = [1.2, 0.1, 2.4, 8.]\n>>> mean_absolute_percentage_error(y_true, y_pred)\n112589990684262.48" .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MeanGammaDevianceMethod
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MeanGammaDevianceMethod> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Class> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MeanGammaDevianceMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MeanGammaDevianceMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MetricsModule> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MeanGammaDevianceMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PerformanceCalculationMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MeanGammaDevianceMethod> <http://www.w3.org/2000/01/rdf-schema#comment> "Mean Gamma deviance regression loss.\n\nGamma deviance is equivalent to the Tweedie deviance with\nthe power parameter `power=2`. It is invariant to scaling of\nthe target variable, and measures relative errors.\n\nRead more in the :ref:`User Guide <mean_tweedie_deviance>`.\n\nParameters\n----------\ny_true : array-like of shape (n_samples,)\n    Ground truth (correct) target values. Requires y_true > 0.\n\ny_pred : array-like of shape (n_samples,)\n    Estimated target values. Requires y_pred > 0.\n\nsample_weight : array-like of shape (n_samples,), default=None\n    Sample weights.\n\nReturns\n-------\nloss : float\n    A non-negative floating point value (the best value is 0.0).\n\nExamples\n--------\n>>> from sklearn.metrics import mean_gamma_deviance\n>>> y_true = [2, 0.5, 1, 4]\n>>> y_pred = [0.5, 0.5, 2., 2.]\n>>> mean_gamma_deviance(y_true, y_pred)\n1.0568..." .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MeanPinballLossMethod
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MeanPinballLossMethod> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Class> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MeanPinballLossMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MeanPinballLossMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MetricsModule> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MeanPinballLossMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PerformanceCalculationMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MeanPinballLossMethod> <http://www.w3.org/2000/01/rdf-schema#comment> "Pinball loss for quantile regression.\n\nRead more in the :ref:`User Guide <pinball_loss>`.\n\nParameters\n----------\ny_true : array-like of shape (n_samples,) or (n_samples, n_outputs)\n    Ground truth (correct) target values.\n\ny_pred : array-like of shape (n_samples,) or (n_samples, n_outputs)\n    Estimated target values.\n\nsample_weight : array-like of shape (n_samples,), default=None\n    Sample weights.\n\nalpha : float, slope of the pinball loss, default=0.5,\n    This loss is equivalent to :ref:`mean_absolute_error` when `alpha=0.5`,\n    `alpha=0.95` is minimized by estimators of the 95th percentile.\n\nmultioutput : {'raw_values', 'uniform_average'}  or array-like of shape             (n_outputs,), default='uniform_average'\n    Defines aggregating of multiple output values.\n    Array-like value defines weights used to average errors.\n\n    'raw_values' :\n        Returns a full set of errors in case of multioutput input.\n\n    'uniform_average' :\n        Errors of all outputs are averaged with uniform weight.\n\nReturns\n-------\nloss : float or ndarray of floats\n    If multioutput is 'raw_values', then mean absolute error is returned\n    for each output separately.\n    If multioutput is 'uniform_average' or an ndarray of weights, then the\n    weighted average of all output errors is returned.\n\n    The pinball loss output is a non-negative floating point. The best\n    value is 0.0.\n\nExamples\n--------\n>>> from sklearn.metrics import mean_pinball_loss\n>>> y_true = [1, 2, 3]\n>>> mean_pinball_loss(y_true, [0, 2, 3], alpha=0.1)\n0.03...\n>>> mean_pinball_loss(y_true, [1, 2, 4], alpha=0.1)\n0.3...\n>>> mean_pinball_loss(y_true, [0, 2, 3], alpha=0.9)\n0.3...\n>>> mean_pinball_loss(y_true, [1, 2, 4], alpha=0.9)\n0.03...\n>>> mean_pinball_loss(y_true, y_true, alpha=0.1)\n0.0\n>>> mean_pinball_loss(y_true, y_true, alpha=0.9)\n0.0" .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MeanPoissonDevianceMethod
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MeanPoissonDevianceMethod> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Class> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MeanPoissonDevianceMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MeanPoissonDevianceMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MetricsModule> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MeanPoissonDevianceMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PerformanceCalculationMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MeanPoissonDevianceMethod> <http://www.w3.org/2000/01/rdf-schema#comment> "Mean Poisson deviance regression loss.\n\nPoisson deviance is equivalent to the Tweedie deviance with\nthe power parameter `power=1`.\n\nRead more in the :ref:`User Guide <mean_tweedie_deviance>`.\n\nParameters\n----------\ny_true : array-like of shape (n_samples,)\n    Ground truth (correct) target values. Requires y_true >= 0.\n\ny_pred : array-like of shape (n_samples,)\n    Estimated target values. Requires y_pred > 0.\n\nsample_weight : array-like of shape (n_samples,), default=None\n    Sample weights.\n\nReturns\n-------\nloss : float\n    A non-negative floating point value (the best value is 0.0).\n\nExamples\n--------\n>>> from sklearn.metrics import mean_poisson_deviance\n>>> y_true = [2, 0, 1, 4]\n>>> y_pred = [0.5, 0.5, 2., 2.]\n>>> mean_poisson_deviance(y_true, y_pred)\n1.4260..." .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MeanSquaredErrorMethod
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MeanSquaredErrorMethod> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Class> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MeanSquaredErrorMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MeanSquaredErrorMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MetricsModule> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MeanSquaredErrorMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PerformanceCalculationMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MeanSquaredErrorMethod> <http://www.w3.org/2000/01/rdf-schema#comment> "Mean squared error regression loss.\n\nRead more in the :ref:`User Guide <mean_squared_error>`.\n\nParameters\n----------\ny_true : array-like of shape (n_samples,) or (n_samples, n_outputs)\n    Ground truth (correct) target values.\n\ny_pred : array-like of shape (n_samples,) or (n_samples, n_outputs)\n    Estimated target values.\n\nsample_weight : array-like of shape (n_samples,), default=None\n    Sample weights.\n\nmultioutput : {'raw_values', 'uniform_average'} or array-like of shape             (n_outputs,), default='uniform_average'\n    Defines aggregating of multiple output values.\n    Array-like value defines weights used to average errors.\n\n    'raw_values' :\n        Returns a full set of errors in case of multioutput input.\n\n    'uniform_average' :\n        Errors of all outputs are averaged with uniform weight.\n\nsquared : bool, default=True\n    If True returns MSE value, if False returns RMSE value.\n\n    .. deprecated:: 1.4\n       `squared` is deprecated in 1.4 and will be removed in 1.6.\n       Use :func:`~sklearn.metrics.root_mean_squared_error`\n       instead to calculate the root mean squared error.\n\nReturns\n-------\nloss : float or ndarray of floats\n    A non-negative floating point value (the best value is 0.0), or an\n    array of floating point values, one for each individual target.\n\nExamples\n--------\n>>> from sklearn.metrics import mean_squared_error\n>>> y_true = [3, -0.5, 2, 7]\n>>> y_pred = [2.5, 0.0, 2, 8]\n>>> mean_squared_error(y_true, y_pred)\n0.375\n>>> y_true = [[0.5, 1],[-1, 1],[7, -6]]\n>>> y_pred = [[0, 2],[-1, 2],[8, -5]]\n>>> mean_squared_error(y_true, y_pred)\n0.708...\n>>> mean_squared_error(y_true, y_pred, multioutput='raw_values')\narray([0.41666667, 1.        ])\n>>> mean_squared_error(y_true, y_pred, multioutput=[0.3, 0.7])\n0.825..." .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MeanSquaredLogErrorMethod
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MeanSquaredLogErrorMethod> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Class> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MeanSquaredLogErrorMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MeanSquaredLogErrorMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MetricsModule> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MeanSquaredLogErrorMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PerformanceCalculationMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MeanSquaredLogErrorMethod> <http://www.w3.org/2000/01/rdf-schema#comment> "Mean squared logarithmic error regression loss.\n\nRead more in the :ref:`User Guide <mean_squared_log_error>`.\n\nParameters\n----------\ny_true : array-like of shape (n_samples,) or (n_samples, n_outputs)\n    Ground truth (correct) target values.\n\ny_pred : array-like of shape (n_samples,) or (n_samples, n_outputs)\n    Estimated target values.\n\nsample_weight : array-like of shape (n_samples,), default=None\n    Sample weights.\n\nmultioutput : {'raw_values', 'uniform_average'} or array-like of shape             (n_outputs,), default='uniform_average'\n\n    Defines aggregating of multiple output values.\n    Array-like value defines weights used to average errors.\n\n    'raw_values' :\n        Returns a full set of errors when the input is of multioutput\n        format.\n\n    'uniform_average' :\n        Errors of all outputs are averaged with uniform weight.\n\nsquared : bool, default=True\n    If True returns MSLE (mean squared log error) value.\n    If False returns RMSLE (root mean squared log error) value.\n\n    .. deprecated:: 1.4\n       `squared` is deprecated in 1.4 and will be removed in 1.6.\n       Use :func:`~sklearn.metrics.root_mean_squared_log_error`\n       instead to calculate the root mean squared logarithmic error.\n\nReturns\n-------\nloss : float or ndarray of floats\n    A non-negative floating point value (the best value is 0.0), or an\n    array of floating point values, one for each individual target.\n\nExamples\n--------\n>>> from sklearn.metrics import mean_squared_log_error\n>>> y_true = [3, 5, 2.5, 7]\n>>> y_pred = [2.5, 5, 4, 8]\n>>> mean_squared_log_error(y_true, y_pred)\n0.039...\n>>> y_true = [[0.5, 1], [1, 2], [7, 6]]\n>>> y_pred = [[0.5, 2], [1, 2.5], [8, 8]]\n>>> mean_squared_log_error(y_true, y_pred)\n0.044...\n>>> mean_squared_log_error(y_true, y_pred, multioutput='raw_values')\narray([0.00462428, 0.08377444])\n>>> mean_squared_log_error(y_true, y_pred, multioutput=[0.3, 0.7])\n0.060..." .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MeanTweedieDevianceMethod
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MeanTweedieDevianceMethod> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Class> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MeanTweedieDevianceMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MeanTweedieDevianceMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MetricsModule> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MeanTweedieDevianceMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PerformanceCalculationMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MeanTweedieDevianceMethod> <http://www.w3.org/2000/01/rdf-schema#comment> "Mean Tweedie deviance regression loss.\n\nRead more in the :ref:`User Guide <mean_tweedie_deviance>`.\n\nParameters\n----------\ny_true : array-like of shape (n_samples,)\n    Ground truth (correct) target values.\n\ny_pred : array-like of shape (n_samples,)\n    Estimated target values.\n\nsample_weight : array-like of shape (n_samples,), default=None\n    Sample weights.\n\npower : float, default=0\n    Tweedie power parameter. Either power <= 0 or power >= 1.\n\n    The higher `p` the less weight is given to extreme\n    deviations between true and predicted targets.\n\n    - power < 0: Extreme stable distribution. Requires: y_pred > 0.\n    - power = 0 : Normal distribution, output corresponds to\n      mean_squared_error. y_true and y_pred can be any real numbers.\n    - power = 1 : Poisson distribution. Requires: y_true >= 0 and\n      y_pred > 0.\n    - 1 < p < 2 : Compound Poisson distribution. Requires: y_true >= 0\n      and y_pred > 0.\n    - power = 2 : Gamma distribution. Requires: y_true > 0 and y_pred > 0.\n    - power = 3 : Inverse Gaussian distribution. Requires: y_true > 0\n      and y_pred > 0.\n    - otherwise : Positive stable distribution. Requires: y_true > 0\n      and y_pred > 0.\n\nReturns\n-------\nloss : float\n    A non-negative floating point value (the best value is 0.0).\n\nExamples\n--------\n>>> from sklearn.metrics import mean_tweedie_deviance\n>>> y_true = [2, 0, 1, 4]\n>>> y_pred = [0.5, 0.5, 2., 2.]\n>>> mean_tweedie_deviance(y_true, y_pred, power=1)\n1.4260..." .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MedianAbsoluteErrorMethod
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MedianAbsoluteErrorMethod> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Class> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MedianAbsoluteErrorMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MedianAbsoluteErrorMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MetricsModule> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MedianAbsoluteErrorMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PerformanceCalculationMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MedianAbsoluteErrorMethod> <http://www.w3.org/2000/01/rdf-schema#comment> "Median absolute error regression loss.\n\nMedian absolute error output is non-negative floating point. The best value\nis 0.0. Read more in the :ref:`User Guide <median_absolute_error>`.\n\nParameters\n----------\ny_true : array-like of shape (n_samples,) or (n_samples, n_outputs)\n    Ground truth (correct) target values.\n\ny_pred : array-like of shape (n_samples,) or (n_samples, n_outputs)\n    Estimated target values.\n\nmultioutput : {'raw_values', 'uniform_average'} or array-like of shape             (n_outputs,), default='uniform_average'\n    Defines aggregating of multiple output values. Array-like value defines\n    weights used to average errors.\n\n    'raw_values' :\n        Returns a full set of errors in case of multioutput input.\n\n    'uniform_average' :\n        Errors of all outputs are averaged with uniform weight.\n\nsample_weight : array-like of shape (n_samples,), default=None\n    Sample weights.\n\n    .. versionadded:: 0.24\n\nReturns\n-------\nloss : float or ndarray of floats\n    If multioutput is 'raw_values', then mean absolute error is returned\n    for each output separately.\n    If multioutput is 'uniform_average' or an ndarray of weights, then the\n    weighted average of all output errors is returned.\n\nExamples\n--------\n>>> from sklearn.metrics import median_absolute_error\n>>> y_true = [3, -0.5, 2, 7]\n>>> y_pred = [2.5, 0.0, 2, 8]\n>>> median_absolute_error(y_true, y_pred)\n0.5\n>>> y_true = [[0.5, 1], [-1, 1], [7, -6]]\n>>> y_pred = [[0, 2], [-1, 2], [8, -5]]\n>>> median_absolute_error(y_true, y_pred)\n0.75\n>>> median_absolute_error(y_true, y_pred, multioutput='raw_values')\narray([0.5, 1. ])\n>>> median_absolute_error(y_true, y_pred, multioutput=[0.3, 0.7])\n0.85" .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MetricsModule
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MetricsModule> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Class> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MetricsModule> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#SklearnModule> .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MultilabelConfusionMatrixMethod
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MultilabelConfusionMatrixMethod> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Class> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MultilabelConfusionMatrixMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MultilabelConfusionMatrixMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MetricsModule> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MultilabelConfusionMatrixMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PerformanceCalculationMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MultilabelConfusionMatrixMethod> <http://www.w3.org/2000/01/rdf-schema#comment> "Compute a confusion matrix for each class or sample.\n\n.. versionadded:: 0.21\n\nCompute class-wise (default) or sample-wise (samplewise=True) multilabel\nconfusion matrix to evaluate the accuracy of a classification, and output\nconfusion matrices for each class or sample.\n\nIn multilabel confusion matrix :math:`MCM`, the count of true negatives\nis :math:`MCM_{:,0,0}`, false negatives is :math:`MCM_{:,1,0}`,\ntrue positives is :math:`MCM_{:,1,1}` and false positives is\n:math:`MCM_{:,0,1}`.\n\nMulticlass data will be treated as if binarized under a one-vs-rest\ntransformation. Returned confusion matrices will be in the order of\nsorted unique labels in the union of (y_true, y_pred).\n\nRead more in the :ref:`User Guide <multilabel_confusion_matrix>`.\n\nParameters\n----------\ny_true : {array-like, sparse matrix} of shape (n_samples, n_outputs) or             (n_samples,)\n    Ground truth (correct) target values.\n\ny_pred : {array-like, sparse matrix} of shape (n_samples, n_outputs) or             (n_samples,)\n    Estimated targets as returned by a classifier.\n\nsample_weight : array-like of shape (n_samples,), default=None\n    Sample weights.\n\nlabels : array-like of shape (n_classes,), default=None\n    A list of classes or column indices to select some (or to force\n    inclusion of classes absent from the data).\n\nsamplewise : bool, default=False\n    In the multilabel case, this calculates a confusion matrix per sample.\n\nReturns\n-------\nmulti_confusion : ndarray of shape (n_outputs, 2, 2)\n    A 2x2 confusion matrix corresponding to each output in the input.\n    When calculating class-wise multi_confusion (default), then\n    n_outputs = n_labels; when calculating sample-wise multi_confusion\n    (samplewise=True), n_outputs = n_samples. If ``labels`` is defined,\n    the results will be returned in the order specified in ``labels``,\n    otherwise the results will be returned in sorted order by default.\n\nSee Also\n--------\nconfusion_matrix : Compute confusion matrix to evaluate the accuracy of a\n    classifier.\n\nNotes\n-----\nThe `multilabel_confusion_matrix` calculates class-wise or sample-wise\nmultilabel confusion matrices, and in multiclass tasks, labels are\nbinarized under a one-vs-rest way; while\n:func:`~sklearn.metrics.confusion_matrix` calculates one confusion matrix\nfor confusion between every two classes.\n\nExamples\n--------\nMultilabel-indicator case:\n\n>>> import numpy as np\n>>> from sklearn.metrics import multilabel_confusion_matrix\n>>> y_true = np.array([[1, 0, 1],\n...                    [0, 1, 0]])\n>>> y_pred = np.array([[1, 0, 0],\n...                    [0, 1, 1]])\n>>> multilabel_confusion_matrix(y_true, y_pred)\narray([[[1, 0],\n        [0, 1]],\n<BLANKLINE>\n       [[1, 0],\n        [0, 1]],\n<BLANKLINE>\n       [[0, 1],\n        [1, 0]]])\n\nMulticlass case:\n\n>>> y_true = [\"cat\", \"ant\", \"cat\", \"cat\", \"ant\", \"bird\"]\n>>> y_pred = [\"ant\", \"ant\", \"cat\", \"cat\", \"ant\", \"cat\"]\n>>> multilabel_confusion_matrix(y_true, y_pred,\n...                             labels=[\"ant\", \"bird\", \"cat\"])\narray([[[3, 1],\n        [0, 2]],\n<BLANKLINE>\n       [[5, 0],\n        [1, 0]],\n<BLANKLINE>\n       [[2, 1],\n        [1, 2]]])" .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MutualInfoScoreMethod
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MutualInfoScoreMethod> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Class> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MutualInfoScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MutualInfoScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MetricsModule> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MutualInfoScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PerformanceCalculationMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MutualInfoScoreMethod> <http://www.w3.org/2000/01/rdf-schema#comment> "Mutual Information between two clusterings.\n\nThe Mutual Information is a measure of the similarity between two labels\nof the same data. Where :math:`|U_i|` is the number of the samples\nin cluster :math:`U_i` and :math:`|V_j|` is the number of the\nsamples in cluster :math:`V_j`, the Mutual Information\nbetween clusterings :math:`U` and :math:`V` is given as:\n\n.. math::\n\n    MI(U,V)=\\sum_{i=1}^{|U|} \\sum_{j=1}^{|V|} \\frac{|U_i\\cap V_j|}{N}\n    \\log\\frac{N|U_i \\cap V_j|}{|U_i||V_j|}\n\nThis metric is independent of the absolute values of the labels:\na permutation of the class or cluster label values won't change the\nscore value in any way.\n\nThis metric is furthermore symmetric: switching :math:`U` (i.e\n``label_true``) with :math:`V` (i.e. ``label_pred``) will return the\nsame score value. This can be useful to measure the agreement of two\nindependent label assignments strategies on the same dataset when the\nreal ground truth is not known.\n\nRead more in the :ref:`User Guide <mutual_info_score>`.\n\nParameters\n----------\nlabels_true : array-like of shape (n_samples,), dtype=integral\n    A clustering of the data into disjoint subsets, called :math:`U` in\n    the above formula.\n\nlabels_pred : array-like of shape (n_samples,), dtype=integral\n    A clustering of the data into disjoint subsets, called :math:`V` in\n    the above formula.\n\ncontingency : {array-like, sparse matrix} of shape             (n_classes_true, n_classes_pred), default=None\n    A contingency matrix given by the\n    :func:`~sklearn.metrics.cluster.contingency_matrix` function. If value\n    is ``None``, it will be computed, otherwise the given value is used,\n    with ``labels_true`` and ``labels_pred`` ignored.\n\nReturns\n-------\nmi : float\n   Mutual information, a non-negative value, measured in nats using the\n   natural logarithm.\n\nSee Also\n--------\nadjusted_mutual_info_score : Adjusted against chance Mutual Information.\nnormalized_mutual_info_score : Normalized Mutual Information.\n\nNotes\n-----\nThe logarithm used is the natural logarithm (base-e).\n\nExamples\n--------\n>>> from sklearn.metrics import mutual_info_score\n>>> labels_true = [0, 1, 1, 0, 1, 0]\n>>> labels_pred = [0, 1, 0, 0, 1, 1]\n>>> mutual_info_score(labels_true, labels_pred)\n0.056..." .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#NanEuclideanDistancesMethod
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#NanEuclideanDistancesMethod> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Class> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#NanEuclideanDistancesMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#NanEuclideanDistancesMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MetricsModule> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#NanEuclideanDistancesMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PerformanceCalculationMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#NanEuclideanDistancesMethod> <http://www.w3.org/2000/01/rdf-schema#comment> "Calculate the euclidean distances in the presence of missing values.\n\nCompute the euclidean distance between each pair of samples in X and Y,\nwhere Y=X is assumed if Y=None. When calculating the distance between a\npair of samples, this formulation ignores feature coordinates with a\nmissing value in either sample and scales up the weight of the remaining\ncoordinates:\n\n    dist(x,y) = sqrt(weight * sq. distance from present coordinates)\n    where,\n    weight = Total # of coordinates / # of present coordinates\n\nFor example, the distance between ``[3, na, na, 6]`` and ``[1, na, 4, 5]``\nis:\n\n    .. math::\n        \\sqrt{\\frac{4}{2}((3-1)^2 + (6-5)^2)}\n\nIf all the coordinates are missing or if there are no common present\ncoordinates then NaN is returned for that pair.\n\nRead more in the :ref:`User Guide <metrics>`.\n\n.. versionadded:: 0.22\n\nParameters\n----------\nX : array-like of shape (n_samples_X, n_features)\n    An array where each row is a sample and each column is a feature.\n\nY : array-like of shape (n_samples_Y, n_features), default=None\n    An array where each row is a sample and each column is a feature.\n    If `None`, method uses `Y=X`.\n\nsquared : bool, default=False\n    Return squared Euclidean distances.\n\nmissing_values : np.nan, float or int, default=np.nan\n    Representation of missing value.\n\ncopy : bool, default=True\n    Make and use a deep copy of X and Y (if Y exists).\n\nReturns\n-------\ndistances : ndarray of shape (n_samples_X, n_samples_Y)\n    Returns the distances between the row vectors of `X`\n    and the row vectors of `Y`.\n\nSee Also\n--------\npaired_distances : Distances between pairs of elements of X and Y.\n\nReferences\n----------\n* John K. Dixon, \"Pattern Recognition with Partly Missing Data\",\n  IEEE Transactions on Systems, Man, and Cybernetics, Volume: 9, Issue:\n  10, pp. 617 - 621, Oct. 1979.\n  http://ieeexplore.ieee.org/abstract/document/4310090/\n\nExamples\n--------\n>>> from sklearn.metrics.pairwise import nan_euclidean_distances\n>>> nan = float(\"NaN\")\n>>> X = [[0, 1], [1, nan]]\n>>> nan_euclidean_distances(X, X) # distance between rows of X\narray([[0.        , 1.41421356],\n       [1.41421356, 0.        ]])\n\n>>> # get distance to origin\n>>> nan_euclidean_distances(X, [[0, 0]])\narray([[1.        ],\n       [1.41421356]])" .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#NdcgScoreMethod
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#NdcgScoreMethod> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Class> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#NdcgScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#NdcgScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MetricsModule> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#NdcgScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PerformanceCalculationMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#NdcgScoreMethod> <http://www.w3.org/2000/01/rdf-schema#comment> "Compute Normalized Discounted Cumulative Gain.\n\nSum the true scores ranked in the order induced by the predicted scores,\nafter applying a logarithmic discount. Then divide by the best possible\nscore (Ideal DCG, obtained for a perfect ranking) to obtain a score between\n0 and 1.\n\nThis ranking metric returns a high value if true labels are ranked high by\n``y_score``.\n\nParameters\n----------\ny_true : array-like of shape (n_samples, n_labels)\n    True targets of multilabel classification, or true scores of entities\n    to be ranked. Negative values in `y_true` may result in an output\n    that is not between 0 and 1.\n\ny_score : array-like of shape (n_samples, n_labels)\n    Target scores, can either be probability estimates, confidence values,\n    or non-thresholded measure of decisions (as returned by\n    \"decision_function\" on some classifiers).\n\nk : int, default=None\n    Only consider the highest k scores in the ranking. If `None`, use all\n    outputs.\n\nsample_weight : array-like of shape (n_samples,), default=None\n    Sample weights. If `None`, all samples are given the same weight.\n\nignore_ties : bool, default=False\n    Assume that there are no ties in y_score (which is likely to be the\n    case if y_score is continuous) for efficiency gains.\n\nReturns\n-------\nnormalized_discounted_cumulative_gain : float in [0., 1.]\n    The averaged NDCG scores for all samples.\n\nSee Also\n--------\ndcg_score : Discounted Cumulative Gain (not normalized).\n\nReferences\n----------\n`Wikipedia entry for Discounted Cumulative Gain\n<https://en.wikipedia.org/wiki/Discounted_cumulative_gain>`_\n\nJarvelin, K., & Kekalainen, J. (2002).\nCumulated gain-based evaluation of IR techniques. ACM Transactions on\nInformation Systems (TOIS), 20(4), 422-446.\n\nWang, Y., Wang, L., Li, Y., He, D., Chen, W., & Liu, T. Y. (2013, May).\nA theoretical analysis of NDCG ranking measures. In Proceedings of the 26th\nAnnual Conference on Learning Theory (COLT 2013)\n\nMcSherry, F., & Najork, M. (2008, March). Computing information retrieval\nperformance measures efficiently in the presence of tied scores. In\nEuropean conference on information retrieval (pp. 414-421). Springer,\nBerlin, Heidelberg.\n\nExamples\n--------\n>>> import numpy as np\n>>> from sklearn.metrics import ndcg_score\n>>> # we have groud-truth relevance of some answers to a query:\n>>> true_relevance = np.asarray([[10, 0, 0, 1, 5]])\n>>> # we predict some scores (relevance) for the answers\n>>> scores = np.asarray([[.1, .2, .3, 4, 70]])\n>>> ndcg_score(true_relevance, scores)\n0.69...\n>>> scores = np.asarray([[.05, 1.1, 1., .5, .0]])\n>>> ndcg_score(true_relevance, scores)\n0.49...\n>>> # we can set k to truncate the sum; only top k answers contribute.\n>>> ndcg_score(true_relevance, scores, k=4)\n0.35...\n>>> # the normalization takes k into account so a perfect answer\n>>> # would still get 1.0\n>>> ndcg_score(true_relevance, true_relevance, k=4)\n1.0...\n>>> # now we have some ties in our prediction\n>>> scores = np.asarray([[1, 0, 0, 0, 1]])\n>>> # by default ties are averaged, so here we get the average (normalized)\n>>> # true relevance of our top predictions: (10 / 10 + 5 / 10) / 2 = .75\n>>> ndcg_score(true_relevance, scores, k=1)\n0.75...\n>>> # we can choose to ignore ties for faster results, but only\n>>> # if we know there aren't ties in our scores, otherwise we get\n>>> # wrong results:\n>>> ndcg_score(true_relevance,\n...           scores, k=1, ignore_ties=True)\n0.5..." .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#NormalizedMutualInfoScoreMethod
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#NormalizedMutualInfoScoreMethod> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Class> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#NormalizedMutualInfoScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#NormalizedMutualInfoScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MetricsModule> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#NormalizedMutualInfoScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PerformanceCalculationMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#NormalizedMutualInfoScoreMethod> <http://www.w3.org/2000/01/rdf-schema#comment> "Normalized Mutual Information between two clusterings.\n\nNormalized Mutual Information (NMI) is a normalization of the Mutual\nInformation (MI) score to scale the results between 0 (no mutual\ninformation) and 1 (perfect correlation). In this function, mutual\ninformation is normalized by some generalized mean of ``H(labels_true)``\nand ``H(labels_pred))``, defined by the `average_method`.\n\nThis measure is not adjusted for chance. Therefore\n:func:`adjusted_mutual_info_score` might be preferred.\n\nThis metric is independent of the absolute values of the labels:\na permutation of the class or cluster label values won't change the\nscore value in any way.\n\nThis metric is furthermore symmetric: switching ``label_true`` with\n``label_pred`` will return the same score value. This can be useful to\nmeasure the agreement of two independent label assignments strategies\non the same dataset when the real ground truth is not known.\n\nRead more in the :ref:`User Guide <mutual_info_score>`.\n\nParameters\n----------\nlabels_true : int array-like of shape (n_samples,)\n    A clustering of the data into disjoint subsets.\n\nlabels_pred : int array-like of shape (n_samples,)\n    A clustering of the data into disjoint subsets.\n\naverage_method : {'min', 'geometric', 'arithmetic', 'max'}, default='arithmetic'\n    How to compute the normalizer in the denominator.\n\n    .. versionadded:: 0.20\n\n    .. versionchanged:: 0.22\n       The default value of ``average_method`` changed from 'geometric' to\n       'arithmetic'.\n\nReturns\n-------\nnmi : float\n   Score between 0.0 and 1.0 in normalized nats (based on the natural\n   logarithm). 1.0 stands for perfectly complete labeling.\n\nSee Also\n--------\nv_measure_score : V-Measure (NMI with arithmetic mean option).\nadjusted_rand_score : Adjusted Rand Index.\nadjusted_mutual_info_score : Adjusted Mutual Information (adjusted\n    against chance).\n\nExamples\n--------\n\nPerfect labelings are both homogeneous and complete, hence have\nscore 1.0::\n\n  >>> from sklearn.metrics.cluster import normalized_mutual_info_score\n  >>> normalized_mutual_info_score([0, 0, 1, 1], [0, 0, 1, 1])\n  ... # doctest: +SKIP\n  1.0\n  >>> normalized_mutual_info_score([0, 0, 1, 1], [1, 1, 0, 0])\n  ... # doctest: +SKIP\n  1.0\n\nIf classes members are completely split across different clusters,\nthe assignment is totally in-complete, hence the NMI is null::\n\n  >>> normalized_mutual_info_score([0, 0, 0, 0], [0, 1, 2, 3])\n  ... # doctest: +SKIP\n  0.0" .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PairConfusionMatrixMethod
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PairConfusionMatrixMethod> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Class> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PairConfusionMatrixMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PairConfusionMatrixMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MetricsModule> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PairConfusionMatrixMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PerformanceCalculationMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PairConfusionMatrixMethod> <http://www.w3.org/2000/01/rdf-schema#comment> "Pair confusion matrix arising from two clusterings [1]_.\n\nThe pair confusion matrix :math:`C` computes a 2 by 2 similarity matrix\nbetween two clusterings by considering all pairs of samples and counting\npairs that are assigned into the same or into different clusters under\nthe true and predicted clusterings.\n\nConsidering a pair of samples that is clustered together a positive pair,\nthen as in binary classification the count of true negatives is\n:math:`C_{00}`, false negatives is :math:`C_{10}`, true positives is\n:math:`C_{11}` and false positives is :math:`C_{01}`.\n\nRead more in the :ref:`User Guide <pair_confusion_matrix>`.\n\nParameters\n----------\nlabels_true : array-like of shape (n_samples,), dtype=integral\n    Ground truth class labels to be used as a reference.\n\nlabels_pred : array-like of shape (n_samples,), dtype=integral\n    Cluster labels to evaluate.\n\nReturns\n-------\nC : ndarray of shape (2, 2), dtype=np.int64\n    The contingency matrix.\n\nSee Also\n--------\nsklearn.metrics.rand_score : Rand Score.\nsklearn.metrics.adjusted_rand_score : Adjusted Rand Score.\nsklearn.metrics.adjusted_mutual_info_score : Adjusted Mutual Information.\n\nReferences\n----------\n.. [1] :doi:`Hubert, L., Arabie, P. \"Comparing partitions.\"\n       Journal of Classification 2, 193218 (1985).\n       <10.1007/BF01908075>`\n\nExamples\n--------\nPerfectly matching labelings have all non-zero entries on the\ndiagonal regardless of actual label values:\n\n  >>> from sklearn.metrics.cluster import pair_confusion_matrix\n  >>> pair_confusion_matrix([0, 0, 1, 1], [1, 1, 0, 0])\n  array([[8, 0],\n         [0, 4]]...\n\nLabelings that assign all classes members to the same clusters\nare complete but may be not always pure, hence penalized, and\nhave some off-diagonal non-zero entries:\n\n  >>> pair_confusion_matrix([0, 0, 1, 2], [0, 0, 1, 1])\n  array([[8, 2],\n         [0, 2]]...\n\nNote that the matrix is not symmetric." .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PairwiseDistancesArgminMethod
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PairwiseDistancesArgminMethod> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Class> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PairwiseDistancesArgminMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PairwiseDistancesArgminMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MetricsModule> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PairwiseDistancesArgminMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PerformanceCalculationMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PairwiseDistancesArgminMethod> <http://www.w3.org/2000/01/rdf-schema#comment> "Compute minimum distances between one point and a set of points.\n\nThis function computes for each row in X, the index of the row of Y which\nis closest (according to the specified distance).\n\nThis is mostly equivalent to calling:\n\n    pairwise_distances(X, Y=Y, metric=metric).argmin(axis=axis)\n\nbut uses much less memory, and is faster for large arrays.\n\nThis function works with dense 2D arrays only.\n\nParameters\n----------\nX : {array-like, sparse matrix} of shape (n_samples_X, n_features)\n    Array containing points.\n\nY : {array-like, sparse matrix} of shape (n_samples_Y, n_features)\n    Arrays containing points.\n\naxis : int, default=1\n    Axis along which the argmin and distances are to be computed.\n\nmetric : str or callable, default=\"euclidean\"\n    Metric to use for distance computation. Any metric from scikit-learn\n    or scipy.spatial.distance can be used.\n\n    If metric is a callable function, it is called on each\n    pair of instances (rows) and the resulting value recorded. The callable\n    should take two arrays as input and return one value indicating the\n    distance between them. This works for Scipy's metrics, but is less\n    efficient than passing the metric name as a string.\n\n    Distance matrices are not supported.\n\n    Valid values for metric are:\n\n    - from scikit-learn: ['cityblock', 'cosine', 'euclidean', 'l1', 'l2',\n      'manhattan']\n\n    - from scipy.spatial.distance: ['braycurtis', 'canberra', 'chebyshev',\n      'correlation', 'dice', 'hamming', 'jaccard', 'kulsinski',\n      'mahalanobis', 'minkowski', 'rogerstanimoto', 'russellrao',\n      'seuclidean', 'sokalmichener', 'sokalsneath', 'sqeuclidean',\n      'yule']\n\n    See the documentation for scipy.spatial.distance for details on these\n    metrics.\n\n    .. note::\n       `'kulsinski'` is deprecated from SciPy 1.9 and will be removed in SciPy 1.11.\n\n    .. note::\n       `'matching'` has been removed in SciPy 1.9 (use `'hamming'` instead).\n\nmetric_kwargs : dict, default=None\n    Keyword arguments to pass to specified metric function.\n\nReturns\n-------\nargmin : numpy.ndarray\n    Y[argmin[i], :] is the row in Y that is closest to X[i, :].\n\nSee Also\n--------\npairwise_distances : Distances between every pair of samples of X and Y.\npairwise_distances_argmin_min : Same as `pairwise_distances_argmin` but also\n    returns the distances.\n\nExamples\n--------\n>>> from sklearn.metrics.pairwise import pairwise_distances_argmin\n>>> X = [[0, 0, 0], [1, 1, 1]]\n>>> Y = [[1, 0, 0], [1, 1, 0]]\n>>> pairwise_distances_argmin(X, Y)\narray([0, 1])" .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PairwiseDistancesArgminMinMethod
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PairwiseDistancesArgminMinMethod> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Class> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PairwiseDistancesArgminMinMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PairwiseDistancesArgminMinMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MetricsModule> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PairwiseDistancesArgminMinMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PerformanceCalculationMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PairwiseDistancesArgminMinMethod> <http://www.w3.org/2000/01/rdf-schema#comment> "Compute minimum distances between one point and a set of points.\n\nThis function computes for each row in X, the index of the row of Y which\nis closest (according to the specified distance). The minimal distances are\nalso returned.\n\nThis is mostly equivalent to calling:\n\n    (pairwise_distances(X, Y=Y, metric=metric).argmin(axis=axis),\n     pairwise_distances(X, Y=Y, metric=metric).min(axis=axis))\n\nbut uses much less memory, and is faster for large arrays.\n\nParameters\n----------\nX : {array-like, sparse matrix} of shape (n_samples_X, n_features)\n    Array containing points.\n\nY : {array-like, sparse matrix} of shape (n_samples_Y, n_features)\n    Array containing points.\n\naxis : int, default=1\n    Axis along which the argmin and distances are to be computed.\n\nmetric : str or callable, default='euclidean'\n    Metric to use for distance computation. Any metric from scikit-learn\n    or scipy.spatial.distance can be used.\n\n    If metric is a callable function, it is called on each\n    pair of instances (rows) and the resulting value recorded. The callable\n    should take two arrays as input and return one value indicating the\n    distance between them. This works for Scipy's metrics, but is less\n    efficient than passing the metric name as a string.\n\n    Distance matrices are not supported.\n\n    Valid values for metric are:\n\n    - from scikit-learn: ['cityblock', 'cosine', 'euclidean', 'l1', 'l2',\n      'manhattan']\n\n    - from scipy.spatial.distance: ['braycurtis', 'canberra', 'chebyshev',\n      'correlation', 'dice', 'hamming', 'jaccard', 'kulsinski',\n      'mahalanobis', 'minkowski', 'rogerstanimoto', 'russellrao',\n      'seuclidean', 'sokalmichener', 'sokalsneath', 'sqeuclidean',\n      'yule']\n\n    See the documentation for scipy.spatial.distance for details on these\n    metrics.\n\n    .. note::\n       `'kulsinski'` is deprecated from SciPy 1.9 and will be removed in SciPy 1.11.\n\n    .. note::\n       `'matching'` has been removed in SciPy 1.9 (use `'hamming'` instead).\n\nmetric_kwargs : dict, default=None\n    Keyword arguments to pass to specified metric function.\n\nReturns\n-------\nargmin : ndarray\n    Y[argmin[i], :] is the row in Y that is closest to X[i, :].\n\ndistances : ndarray\n    The array of minimum distances. `distances[i]` is the distance between\n    the i-th row in X and the argmin[i]-th row in Y.\n\nSee Also\n--------\npairwise_distances : Distances between every pair of samples of X and Y.\npairwise_distances_argmin : Same as `pairwise_distances_argmin_min` but only\n    returns the argmins.\n\nExamples\n--------\n>>> from sklearn.metrics.pairwise import pairwise_distances_argmin_min\n>>> X = [[0, 0, 0], [1, 1, 1]]\n>>> Y = [[1, 0, 0], [1, 1, 0]]\n>>> argmin, distances = pairwise_distances_argmin_min(X, Y)\n>>> argmin\narray([0, 1])\n>>> distances\narray([1., 1.])" .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PairwiseDistancesChunkedMethod
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PairwiseDistancesChunkedMethod> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Class> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PairwiseDistancesChunkedMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PairwiseDistancesChunkedMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MetricsModule> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PairwiseDistancesChunkedMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PerformanceCalculationMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PairwiseDistancesChunkedMethod> <http://www.w3.org/2000/01/rdf-schema#comment> "Generate a distance matrix chunk by chunk with optional reduction.\n\nIn cases where not all of a pairwise distance matrix needs to be\nstored at once, this is used to calculate pairwise distances in\n``working_memory``-sized chunks.  If ``reduce_func`` is given, it is\nrun on each chunk and its return values are concatenated into lists,\narrays or sparse matrices.\n\nParameters\n----------\nX : {array-like, sparse matrix} of shape (n_samples_X, n_samples_X) or             (n_samples_X, n_features)\n    Array of pairwise distances between samples, or a feature array.\n    The shape the array should be (n_samples_X, n_samples_X) if\n    metric='precomputed' and (n_samples_X, n_features) otherwise.\n\nY : {array-like, sparse matrix} of shape (n_samples_Y, n_features), default=None\n    An optional second feature array. Only allowed if\n    metric != \"precomputed\".\n\nreduce_func : callable, default=None\n    The function which is applied on each chunk of the distance matrix,\n    reducing it to needed values.  ``reduce_func(D_chunk, start)``\n    is called repeatedly, where ``D_chunk`` is a contiguous vertical\n    slice of the pairwise distance matrix, starting at row ``start``.\n    It should return one of: None; an array, a list, or a sparse matrix\n    of length ``D_chunk.shape[0]``; or a tuple of such objects.\n    Returning None is useful for in-place operations, rather than\n    reductions.\n\n    If None, pairwise_distances_chunked returns a generator of vertical\n    chunks of the distance matrix.\n\nmetric : str or callable, default='euclidean'\n    The metric to use when calculating distance between instances in a\n    feature array. If metric is a string, it must be one of the options\n    allowed by scipy.spatial.distance.pdist for its metric parameter,\n    or a metric listed in pairwise.PAIRWISE_DISTANCE_FUNCTIONS.\n    If metric is \"precomputed\", X is assumed to be a distance matrix.\n    Alternatively, if metric is a callable function, it is called on\n    each pair of instances (rows) and the resulting value recorded.\n    The callable should take two arrays from X as input and return a\n    value indicating the distance between them.\n\nn_jobs : int, default=None\n    The number of jobs to use for the computation. This works by\n    breaking down the pairwise matrix into n_jobs even slices and\n    computing them in parallel.\n\n    ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n    ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n    for more details.\n\nworking_memory : float, default=None\n    The sought maximum memory for temporary distance matrix chunks.\n    When None (default), the value of\n    ``sklearn.get_config()['working_memory']`` is used.\n\n**kwds : optional keyword parameters\n    Any further parameters are passed directly to the distance function.\n    If using a scipy.spatial.distance metric, the parameters are still\n    metric dependent. See the scipy docs for usage examples.\n\nYields\n------\nD_chunk : {ndarray, sparse matrix}\n    A contiguous slice of distance matrix, optionally processed by\n    ``reduce_func``.\n\nExamples\n--------\nWithout reduce_func:\n\n>>> import numpy as np\n>>> from sklearn.metrics import pairwise_distances_chunked\n>>> X = np.random.RandomState(0).rand(5, 3)\n>>> D_chunk = next(pairwise_distances_chunked(X))\n>>> D_chunk\narray([[0.  ..., 0.29..., 0.41..., 0.19..., 0.57...],\n       [0.29..., 0.  ..., 0.57..., 0.41..., 0.76...],\n       [0.41..., 0.57..., 0.  ..., 0.44..., 0.90...],\n       [0.19..., 0.41..., 0.44..., 0.  ..., 0.51...],\n       [0.57..., 0.76..., 0.90..., 0.51..., 0.  ...]])\n\nRetrieve all neighbors and average distance within radius r:\n\n>>> r = .2\n>>> def reduce_func(D_chunk, start):\n...     neigh = [np.flatnonzero(d < r) for d in D_chunk]\n...     avg_dist = (D_chunk * (D_chunk < r)).mean(axis=1)\n...     return neigh, avg_dist\n>>> gen = pairwise_distances_chunked(X, reduce_func=reduce_func)\n>>> neigh, avg_dist = next(gen)\n>>> neigh\n[array([0, 3]), array([1]), array([2]), array([0, 3]), array([4])]\n>>> avg_dist\narray([0.039..., 0.        , 0.        , 0.039..., 0.        ])\n\nWhere r is defined per sample, we need to make use of ``start``:\n\n>>> r = [.2, .4, .4, .3, .1]\n>>> def reduce_func(D_chunk, start):\n...     neigh = [np.flatnonzero(d < r[i])\n...              for i, d in enumerate(D_chunk, start)]\n...     return neigh\n>>> neigh = next(pairwise_distances_chunked(X, reduce_func=reduce_func))\n>>> neigh\n[array([0, 3]), array([0, 1]), array([2]), array([0, 3]), array([4])]\n\nForce row-by-row generation by reducing ``working_memory``:\n\n>>> gen = pairwise_distances_chunked(X, reduce_func=reduce_func,\n...                                  working_memory=0)\n>>> next(gen)\n[array([0, 3])]\n>>> next(gen)\n[array([0, 1])]" .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PairwiseDistancesMethod
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PairwiseDistancesMethod> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Class> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PairwiseDistancesMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PairwiseDistancesMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MetricsModule> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PairwiseDistancesMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PerformanceCalculationMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PairwiseDistancesMethod> <http://www.w3.org/2000/01/rdf-schema#comment> "Compute the distance matrix from a vector array X and optional Y.\n\nThis method takes either a vector array or a distance matrix, and returns\na distance matrix. If the input is a vector array, the distances are\ncomputed. If the input is a distances matrix, it is returned instead.\n\nThis method provides a safe way to take a distance matrix as input, while\npreserving compatibility with many other algorithms that take a vector\narray.\n\nIf Y is given (default is None), then the returned matrix is the pairwise\ndistance between the arrays from both X and Y.\n\nValid values for metric are:\n\n- From scikit-learn: ['cityblock', 'cosine', 'euclidean', 'l1', 'l2',\n  'manhattan']. These metrics support sparse matrix\n  inputs.\n  ['nan_euclidean'] but it does not yet support sparse matrices.\n\n- From scipy.spatial.distance: ['braycurtis', 'canberra', 'chebyshev',\n  'correlation', 'dice', 'hamming', 'jaccard', 'kulsinski', 'mahalanobis',\n  'minkowski', 'rogerstanimoto', 'russellrao', 'seuclidean',\n  'sokalmichener', 'sokalsneath', 'sqeuclidean', 'yule']\n  See the documentation for scipy.spatial.distance for details on these\n  metrics. These metrics do not support sparse matrix inputs.\n\n.. note::\n    `'kulsinski'` is deprecated from SciPy 1.9 and will be removed in SciPy 1.11.\n\n.. note::\n    `'matching'` has been removed in SciPy 1.9 (use `'hamming'` instead).\n\nNote that in the case of 'cityblock', 'cosine' and 'euclidean' (which are\nvalid scipy.spatial.distance metrics), the scikit-learn implementation\nwill be used, which is faster and has support for sparse matrices (except\nfor 'cityblock'). For a verbose description of the metrics from\nscikit-learn, see :func:`sklearn.metrics.pairwise.distance_metrics`\nfunction.\n\nRead more in the :ref:`User Guide <metrics>`.\n\nParameters\n----------\nX : {array-like, sparse matrix} of shape (n_samples_X, n_samples_X) or             (n_samples_X, n_features)\n    Array of pairwise distances between samples, or a feature array.\n    The shape of the array should be (n_samples_X, n_samples_X) if\n    metric == \"precomputed\" and (n_samples_X, n_features) otherwise.\n\nY : {array-like, sparse matrix} of shape (n_samples_Y, n_features), default=None\n    An optional second feature array. Only allowed if\n    metric != \"precomputed\".\n\nmetric : str or callable, default='euclidean'\n    The metric to use when calculating distance between instances in a\n    feature array. If metric is a string, it must be one of the options\n    allowed by scipy.spatial.distance.pdist for its metric parameter, or\n    a metric listed in ``pairwise.PAIRWISE_DISTANCE_FUNCTIONS``.\n    If metric is \"precomputed\", X is assumed to be a distance matrix.\n    Alternatively, if metric is a callable function, it is called on each\n    pair of instances (rows) and the resulting value recorded. The callable\n    should take two arrays from X as input and return a value indicating\n    the distance between them.\n\nn_jobs : int, default=None\n    The number of jobs to use for the computation. This works by breaking\n    down the pairwise matrix into n_jobs even slices and computing them in\n    parallel.\n\n    ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n    ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n    for more details.\n\nforce_all_finite : bool or 'allow-nan', default=True\n    Whether to raise an error on np.inf, np.nan, pd.NA in array. Ignored\n    for a metric listed in ``pairwise.PAIRWISE_DISTANCE_FUNCTIONS``. The\n    possibilities are:\n\n    - True: Force all values of array to be finite.\n    - False: accepts np.inf, np.nan, pd.NA in array.\n    - 'allow-nan': accepts only np.nan and pd.NA values in array. Values\n      cannot be infinite.\n\n    .. versionadded:: 0.22\n       ``force_all_finite`` accepts the string ``'allow-nan'``.\n\n    .. versionchanged:: 0.23\n       Accepts `pd.NA` and converts it into `np.nan`.\n\n**kwds : optional keyword parameters\n    Any further parameters are passed directly to the distance function.\n    If using a scipy.spatial.distance metric, the parameters are still\n    metric dependent. See the scipy docs for usage examples.\n\nReturns\n-------\nD : ndarray of shape (n_samples_X, n_samples_X) or             (n_samples_X, n_samples_Y)\n    A distance matrix D such that D_{i, j} is the distance between the\n    ith and jth vectors of the given matrix X, if Y is None.\n    If Y is not None, then D_{i, j} is the distance between the ith array\n    from X and the jth array from Y.\n\nSee Also\n--------\npairwise_distances_chunked : Performs the same calculation as this\n    function, but returns a generator of chunks of the distance matrix, in\n    order to limit memory usage.\nsklearn.metrics.pairwise.paired_distances : Computes the distances between\n    corresponding elements of two arrays.\n\nExamples\n--------\n>>> from sklearn.metrics.pairwise import pairwise_distances\n>>> X = [[0, 0, 0], [1, 1, 1]]\n>>> Y = [[1, 0, 0], [1, 1, 0]]\n>>> pairwise_distances(X, Y, metric='sqeuclidean')\narray([[1., 2.],\n       [2., 1.]])" .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PairwiseKernelsMethod
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PairwiseKernelsMethod> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Class> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PairwiseKernelsMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PairwiseKernelsMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MetricsModule> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PairwiseKernelsMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PerformanceCalculationMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PairwiseKernelsMethod> <http://www.w3.org/2000/01/rdf-schema#comment> "Compute the kernel between arrays X and optional array Y.\n\nThis method takes either a vector array or a kernel matrix, and returns\na kernel matrix. If the input is a vector array, the kernels are\ncomputed. If the input is a kernel matrix, it is returned instead.\n\nThis method provides a safe way to take a kernel matrix as input, while\npreserving compatibility with many other algorithms that take a vector\narray.\n\nIf Y is given (default is None), then the returned matrix is the pairwise\nkernel between the arrays from both X and Y.\n\nValid values for metric are:\n    ['additive_chi2', 'chi2', 'linear', 'poly', 'polynomial', 'rbf',\n    'laplacian', 'sigmoid', 'cosine']\n\nRead more in the :ref:`User Guide <metrics>`.\n\nParameters\n----------\nX : {array-like, sparse matrix}  of shape (n_samples_X, n_samples_X) or             (n_samples_X, n_features)\n    Array of pairwise kernels between samples, or a feature array.\n    The shape of the array should be (n_samples_X, n_samples_X) if\n    metric == \"precomputed\" and (n_samples_X, n_features) otherwise.\n\nY : {array-like, sparse matrix} of shape (n_samples_Y, n_features), default=None\n    A second feature array only if X has shape (n_samples_X, n_features).\n\nmetric : str or callable, default=\"linear\"\n    The metric to use when calculating kernel between instances in a\n    feature array. If metric is a string, it must be one of the metrics\n    in ``pairwise.PAIRWISE_KERNEL_FUNCTIONS``.\n    If metric is \"precomputed\", X is assumed to be a kernel matrix.\n    Alternatively, if metric is a callable function, it is called on each\n    pair of instances (rows) and the resulting value recorded. The callable\n    should take two rows from X as input and return the corresponding\n    kernel value as a single number. This means that callables from\n    :mod:`sklearn.metrics.pairwise` are not allowed, as they operate on\n    matrices, not single samples. Use the string identifying the kernel\n    instead.\n\nfilter_params : bool, default=False\n    Whether to filter invalid parameters or not.\n\nn_jobs : int, default=None\n    The number of jobs to use for the computation. This works by breaking\n    down the pairwise matrix into n_jobs even slices and computing them in\n    parallel.\n\n    ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n    ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n    for more details.\n\n**kwds : optional keyword parameters\n    Any further parameters are passed directly to the kernel function.\n\nReturns\n-------\nK : ndarray of shape (n_samples_X, n_samples_X) or (n_samples_X, n_samples_Y)\n    A kernel matrix K such that K_{i, j} is the kernel between the\n    ith and jth vectors of the given matrix X, if Y is None.\n    If Y is not None, then K_{i, j} is the kernel between the ith array\n    from X and the jth array from Y.\n\nNotes\n-----\nIf metric is 'precomputed', Y is ignored and X is returned.\n\nExamples\n--------\n>>> from sklearn.metrics.pairwise import pairwise_kernels\n>>> X = [[0, 0, 0], [1, 1, 1]]\n>>> Y = [[1, 0, 0], [1, 1, 0]]\n>>> pairwise_kernels(X, Y, metric='linear')\narray([[0., 0.],\n       [1., 2.]])" .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PerformanceCalculation
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PerformanceCalculationMethod
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PrecisionRecallCurveMethod
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PrecisionRecallCurveMethod> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Class> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PrecisionRecallCurveMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PrecisionRecallCurveMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MetricsModule> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PrecisionRecallCurveMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PerformanceCalculationMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PrecisionRecallCurveMethod> <http://www.w3.org/2000/01/rdf-schema#comment> "Compute precision-recall pairs for different probability thresholds.\n\nNote: this implementation is restricted to the binary classification task.\n\nThe precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\ntrue positives and ``fp`` the number of false positives. The precision is\nintuitively the ability of the classifier not to label as positive a sample\nthat is negative.\n\nThe recall is the ratio ``tp / (tp + fn)`` where ``tp`` is the number of\ntrue positives and ``fn`` the number of false negatives. The recall is\nintuitively the ability of the classifier to find all the positive samples.\n\nThe last precision and recall values are 1. and 0. respectively and do not\nhave a corresponding threshold. This ensures that the graph starts on the\ny axis.\n\nThe first precision and recall values are precision=class balance and recall=1.0\nwhich corresponds to a classifier that always predicts the positive class.\n\nRead more in the :ref:`User Guide <precision_recall_f_measure_metrics>`.\n\nParameters\n----------\ny_true : array-like of shape (n_samples,)\n    True binary labels. If labels are not either {-1, 1} or {0, 1}, then\n    pos_label should be explicitly given.\n\nprobas_pred : array-like of shape (n_samples,)\n    Target scores, can either be probability estimates of the positive\n    class, or non-thresholded measure of decisions (as returned by\n    `decision_function` on some classifiers).\n\npos_label : int, float, bool or str, default=None\n    The label of the positive class.\n    When ``pos_label=None``, if y_true is in {-1, 1} or {0, 1},\n    ``pos_label`` is set to 1, otherwise an error will be raised.\n\nsample_weight : array-like of shape (n_samples,), default=None\n    Sample weights.\n\ndrop_intermediate : bool, default=False\n    Whether to drop some suboptimal thresholds which would not appear\n    on a plotted precision-recall curve. This is useful in order to create\n    lighter precision-recall curves.\n\n    .. versionadded:: 1.3\n\nReturns\n-------\nprecision : ndarray of shape (n_thresholds + 1,)\n    Precision values such that element i is the precision of\n    predictions with score >= thresholds[i] and the last element is 1.\n\nrecall : ndarray of shape (n_thresholds + 1,)\n    Decreasing recall values such that element i is the recall of\n    predictions with score >= thresholds[i] and the last element is 0.\n\nthresholds : ndarray of shape (n_thresholds,)\n    Increasing thresholds on the decision function used to compute\n    precision and recall where `n_thresholds = len(np.unique(probas_pred))`.\n\nSee Also\n--------\nPrecisionRecallDisplay.from_estimator : Plot Precision Recall Curve given\n    a binary classifier.\nPrecisionRecallDisplay.from_predictions : Plot Precision Recall Curve\n    using predictions from a binary classifier.\naverage_precision_score : Compute average precision from prediction scores.\ndet_curve: Compute error rates for different probability thresholds.\nroc_curve : Compute Receiver operating characteristic (ROC) curve.\n\nExamples\n--------\n>>> import numpy as np\n>>> from sklearn.metrics import precision_recall_curve\n>>> y_true = np.array([0, 0, 1, 1])\n>>> y_scores = np.array([0.1, 0.4, 0.35, 0.8])\n>>> precision, recall, thresholds = precision_recall_curve(\n...     y_true, y_scores)\n>>> precision\narray([0.5       , 0.66666667, 0.5       , 1.        , 1.        ])\n>>> recall\narray([1. , 1. , 0.5, 0.5, 0. ])\n>>> thresholds\narray([0.1 , 0.35, 0.4 , 0.8 ])" .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PrecisionRecallFscoreSupportMethod
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PrecisionRecallFscoreSupportMethod> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Class> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PrecisionRecallFscoreSupportMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PrecisionRecallFscoreSupportMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MetricsModule> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PrecisionRecallFscoreSupportMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PerformanceCalculationMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PrecisionRecallFscoreSupportMethod> <http://www.w3.org/2000/01/rdf-schema#comment> "Compute precision, recall, F-measure and support for each class.\n\nThe precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\ntrue positives and ``fp`` the number of false positives. The precision is\nintuitively the ability of the classifier not to label a negative sample as\npositive.\n\nThe recall is the ratio ``tp / (tp + fn)`` where ``tp`` is the number of\ntrue positives and ``fn`` the number of false negatives. The recall is\nintuitively the ability of the classifier to find all the positive samples.\n\nThe F-beta score can be interpreted as a weighted harmonic mean of\nthe precision and recall, where an F-beta score reaches its best\nvalue at 1 and worst score at 0.\n\nThe F-beta score weights recall more than precision by a factor of\n``beta``. ``beta == 1.0`` means recall and precision are equally important.\n\nThe support is the number of occurrences of each class in ``y_true``.\n\nSupport beyond term:`binary` targets is achieved by treating :term:`multiclass`\nand :term:`multilabel` data as a collection of binary problems, one for each\nlabel. For the :term:`binary` case, setting `average='binary'` will return\nmetrics for `pos_label`. If `average` is not `'binary'`, `pos_label` is ignored\nand metrics for both classes are computed, then averaged or both returned (when\n`average=None`). Similarly, for :term:`multiclass` and :term:`multilabel` targets,\nmetrics for all `labels` are either returned or averaged depending on the `average`\nparameter. Use `labels` specify the set of labels to calculate metrics for.\n\nRead more in the :ref:`User Guide <precision_recall_f_measure_metrics>`.\n\nParameters\n----------\ny_true : 1d array-like, or label indicator array / sparse matrix\n    Ground truth (correct) target values.\n\ny_pred : 1d array-like, or label indicator array / sparse matrix\n    Estimated targets as returned by a classifier.\n\nbeta : float, default=1.0\n    The strength of recall versus precision in the F-score.\n\nlabels : array-like, default=None\n    The set of labels to include when `average != 'binary'`, and their\n    order if `average is None`. Labels present in the data can be\n    excluded, for example in multiclass classification to exclude a \"negative\n    class\". Labels not present in the data can be included and will be\n    \"assigned\" 0 samples. For multilabel targets, labels are column indices.\n    By default, all labels in `y_true` and `y_pred` are used in sorted order.\n\npos_label : int, float, bool or str, default=1\n    The class to report if `average='binary'` and the data is binary,\n    otherwise this parameter is ignored.\n    For multiclass or multilabel targets, set `labels=[pos_label]` and\n    `average != 'binary'` to report metrics for one label only.\n\naverage : {'binary', 'micro', 'macro', 'samples', 'weighted'},             default=None\n    If ``None``, the metrics for each class are returned. Otherwise, this\n    determines the type of averaging performed on the data:\n\n    ``'binary'``:\n        Only report results for the class specified by ``pos_label``.\n        This is applicable only if targets (``y_{true,pred}``) are binary.\n    ``'micro'``:\n        Calculate metrics globally by counting the total true positives,\n        false negatives and false positives.\n    ``'macro'``:\n        Calculate metrics for each label, and find their unweighted\n        mean.  This does not take label imbalance into account.\n    ``'weighted'``:\n        Calculate metrics for each label, and find their average weighted\n        by support (the number of true instances for each label). This\n        alters 'macro' to account for label imbalance; it can result in an\n        F-score that is not between precision and recall.\n    ``'samples'``:\n        Calculate metrics for each instance, and find their average (only\n        meaningful for multilabel classification where this differs from\n        :func:`accuracy_score`).\n\nwarn_for : list, tuple or set, for internal use\n    This determines which warnings will be made in the case that this\n    function is being used to return only one of its metrics.\n\nsample_weight : array-like of shape (n_samples,), default=None\n    Sample weights.\n\nzero_division : {\"warn\", 0.0, 1.0, np.nan}, default=\"warn\"\n    Sets the value to return when there is a zero division:\n       - recall: when there are no positive labels\n       - precision: when there are no positive predictions\n       - f-score: both\n\n    Notes:\n    - If set to \"warn\", this acts like 0, but a warning is also raised.\n    - If set to `np.nan`, such values will be excluded from the average.\n\n    .. versionadded:: 1.3\n       `np.nan` option was added.\n\nReturns\n-------\nprecision : float (if average is not None) or array of float, shape =        [n_unique_labels]\n    Precision score.\n\nrecall : float (if average is not None) or array of float, shape =        [n_unique_labels]\n    Recall score.\n\nfbeta_score : float (if average is not None) or array of float, shape =        [n_unique_labels]\n    F-beta score.\n\nsupport : None (if average is not None) or array of int, shape =        [n_unique_labels]\n    The number of occurrences of each label in ``y_true``.\n\nNotes\n-----\nWhen ``true positive + false positive == 0``, precision is undefined.\nWhen ``true positive + false negative == 0``, recall is undefined. When\n``true positive + false negative + false positive == 0``, f-score is\nundefined. In such cases, by default the metric will be set to 0, and\n``UndefinedMetricWarning`` will be raised. This behavior can be modified\nwith ``zero_division``.\n\nReferences\n----------\n.. [1] `Wikipedia entry for the Precision and recall\n       <https://en.wikipedia.org/wiki/Precision_and_recall>`_.\n\n.. [2] `Wikipedia entry for the F1-score\n       <https://en.wikipedia.org/wiki/F1_score>`_.\n\n.. [3] `Discriminative Methods for Multi-labeled Classification Advances\n       in Knowledge Discovery and Data Mining (2004), pp. 22-30 by Shantanu\n       Godbole, Sunita Sarawagi\n       <http://www.godbole.net/shantanu/pubs/multilabelsvm-pakdd04.pdf>`_.\n\nExamples\n--------\n>>> import numpy as np\n>>> from sklearn.metrics import precision_recall_fscore_support\n>>> y_true = np.array(['cat', 'dog', 'pig', 'cat', 'dog', 'pig'])\n>>> y_pred = np.array(['cat', 'pig', 'dog', 'cat', 'cat', 'dog'])\n>>> precision_recall_fscore_support(y_true, y_pred, average='macro')\n(0.22..., 0.33..., 0.26..., None)\n>>> precision_recall_fscore_support(y_true, y_pred, average='micro')\n(0.33..., 0.33..., 0.33..., None)\n>>> precision_recall_fscore_support(y_true, y_pred, average='weighted')\n(0.22..., 0.33..., 0.26..., None)\n\nIt is possible to compute per-label precisions, recalls, F1-scores and\nsupports instead of averaging:\n\n>>> precision_recall_fscore_support(y_true, y_pred, average=None,\n... labels=['pig', 'dog', 'cat'])\n(array([0.        , 0.        , 0.66...]),\n array([0., 0., 1.]), array([0. , 0. , 0.8]),\n array([2, 2, 2]))" .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PrecisionScoreMethod
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PrecisionScoreMethod> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Class> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PrecisionScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PrecisionScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MetricsModule> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PrecisionScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PerformanceCalculationMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PrecisionScoreMethod> <http://www.w3.org/2000/01/rdf-schema#comment> "Compute the precision.\n\nThe precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\ntrue positives and ``fp`` the number of false positives. The precision is\nintuitively the ability of the classifier not to label as positive a sample\nthat is negative.\n\nThe best value is 1 and the worst value is 0.\n\nSupport beyond term:`binary` targets is achieved by treating :term:`multiclass`\nand :term:`multilabel` data as a collection of binary problems, one for each\nlabel. For the :term:`binary` case, setting `average='binary'` will return\nprecision for `pos_label`. If `average` is not `'binary'`, `pos_label` is ignored\nand precision for both classes are computed, then averaged or both returned (when\n`average=None`). Similarly, for :term:`multiclass` and :term:`multilabel` targets,\nprecision for all `labels` are either returned or averaged depending on the\n`average` parameter. Use `labels` specify the set of labels to calculate precision\nfor.\n\nRead more in the :ref:`User Guide <precision_recall_f_measure_metrics>`.\n\nParameters\n----------\ny_true : 1d array-like, or label indicator array / sparse matrix\n    Ground truth (correct) target values.\n\ny_pred : 1d array-like, or label indicator array / sparse matrix\n    Estimated targets as returned by a classifier.\n\nlabels : array-like, default=None\n    The set of labels to include when `average != 'binary'`, and their\n    order if `average is None`. Labels present in the data can be\n    excluded, for example in multiclass classification to exclude a \"negative\n    class\". Labels not present in the data can be included and will be\n    \"assigned\" 0 samples. For multilabel targets, labels are column indices.\n    By default, all labels in `y_true` and `y_pred` are used in sorted order.\n\n    .. versionchanged:: 0.17\n       Parameter `labels` improved for multiclass problem.\n\npos_label : int, float, bool or str, default=1\n    The class to report if `average='binary'` and the data is binary,\n    otherwise this parameter is ignored.\n    For multiclass or multilabel targets, set `labels=[pos_label]` and\n    `average != 'binary'` to report metrics for one label only.\n\naverage : {'micro', 'macro', 'samples', 'weighted', 'binary'} or None,             default='binary'\n    This parameter is required for multiclass/multilabel targets.\n    If ``None``, the scores for each class are returned. Otherwise, this\n    determines the type of averaging performed on the data:\n\n    ``'binary'``:\n        Only report results for the class specified by ``pos_label``.\n        This is applicable only if targets (``y_{true,pred}``) are binary.\n    ``'micro'``:\n        Calculate metrics globally by counting the total true positives,\n        false negatives and false positives.\n    ``'macro'``:\n        Calculate metrics for each label, and find their unweighted\n        mean.  This does not take label imbalance into account.\n    ``'weighted'``:\n        Calculate metrics for each label, and find their average weighted\n        by support (the number of true instances for each label). This\n        alters 'macro' to account for label imbalance; it can result in an\n        F-score that is not between precision and recall.\n    ``'samples'``:\n        Calculate metrics for each instance, and find their average (only\n        meaningful for multilabel classification where this differs from\n        :func:`accuracy_score`).\n\nsample_weight : array-like of shape (n_samples,), default=None\n    Sample weights.\n\nzero_division : {\"warn\", 0.0, 1.0, np.nan}, default=\"warn\"\n    Sets the value to return when there is a zero division.\n\n    Notes:\n    - If set to \"warn\", this acts like 0, but a warning is also raised.\n    - If set to `np.nan`, such values will be excluded from the average.\n\n    .. versionadded:: 1.3\n       `np.nan` option was added.\n\nReturns\n-------\nprecision : float (if average is not None) or array of float of shape                 (n_unique_labels,)\n    Precision of the positive class in binary classification or weighted\n    average of the precision of each class for the multiclass task.\n\nSee Also\n--------\nprecision_recall_fscore_support : Compute precision, recall, F-measure and\n    support for each class.\nrecall_score :  Compute the ratio ``tp / (tp + fn)`` where ``tp`` is the\n    number of true positives and ``fn`` the number of false negatives.\nPrecisionRecallDisplay.from_estimator : Plot precision-recall curve given\n    an estimator and some data.\nPrecisionRecallDisplay.from_predictions : Plot precision-recall curve given\n    binary class predictions.\nmultilabel_confusion_matrix : Compute a confusion matrix for each class or\n    sample.\n\nNotes\n-----\nWhen ``true positive + false positive == 0``, precision returns 0 and\nraises ``UndefinedMetricWarning``. This behavior can be\nmodified with ``zero_division``.\n\nExamples\n--------\n>>> import numpy as np\n>>> from sklearn.metrics import precision_score\n>>> y_true = [0, 1, 2, 0, 1, 2]\n>>> y_pred = [0, 2, 1, 0, 0, 1]\n>>> precision_score(y_true, y_pred, average='macro')\n0.22...\n>>> precision_score(y_true, y_pred, average='micro')\n0.33...\n>>> precision_score(y_true, y_pred, average='weighted')\n0.22...\n>>> precision_score(y_true, y_pred, average=None)\narray([0.66..., 0.        , 0.        ])\n>>> y_pred = [0, 0, 0, 0, 0, 0]\n>>> precision_score(y_true, y_pred, average=None)\narray([0.33..., 0.        , 0.        ])\n>>> precision_score(y_true, y_pred, average=None, zero_division=1)\narray([0.33..., 1.        , 1.        ])\n>>> precision_score(y_true, y_pred, average=None, zero_division=np.nan)\narray([0.33...,        nan,        nan])\n\n>>> # multilabel classification\n>>> y_true = [[0, 0, 0], [1, 1, 1], [0, 1, 1]]\n>>> y_pred = [[0, 0, 0], [1, 1, 1], [1, 1, 0]]\n>>> precision_score(y_true, y_pred, average=None)\narray([0.5, 1. , 1. ])" .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#R2ScoreMethod
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#R2ScoreMethod> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Class> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#R2ScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#R2ScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MetricsModule> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#R2ScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PerformanceCalculationMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#R2ScoreMethod> <http://www.w3.org/2000/01/rdf-schema#comment> ":math:`R^2` (coefficient of determination) regression score function.\n\nBest possible score is 1.0 and it can be negative (because the\nmodel can be arbitrarily worse). In the general case when the true y is\nnon-constant, a constant model that always predicts the average y\ndisregarding the input features would get a :math:`R^2` score of 0.0.\n\nIn the particular case when ``y_true`` is constant, the :math:`R^2` score\nis not finite: it is either ``NaN`` (perfect predictions) or ``-Inf``\n(imperfect predictions). To prevent such non-finite numbers to pollute\nhigher-level experiments such as a grid search cross-validation, by default\nthese cases are replaced with 1.0 (perfect predictions) or 0.0 (imperfect\npredictions) respectively. You can set ``force_finite`` to ``False`` to\nprevent this fix from happening.\n\nNote: when the prediction residuals have zero mean, the :math:`R^2` score\nis identical to the\n:func:`Explained Variance score <explained_variance_score>`.\n\nRead more in the :ref:`User Guide <r2_score>`.\n\nParameters\n----------\ny_true : array-like of shape (n_samples,) or (n_samples, n_outputs)\n    Ground truth (correct) target values.\n\ny_pred : array-like of shape (n_samples,) or (n_samples, n_outputs)\n    Estimated target values.\n\nsample_weight : array-like of shape (n_samples,), default=None\n    Sample weights.\n\nmultioutput : {'raw_values', 'uniform_average', 'variance_weighted'},             array-like of shape (n_outputs,) or None, default='uniform_average'\n\n    Defines aggregating of multiple output scores.\n    Array-like value defines weights used to average scores.\n    Default is \"uniform_average\".\n\n    'raw_values' :\n        Returns a full set of scores in case of multioutput input.\n\n    'uniform_average' :\n        Scores of all outputs are averaged with uniform weight.\n\n    'variance_weighted' :\n        Scores of all outputs are averaged, weighted by the variances\n        of each individual output.\n\n    .. versionchanged:: 0.19\n        Default value of multioutput is 'uniform_average'.\n\nforce_finite : bool, default=True\n    Flag indicating if ``NaN`` and ``-Inf`` scores resulting from constant\n    data should be replaced with real numbers (``1.0`` if prediction is\n    perfect, ``0.0`` otherwise). Default is ``True``, a convenient setting\n    for hyperparameters' search procedures (e.g. grid search\n    cross-validation).\n\n    .. versionadded:: 1.1\n\nReturns\n-------\nz : float or ndarray of floats\n    The :math:`R^2` score or ndarray of scores if 'multioutput' is\n    'raw_values'.\n\nNotes\n-----\nThis is not a symmetric function.\n\nUnlike most other scores, :math:`R^2` score may be negative (it need not\nactually be the square of a quantity R).\n\nThis metric is not well-defined for single samples and will return a NaN\nvalue if n_samples is less than two.\n\nReferences\n----------\n.. [1] `Wikipedia entry on the Coefficient of determination\n        <https://en.wikipedia.org/wiki/Coefficient_of_determination>`_\n\nExamples\n--------\n>>> from sklearn.metrics import r2_score\n>>> y_true = [3, -0.5, 2, 7]\n>>> y_pred = [2.5, 0.0, 2, 8]\n>>> r2_score(y_true, y_pred)\n0.948...\n>>> y_true = [[0.5, 1], [-1, 1], [7, -6]]\n>>> y_pred = [[0, 2], [-1, 2], [8, -5]]\n>>> r2_score(y_true, y_pred,\n...          multioutput='variance_weighted')\n0.938...\n>>> y_true = [1, 2, 3]\n>>> y_pred = [1, 2, 3]\n>>> r2_score(y_true, y_pred)\n1.0\n>>> y_true = [1, 2, 3]\n>>> y_pred = [2, 2, 2]\n>>> r2_score(y_true, y_pred)\n0.0\n>>> y_true = [1, 2, 3]\n>>> y_pred = [3, 2, 1]\n>>> r2_score(y_true, y_pred)\n-3.0\n>>> y_true = [-2, -2, -2]\n>>> y_pred = [-2, -2, -2]\n>>> r2_score(y_true, y_pred)\n1.0\n>>> r2_score(y_true, y_pred, force_finite=False)\nnan\n>>> y_true = [-2, -2, -2]\n>>> y_pred = [-2, -2, -2 + 1e-8]\n>>> r2_score(y_true, y_pred)\n0.0\n>>> r2_score(y_true, y_pred, force_finite=False)\n-inf" .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RandScoreMethod
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RandScoreMethod> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Class> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RandScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RandScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MetricsModule> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RandScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PerformanceCalculationMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RandScoreMethod> <http://www.w3.org/2000/01/rdf-schema#comment> "Rand index.\n\nThe Rand Index computes a similarity measure between two clusterings\nby considering all pairs of samples and counting pairs that are\nassigned in the same or different clusters in the predicted and\ntrue clusterings [1]_ [2]_.\n\nThe raw RI score [3]_ is:\n\n    RI = (number of agreeing pairs) / (number of pairs)\n\nRead more in the :ref:`User Guide <rand_score>`.\n\nParameters\n----------\nlabels_true : array-like of shape (n_samples,), dtype=integral\n    Ground truth class labels to be used as a reference.\n\nlabels_pred : array-like of shape (n_samples,), dtype=integral\n    Cluster labels to evaluate.\n\nReturns\n-------\nRI : float\n   Similarity score between 0.0 and 1.0, inclusive, 1.0 stands for\n   perfect match.\n\nSee Also\n--------\nadjusted_rand_score: Adjusted Rand Score.\nadjusted_mutual_info_score: Adjusted Mutual Information.\n\nReferences\n----------\n.. [1] :doi:`Hubert, L., Arabie, P. \"Comparing partitions.\"\n   Journal of Classification 2, 193218 (1985).\n   <10.1007/BF01908075>`.\n\n.. [2] `Wikipedia: Simple Matching Coefficient\n    <https://en.wikipedia.org/wiki/Simple_matching_coefficient>`_\n\n.. [3] `Wikipedia: Rand Index <https://en.wikipedia.org/wiki/Rand_index>`_\n\nExamples\n--------\nPerfectly matching labelings have a score of 1 even\n\n  >>> from sklearn.metrics.cluster import rand_score\n  >>> rand_score([0, 0, 1, 1], [1, 1, 0, 0])\n  1.0\n\nLabelings that assign all classes members to the same clusters\nare complete but may not always be pure, hence penalized:\n\n  >>> rand_score([0, 0, 1, 2], [0, 0, 1, 1])\n  0.83..." .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RecallScoreMethod
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RecallScoreMethod> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Class> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RecallScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RecallScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MetricsModule> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RecallScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PerformanceCalculationMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RecallScoreMethod> <http://www.w3.org/2000/01/rdf-schema#comment> "Compute the recall.\n\nThe recall is the ratio ``tp / (tp + fn)`` where ``tp`` is the number of\ntrue positives and ``fn`` the number of false negatives. The recall is\nintuitively the ability of the classifier to find all the positive samples.\n\nThe best value is 1 and the worst value is 0.\n\nSupport beyond term:`binary` targets is achieved by treating :term:`multiclass`\nand :term:`multilabel` data as a collection of binary problems, one for each\nlabel. For the :term:`binary` case, setting `average='binary'` will return\nrecall for `pos_label`. If `average` is not `'binary'`, `pos_label` is ignored\nand recall for both classes are computed then averaged or both returned (when\n`average=None`). Similarly, for :term:`multiclass` and :term:`multilabel` targets,\nrecall for all `labels` are either returned or averaged depending on the `average`\nparameter. Use `labels` specify the set of labels to calculate recall for.\n\nRead more in the :ref:`User Guide <precision_recall_f_measure_metrics>`.\n\nParameters\n----------\ny_true : 1d array-like, or label indicator array / sparse matrix\n    Ground truth (correct) target values.\n\ny_pred : 1d array-like, or label indicator array / sparse matrix\n    Estimated targets as returned by a classifier.\n\nlabels : array-like, default=None\n    The set of labels to include when `average != 'binary'`, and their\n    order if `average is None`. Labels present in the data can be\n    excluded, for example in multiclass classification to exclude a \"negative\n    class\". Labels not present in the data can be included and will be\n    \"assigned\" 0 samples. For multilabel targets, labels are column indices.\n    By default, all labels in `y_true` and `y_pred` are used in sorted order.\n\n    .. versionchanged:: 0.17\n       Parameter `labels` improved for multiclass problem.\n\npos_label : int, float, bool or str, default=1\n    The class to report if `average='binary'` and the data is binary,\n    otherwise this parameter is ignored.\n    For multiclass or multilabel targets, set `labels=[pos_label]` and\n    `average != 'binary'` to report metrics for one label only.\n\naverage : {'micro', 'macro', 'samples', 'weighted', 'binary'} or None,             default='binary'\n    This parameter is required for multiclass/multilabel targets.\n    If ``None``, the scores for each class are returned. Otherwise, this\n    determines the type of averaging performed on the data:\n\n    ``'binary'``:\n        Only report results for the class specified by ``pos_label``.\n        This is applicable only if targets (``y_{true,pred}``) are binary.\n    ``'micro'``:\n        Calculate metrics globally by counting the total true positives,\n        false negatives and false positives.\n    ``'macro'``:\n        Calculate metrics for each label, and find their unweighted\n        mean.  This does not take label imbalance into account.\n    ``'weighted'``:\n        Calculate metrics for each label, and find their average weighted\n        by support (the number of true instances for each label). This\n        alters 'macro' to account for label imbalance; it can result in an\n        F-score that is not between precision and recall. Weighted recall\n        is equal to accuracy.\n    ``'samples'``:\n        Calculate metrics for each instance, and find their average (only\n        meaningful for multilabel classification where this differs from\n        :func:`accuracy_score`).\n\nsample_weight : array-like of shape (n_samples,), default=None\n    Sample weights.\n\nzero_division : {\"warn\", 0.0, 1.0, np.nan}, default=\"warn\"\n    Sets the value to return when there is a zero division.\n\n    Notes:\n    - If set to \"warn\", this acts like 0, but a warning is also raised.\n    - If set to `np.nan`, such values will be excluded from the average.\n\n    .. versionadded:: 1.3\n       `np.nan` option was added.\n\nReturns\n-------\nrecall : float (if average is not None) or array of float of shape              (n_unique_labels,)\n    Recall of the positive class in binary classification or weighted\n    average of the recall of each class for the multiclass task.\n\nSee Also\n--------\nprecision_recall_fscore_support : Compute precision, recall, F-measure and\n    support for each class.\nprecision_score : Compute the ratio ``tp / (tp + fp)`` where ``tp`` is the\n    number of true positives and ``fp`` the number of false positives.\nbalanced_accuracy_score : Compute balanced accuracy to deal with imbalanced\n    datasets.\nmultilabel_confusion_matrix : Compute a confusion matrix for each class or\n    sample.\nPrecisionRecallDisplay.from_estimator : Plot precision-recall curve given\n    an estimator and some data.\nPrecisionRecallDisplay.from_predictions : Plot precision-recall curve given\n    binary class predictions.\n\nNotes\n-----\nWhen ``true positive + false negative == 0``, recall returns 0 and raises\n``UndefinedMetricWarning``. This behavior can be modified with\n``zero_division``.\n\nExamples\n--------\n>>> import numpy as np\n>>> from sklearn.metrics import recall_score\n>>> y_true = [0, 1, 2, 0, 1, 2]\n>>> y_pred = [0, 2, 1, 0, 0, 1]\n>>> recall_score(y_true, y_pred, average='macro')\n0.33...\n>>> recall_score(y_true, y_pred, average='micro')\n0.33...\n>>> recall_score(y_true, y_pred, average='weighted')\n0.33...\n>>> recall_score(y_true, y_pred, average=None)\narray([1., 0., 0.])\n>>> y_true = [0, 0, 0, 0, 0, 0]\n>>> recall_score(y_true, y_pred, average=None)\narray([0.5, 0. , 0. ])\n>>> recall_score(y_true, y_pred, average=None, zero_division=1)\narray([0.5, 1. , 1. ])\n>>> recall_score(y_true, y_pred, average=None, zero_division=np.nan)\narray([0.5, nan, nan])\n\n>>> # multilabel classification\n>>> y_true = [[0, 0, 0], [1, 1, 1], [0, 1, 1]]\n>>> y_pred = [[0, 0, 0], [1, 1, 1], [1, 1, 0]]\n>>> recall_score(y_true, y_pred, average=None)\narray([1. , 1. , 0.5])" .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RocAucScoreMethod
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RocAucScoreMethod> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Class> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RocAucScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RocAucScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MetricsModule> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RocAucScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PerformanceCalculationMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RocAucScoreMethod> <http://www.w3.org/2000/01/rdf-schema#comment> "Compute Area Under the Receiver Operating Characteristic Curve (ROC AUC)     from prediction scores.\n\nNote: this implementation can be used with binary, multiclass and\nmultilabel classification, but some restrictions apply (see Parameters).\n\nRead more in the :ref:`User Guide <roc_metrics>`.\n\nParameters\n----------\ny_true : array-like of shape (n_samples,) or (n_samples, n_classes)\n    True labels or binary label indicators. The binary and multiclass cases\n    expect labels with shape (n_samples,) while the multilabel case expects\n    binary label indicators with shape (n_samples, n_classes).\n\ny_score : array-like of shape (n_samples,) or (n_samples, n_classes)\n    Target scores.\n\n    * In the binary case, it corresponds to an array of shape\n      `(n_samples,)`. Both probability estimates and non-thresholded\n      decision values can be provided. The probability estimates correspond\n      to the **probability of the class with the greater label**,\n      i.e. `estimator.classes_[1]` and thus\n      `estimator.predict_proba(X, y)[:, 1]`. The decision values\n      corresponds to the output of `estimator.decision_function(X, y)`.\n      See more information in the :ref:`User guide <roc_auc_binary>`;\n    * In the multiclass case, it corresponds to an array of shape\n      `(n_samples, n_classes)` of probability estimates provided by the\n      `predict_proba` method. The probability estimates **must**\n      sum to 1 across the possible classes. In addition, the order of the\n      class scores must correspond to the order of ``labels``,\n      if provided, or else to the numerical or lexicographical order of\n      the labels in ``y_true``. See more information in the\n      :ref:`User guide <roc_auc_multiclass>`;\n    * In the multilabel case, it corresponds to an array of shape\n      `(n_samples, n_classes)`. Probability estimates are provided by the\n      `predict_proba` method and the non-thresholded decision values by\n      the `decision_function` method. The probability estimates correspond\n      to the **probability of the class with the greater label for each\n      output** of the classifier. See more information in the\n      :ref:`User guide <roc_auc_multilabel>`.\n\naverage : {'micro', 'macro', 'samples', 'weighted'} or None,             default='macro'\n    If ``None``, the scores for each class are returned.\n    Otherwise, this determines the type of averaging performed on the data.\n    Note: multiclass ROC AUC currently only handles the 'macro' and\n    'weighted' averages. For multiclass targets, `average=None` is only\n    implemented for `multi_class='ovr'` and `average='micro'` is only\n    implemented for `multi_class='ovr'`.\n\n    ``'micro'``:\n        Calculate metrics globally by considering each element of the label\n        indicator matrix as a label.\n    ``'macro'``:\n        Calculate metrics for each label, and find their unweighted\n        mean.  This does not take label imbalance into account.\n    ``'weighted'``:\n        Calculate metrics for each label, and find their average, weighted\n        by support (the number of true instances for each label).\n    ``'samples'``:\n        Calculate metrics for each instance, and find their average.\n\n    Will be ignored when ``y_true`` is binary.\n\nsample_weight : array-like of shape (n_samples,), default=None\n    Sample weights.\n\nmax_fpr : float > 0 and <= 1, default=None\n    If not ``None``, the standardized partial AUC [2]_ over the range\n    [0, max_fpr] is returned. For the multiclass case, ``max_fpr``,\n    should be either equal to ``None`` or ``1.0`` as AUC ROC partial\n    computation currently is not supported for multiclass.\n\nmulti_class : {'raise', 'ovr', 'ovo'}, default='raise'\n    Only used for multiclass targets. Determines the type of configuration\n    to use. The default value raises an error, so either\n    ``'ovr'`` or ``'ovo'`` must be passed explicitly.\n\n    ``'ovr'``:\n        Stands for One-vs-rest. Computes the AUC of each class\n        against the rest [3]_ [4]_. This\n        treats the multiclass case in the same way as the multilabel case.\n        Sensitive to class imbalance even when ``average == 'macro'``,\n        because class imbalance affects the composition of each of the\n        'rest' groupings.\n    ``'ovo'``:\n        Stands for One-vs-one. Computes the average AUC of all\n        possible pairwise combinations of classes [5]_.\n        Insensitive to class imbalance when\n        ``average == 'macro'``.\n\nlabels : array-like of shape (n_classes,), default=None\n    Only used for multiclass targets. List of labels that index the\n    classes in ``y_score``. If ``None``, the numerical or lexicographical\n    order of the labels in ``y_true`` is used.\n\nReturns\n-------\nauc : float\n    Area Under the Curve score.\n\nSee Also\n--------\naverage_precision_score : Area under the precision-recall curve.\nroc_curve : Compute Receiver operating characteristic (ROC) curve.\nRocCurveDisplay.from_estimator : Plot Receiver Operating Characteristic\n    (ROC) curve given an estimator and some data.\nRocCurveDisplay.from_predictions : Plot Receiver Operating Characteristic\n    (ROC) curve given the true and predicted values.\n\nNotes\n-----\nThe Gini Coefficient is a summary measure of the ranking ability of binary\nclassifiers. It is expressed using the area under of the ROC as follows:\n\nG = 2 * AUC - 1\n\nWhere G is the Gini coefficient and AUC is the ROC-AUC score. This normalisation\nwill ensure that random guessing will yield a score of 0 in expectation, and it is\nupper bounded by 1.\n\nReferences\n----------\n.. [1] `Wikipedia entry for the Receiver operating characteristic\n        <https://en.wikipedia.org/wiki/Receiver_operating_characteristic>`_\n\n.. [2] `Analyzing a portion of the ROC curve. McClish, 1989\n        <https://www.ncbi.nlm.nih.gov/pubmed/2668680>`_\n\n.. [3] Provost, F., Domingos, P. (2000). Well-trained PETs: Improving\n       probability estimation trees (Section 6.2), CeDER Working Paper\n       #IS-00-04, Stern School of Business, New York University.\n\n.. [4] `Fawcett, T. (2006). An introduction to ROC analysis. Pattern\n        Recognition Letters, 27(8), 861-874.\n        <https://www.sciencedirect.com/science/article/pii/S016786550500303X>`_\n\n.. [5] `Hand, D.J., Till, R.J. (2001). A Simple Generalisation of the Area\n        Under the ROC Curve for Multiple Class Classification Problems.\n        Machine Learning, 45(2), 171-186.\n        <http://link.springer.com/article/10.1023/A:1010920819831>`_\n.. [6] `Wikipedia entry for the Gini coefficient\n        <https://en.wikipedia.org/wiki/Gini_coefficient>`_\n\nExamples\n--------\nBinary case:\n\n>>> from sklearn.datasets import load_breast_cancer\n>>> from sklearn.linear_model import LogisticRegression\n>>> from sklearn.metrics import roc_auc_score\n>>> X, y = load_breast_cancer(return_X_y=True)\n>>> clf = LogisticRegression(solver=\"liblinear\", random_state=0).fit(X, y)\n>>> roc_auc_score(y, clf.predict_proba(X)[:, 1])\n0.99...\n>>> roc_auc_score(y, clf.decision_function(X))\n0.99...\n\nMulticlass case:\n\n>>> from sklearn.datasets import load_iris\n>>> X, y = load_iris(return_X_y=True)\n>>> clf = LogisticRegression(solver=\"liblinear\").fit(X, y)\n>>> roc_auc_score(y, clf.predict_proba(X), multi_class='ovr')\n0.99...\n\nMultilabel case:\n\n>>> import numpy as np\n>>> from sklearn.datasets import make_multilabel_classification\n>>> from sklearn.multioutput import MultiOutputClassifier\n>>> X, y = make_multilabel_classification(random_state=0)\n>>> clf = MultiOutputClassifier(clf).fit(X, y)\n>>> # get a list of n_output containing probability arrays of shape\n>>> # (n_samples, n_classes)\n>>> y_pred = clf.predict_proba(X)\n>>> # extract the positive columns for each output\n>>> y_pred = np.transpose([pred[:, 1] for pred in y_pred])\n>>> roc_auc_score(y, y_pred, average=None)\narray([0.82..., 0.86..., 0.94..., 0.85... , 0.94...])\n>>> from sklearn.linear_model import RidgeClassifierCV\n>>> clf = RidgeClassifierCV().fit(X, y)\n>>> roc_auc_score(y, clf.decision_function(X), average=None)\narray([0.81..., 0.84... , 0.93..., 0.87..., 0.94...])" .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RocCurveMethod
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RocCurveMethod> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Class> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RocCurveMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RocCurveMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MetricsModule> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RocCurveMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PerformanceCalculationMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RocCurveMethod> <http://www.w3.org/2000/01/rdf-schema#comment> "Compute Receiver operating characteristic (ROC).\n\nNote: this implementation is restricted to the binary classification task.\n\nRead more in the :ref:`User Guide <roc_metrics>`.\n\nParameters\n----------\ny_true : array-like of shape (n_samples,)\n    True binary labels. If labels are not either {-1, 1} or {0, 1}, then\n    pos_label should be explicitly given.\n\ny_score : array-like of shape (n_samples,)\n    Target scores, can either be probability estimates of the positive\n    class, confidence values, or non-thresholded measure of decisions\n    (as returned by \"decision_function\" on some classifiers).\n\npos_label : int, float, bool or str, default=None\n    The label of the positive class.\n    When ``pos_label=None``, if `y_true` is in {-1, 1} or {0, 1},\n    ``pos_label`` is set to 1, otherwise an error will be raised.\n\nsample_weight : array-like of shape (n_samples,), default=None\n    Sample weights.\n\ndrop_intermediate : bool, default=True\n    Whether to drop some suboptimal thresholds which would not appear\n    on a plotted ROC curve. This is useful in order to create lighter\n    ROC curves.\n\n    .. versionadded:: 0.17\n       parameter *drop_intermediate*.\n\nReturns\n-------\nfpr : ndarray of shape (>2,)\n    Increasing false positive rates such that element i is the false\n    positive rate of predictions with score >= `thresholds[i]`.\n\ntpr : ndarray of shape (>2,)\n    Increasing true positive rates such that element `i` is the true\n    positive rate of predictions with score >= `thresholds[i]`.\n\nthresholds : ndarray of shape (n_thresholds,)\n    Decreasing thresholds on the decision function used to compute\n    fpr and tpr. `thresholds[0]` represents no instances being predicted\n    and is arbitrarily set to `np.inf`.\n\nSee Also\n--------\nRocCurveDisplay.from_estimator : Plot Receiver Operating Characteristic\n    (ROC) curve given an estimator and some data.\nRocCurveDisplay.from_predictions : Plot Receiver Operating Characteristic\n    (ROC) curve given the true and predicted values.\ndet_curve: Compute error rates for different probability thresholds.\nroc_auc_score : Compute the area under the ROC curve.\n\nNotes\n-----\nSince the thresholds are sorted from low to high values, they\nare reversed upon returning them to ensure they correspond to both ``fpr``\nand ``tpr``, which are sorted in reversed order during their calculation.\n\nAn arbitrary threshold is added for the case `tpr=0` and `fpr=0` to\nensure that the curve starts at `(0, 0)`. This threshold corresponds to the\n`np.inf`.\n\nReferences\n----------\n.. [1] `Wikipedia entry for the Receiver operating characteristic\n        <https://en.wikipedia.org/wiki/Receiver_operating_characteristic>`_\n\n.. [2] Fawcett T. An introduction to ROC analysis[J]. Pattern Recognition\n       Letters, 2006, 27(8):861-874.\n\nExamples\n--------\n>>> import numpy as np\n>>> from sklearn import metrics\n>>> y = np.array([1, 1, 2, 2])\n>>> scores = np.array([0.1, 0.4, 0.35, 0.8])\n>>> fpr, tpr, thresholds = metrics.roc_curve(y, scores, pos_label=2)\n>>> fpr\narray([0. , 0. , 0.5, 0.5, 1. ])\n>>> tpr\narray([0. , 0.5, 0.5, 1. , 1. ])\n>>> thresholds\narray([ inf, 0.8 , 0.4 , 0.35, 0.1 ])" .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RootMeanSquaredErrorMethod
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RootMeanSquaredErrorMethod> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Class> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RootMeanSquaredErrorMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RootMeanSquaredErrorMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MetricsModule> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RootMeanSquaredErrorMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PerformanceCalculationMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RootMeanSquaredErrorMethod> <http://www.w3.org/2000/01/rdf-schema#comment> "Root mean squared error regression loss.\n\nRead more in the :ref:`User Guide <mean_squared_error>`.\n\n.. versionadded:: 1.4\n\nParameters\n----------\ny_true : array-like of shape (n_samples,) or (n_samples, n_outputs)\n    Ground truth (correct) target values.\n\ny_pred : array-like of shape (n_samples,) or (n_samples, n_outputs)\n    Estimated target values.\n\nsample_weight : array-like of shape (n_samples,), default=None\n    Sample weights.\n\nmultioutput : {'raw_values', 'uniform_average'} or array-like of shape             (n_outputs,), default='uniform_average'\n    Defines aggregating of multiple output values.\n    Array-like value defines weights used to average errors.\n\n    'raw_values' :\n        Returns a full set of errors in case of multioutput input.\n\n    'uniform_average' :\n        Errors of all outputs are averaged with uniform weight.\n\nReturns\n-------\nloss : float or ndarray of floats\n    A non-negative floating point value (the best value is 0.0), or an\n    array of floating point values, one for each individual target.\n\nExamples\n--------\n>>> from sklearn.metrics import root_mean_squared_error\n>>> y_true = [3, -0.5, 2, 7]\n>>> y_pred = [2.5, 0.0, 2, 8]\n>>> root_mean_squared_error(y_true, y_pred)\n0.612...\n>>> y_true = [[0.5, 1],[-1, 1],[7, -6]]\n>>> y_pred = [[0, 2],[-1, 2],[8, -5]]\n>>> root_mean_squared_error(y_true, y_pred)\n0.822..." .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RootMeanSquaredLogErrorMethod
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RootMeanSquaredLogErrorMethod> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Class> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RootMeanSquaredLogErrorMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RootMeanSquaredLogErrorMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MetricsModule> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RootMeanSquaredLogErrorMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PerformanceCalculationMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RootMeanSquaredLogErrorMethod> <http://www.w3.org/2000/01/rdf-schema#comment> "Root mean squared logarithmic error regression loss.\n\nRead more in the :ref:`User Guide <mean_squared_log_error>`.\n\n.. versionadded:: 1.4\n\nParameters\n----------\ny_true : array-like of shape (n_samples,) or (n_samples, n_outputs)\n    Ground truth (correct) target values.\n\ny_pred : array-like of shape (n_samples,) or (n_samples, n_outputs)\n    Estimated target values.\n\nsample_weight : array-like of shape (n_samples,), default=None\n    Sample weights.\n\nmultioutput : {'raw_values', 'uniform_average'} or array-like of shape             (n_outputs,), default='uniform_average'\n\n    Defines aggregating of multiple output values.\n    Array-like value defines weights used to average errors.\n\n    'raw_values' :\n        Returns a full set of errors when the input is of multioutput\n        format.\n\n    'uniform_average' :\n        Errors of all outputs are averaged with uniform weight.\n\nReturns\n-------\nloss : float or ndarray of floats\n    A non-negative floating point value (the best value is 0.0), or an\n    array of floating point values, one for each individual target.\n\nExamples\n--------\n>>> from sklearn.metrics import root_mean_squared_log_error\n>>> y_true = [3, 5, 2.5, 7]\n>>> y_pred = [2.5, 5, 4, 8]\n>>> root_mean_squared_log_error(y_true, y_pred)\n0.199..." .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#SilhouetteSamplesMethod
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#SilhouetteSamplesMethod> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Class> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#SilhouetteSamplesMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#SilhouetteSamplesMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MetricsModule> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#SilhouetteSamplesMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PerformanceCalculationMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#SilhouetteSamplesMethod> <http://www.w3.org/2000/01/rdf-schema#comment> "Compute the Silhouette Coefficient for each sample.\n\nThe Silhouette Coefficient is a measure of how well samples are clustered\nwith samples that are similar to themselves. Clustering models with a high\nSilhouette Coefficient are said to be dense, where samples in the same\ncluster are similar to each other, and well separated, where samples in\ndifferent clusters are not very similar to each other.\n\nThe Silhouette Coefficient is calculated using the mean intra-cluster\ndistance (``a``) and the mean nearest-cluster distance (``b``) for each\nsample.  The Silhouette Coefficient for a sample is ``(b - a) / max(a,\nb)``.\nNote that Silhouette Coefficient is only defined if number of labels\nis 2 ``<= n_labels <= n_samples - 1``.\n\nThis function returns the Silhouette Coefficient for each sample.\n\nThe best value is 1 and the worst value is -1. Values near 0 indicate\noverlapping clusters.\n\nRead more in the :ref:`User Guide <silhouette_coefficient>`.\n\nParameters\n----------\nX : {array-like, sparse matrix} of shape (n_samples_a, n_samples_a) if metric ==             \"precomputed\" or (n_samples_a, n_features) otherwise\n    An array of pairwise distances between samples, or a feature array. If\n    a sparse matrix is provided, CSR format should be favoured avoiding\n    an additional copy.\n\nlabels : array-like of shape (n_samples,)\n    Label values for each sample.\n\nmetric : str or callable, default='euclidean'\n    The metric to use when calculating distance between instances in a\n    feature array. If metric is a string, it must be one of the options\n    allowed by :func:`~sklearn.metrics.pairwise_distances`.\n    If ``X`` is the distance array itself, use \"precomputed\" as the metric.\n    Precomputed distance matrices must have 0 along the diagonal.\n\n**kwds : optional keyword parameters\n    Any further parameters are passed directly to the distance function.\n    If using a ``scipy.spatial.distance`` metric, the parameters are still\n    metric dependent. See the scipy docs for usage examples.\n\nReturns\n-------\nsilhouette : array-like of shape (n_samples,)\n    Silhouette Coefficients for each sample.\n\nReferences\n----------\n\n.. [1] `Peter J. Rousseeuw (1987). \"Silhouettes: a Graphical Aid to the\n   Interpretation and Validation of Cluster Analysis\". Computational\n   and Applied Mathematics 20: 53-65.\n   <https://www.sciencedirect.com/science/article/pii/0377042787901257>`_\n\n.. [2] `Wikipedia entry on the Silhouette Coefficient\n   <https://en.wikipedia.org/wiki/Silhouette_(clustering)>`_\n\nExamples\n--------\n>>> from sklearn.metrics import silhouette_samples\n>>> from sklearn.datasets import make_blobs\n>>> from sklearn.cluster import KMeans\n>>> X, y = make_blobs(n_samples=50, random_state=42)\n>>> kmeans = KMeans(n_clusters=3, random_state=42)\n>>> labels = kmeans.fit_predict(X)\n>>> silhouette_samples(X, labels)\narray([...])" .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#SilhouetteScoreMethod
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#SilhouetteScoreMethod> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Class> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#SilhouetteScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#SilhouetteScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MetricsModule> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#SilhouetteScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PerformanceCalculationMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#SilhouetteScoreMethod> <http://www.w3.org/2000/01/rdf-schema#comment> "Compute the mean Silhouette Coefficient of all samples.\n\nThe Silhouette Coefficient is calculated using the mean intra-cluster\ndistance (``a``) and the mean nearest-cluster distance (``b``) for each\nsample.  The Silhouette Coefficient for a sample is ``(b - a) / max(a,\nb)``.  To clarify, ``b`` is the distance between a sample and the nearest\ncluster that the sample is not a part of.\nNote that Silhouette Coefficient is only defined if number of labels\nis ``2 <= n_labels <= n_samples - 1``.\n\nThis function returns the mean Silhouette Coefficient over all samples.\nTo obtain the values for each sample, use :func:`silhouette_samples`.\n\nThe best value is 1 and the worst value is -1. Values near 0 indicate\noverlapping clusters. Negative values generally indicate that a sample has\nbeen assigned to the wrong cluster, as a different cluster is more similar.\n\nRead more in the :ref:`User Guide <silhouette_coefficient>`.\n\nParameters\n----------\nX : {array-like, sparse matrix} of shape (n_samples_a, n_samples_a) if metric ==             \"precomputed\" or (n_samples_a, n_features) otherwise\n    An array of pairwise distances between samples, or a feature array.\n\nlabels : array-like of shape (n_samples,)\n    Predicted labels for each sample.\n\nmetric : str or callable, default='euclidean'\n    The metric to use when calculating distance between instances in a\n    feature array. If metric is a string, it must be one of the options\n    allowed by :func:`~sklearn.metrics.pairwise_distances`. If ``X`` is\n    the distance array itself, use ``metric=\"precomputed\"``.\n\nsample_size : int, default=None\n    The size of the sample to use when computing the Silhouette Coefficient\n    on a random subset of the data.\n    If ``sample_size is None``, no sampling is used.\n\nrandom_state : int, RandomState instance or None, default=None\n    Determines random number generation for selecting a subset of samples.\n    Used when ``sample_size is not None``.\n    Pass an int for reproducible results across multiple function calls.\n    See :term:`Glossary <random_state>`.\n\n**kwds : optional keyword parameters\n    Any further parameters are passed directly to the distance function.\n    If using a scipy.spatial.distance metric, the parameters are still\n    metric dependent. See the scipy docs for usage examples.\n\nReturns\n-------\nsilhouette : float\n    Mean Silhouette Coefficient for all samples.\n\nReferences\n----------\n\n.. [1] `Peter J. Rousseeuw (1987). \"Silhouettes: a Graphical Aid to the\n   Interpretation and Validation of Cluster Analysis\". Computational\n   and Applied Mathematics 20: 53-65.\n   <https://www.sciencedirect.com/science/article/pii/0377042787901257>`_\n\n.. [2] `Wikipedia entry on the Silhouette Coefficient\n       <https://en.wikipedia.org/wiki/Silhouette_(clustering)>`_\n\nExamples\n--------\n>>> from sklearn.datasets import make_blobs\n>>> from sklearn.cluster import KMeans\n>>> from sklearn.metrics import silhouette_score\n>>> X, y = make_blobs(random_state=42)\n>>> kmeans = KMeans(n_clusters=2, random_state=42)\n>>> silhouette_score(X, kmeans.fit_predict(X))\n0.49..." .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#SklearnModule
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#SklearnModule> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Class> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#SklearnModule> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#Module> .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#TopKAccuracyScoreMethod
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#TopKAccuracyScoreMethod> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Class> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#TopKAccuracyScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#TopKAccuracyScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MetricsModule> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#TopKAccuracyScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PerformanceCalculationMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#TopKAccuracyScoreMethod> <http://www.w3.org/2000/01/rdf-schema#comment> "Top-k Accuracy classification score.\n\nThis metric computes the number of times where the correct label is among\nthe top `k` labels predicted (ranked by predicted scores). Note that the\nmultilabel case isn't covered here.\n\nRead more in the :ref:`User Guide <top_k_accuracy_score>`\n\nParameters\n----------\ny_true : array-like of shape (n_samples,)\n    True labels.\n\ny_score : array-like of shape (n_samples,) or (n_samples, n_classes)\n    Target scores. These can be either probability estimates or\n    non-thresholded decision values (as returned by\n    :term:`decision_function` on some classifiers).\n    The binary case expects scores with shape (n_samples,) while the\n    multiclass case expects scores with shape (n_samples, n_classes).\n    In the multiclass case, the order of the class scores must\n    correspond to the order of ``labels``, if provided, or else to\n    the numerical or lexicographical order of the labels in ``y_true``.\n    If ``y_true`` does not contain all the labels, ``labels`` must be\n    provided.\n\nk : int, default=2\n    Number of most likely outcomes considered to find the correct label.\n\nnormalize : bool, default=True\n    If `True`, return the fraction of correctly classified samples.\n    Otherwise, return the number of correctly classified samples.\n\nsample_weight : array-like of shape (n_samples,), default=None\n    Sample weights. If `None`, all samples are given the same weight.\n\nlabels : array-like of shape (n_classes,), default=None\n    Multiclass only. List of labels that index the classes in ``y_score``.\n    If ``None``, the numerical or lexicographical order of the labels in\n    ``y_true`` is used. If ``y_true`` does not contain all the labels,\n    ``labels`` must be provided.\n\nReturns\n-------\nscore : float\n    The top-k accuracy score. The best performance is 1 with\n    `normalize == True` and the number of samples with\n    `normalize == False`.\n\nSee Also\n--------\naccuracy_score : Compute the accuracy score. By default, the function will\n    return the fraction of correct predictions divided by the total number\n    of predictions.\n\nNotes\n-----\nIn cases where two or more labels are assigned equal predicted scores,\nthe labels with the highest indices will be chosen first. This might\nimpact the result if the correct label falls after the threshold because\nof that.\n\nExamples\n--------\n>>> import numpy as np\n>>> from sklearn.metrics import top_k_accuracy_score\n>>> y_true = np.array([0, 1, 2, 2])\n>>> y_score = np.array([[0.5, 0.2, 0.2],  # 0 is in top 2\n...                     [0.3, 0.4, 0.2],  # 1 is in top 2\n...                     [0.2, 0.4, 0.3],  # 2 is in top 2\n...                     [0.7, 0.2, 0.1]]) # 2 isn't in top 2\n>>> top_k_accuracy_score(y_true, y_score, k=2)\n0.75\n>>> # Not normalizing gives the number of \"correctly\" classified samples\n>>> top_k_accuracy_score(y_true, y_score, k=2, normalize=False)\n3" .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#VMeasureScoreMethod
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#VMeasureScoreMethod> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Class> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#VMeasureScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#VMeasureScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MetricsModule> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#VMeasureScoreMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PerformanceCalculationMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#VMeasureScoreMethod> <http://www.w3.org/2000/01/rdf-schema#comment> "V-measure cluster labeling given a ground truth.\n\nThis score is identical to :func:`normalized_mutual_info_score` with\nthe ``'arithmetic'`` option for averaging.\n\nThe V-measure is the harmonic mean between homogeneity and completeness::\n\n    v = (1 + beta) * homogeneity * completeness\n         / (beta * homogeneity + completeness)\n\nThis metric is independent of the absolute values of the labels:\na permutation of the class or cluster label values won't change the\nscore value in any way.\n\nThis metric is furthermore symmetric: switching ``label_true`` with\n``label_pred`` will return the same score value. This can be useful to\nmeasure the agreement of two independent label assignments strategies\non the same dataset when the real ground truth is not known.\n\nRead more in the :ref:`User Guide <homogeneity_completeness>`.\n\nParameters\n----------\nlabels_true : array-like of shape (n_samples,)\n    Ground truth class labels to be used as a reference.\n\nlabels_pred : array-like of shape (n_samples,)\n    Cluster labels to evaluate.\n\nbeta : float, default=1.0\n    Ratio of weight attributed to ``homogeneity`` vs ``completeness``.\n    If ``beta`` is greater than 1, ``completeness`` is weighted more\n    strongly in the calculation. If ``beta`` is less than 1,\n    ``homogeneity`` is weighted more strongly.\n\nReturns\n-------\nv_measure : float\n   Score between 0.0 and 1.0. 1.0 stands for perfectly complete labeling.\n\nSee Also\n--------\nhomogeneity_score : Homogeneity metric of cluster labeling.\ncompleteness_score : Completeness metric of cluster labeling.\nnormalized_mutual_info_score : Normalized Mutual Information.\n\nReferences\n----------\n\n.. [1] `Andrew Rosenberg and Julia Hirschberg, 2007. V-Measure: A\n   conditional entropy-based external cluster evaluation measure\n   <https://aclweb.org/anthology/D/D07/D07-1043.pdf>`_\n\nExamples\n--------\nPerfect labelings are both homogeneous and complete, hence have score 1.0::\n\n  >>> from sklearn.metrics.cluster import v_measure_score\n  >>> v_measure_score([0, 0, 1, 1], [0, 0, 1, 1])\n  1.0\n  >>> v_measure_score([0, 0, 1, 1], [1, 1, 0, 0])\n  1.0\n\nLabelings that assign all classes members to the same clusters\nare complete but not homogeneous, hence penalized::\n\n  >>> print(\"%.6f\" % v_measure_score([0, 0, 1, 2], [0, 0, 1, 1]))\n  0.8...\n  >>> print(\"%.6f\" % v_measure_score([0, 1, 2, 3], [0, 0, 1, 1]))\n  0.66...\n\nLabelings that have pure clusters with members coming from the same\nclasses are homogeneous but un-necessary splits harm completeness\nand thus penalize V-measure as well::\n\n  >>> print(\"%.6f\" % v_measure_score([0, 0, 1, 1], [0, 0, 1, 2]))\n  0.8...\n  >>> print(\"%.6f\" % v_measure_score([0, 0, 1, 1], [0, 1, 2, 3]))\n  0.66...\n\nIf classes members are completely split across different clusters,\nthe assignment is totally incomplete, hence the V-Measure is null::\n\n  >>> print(\"%.6f\" % v_measure_score([0, 0, 0, 0], [0, 1, 2, 3]))\n  0.0...\n\nClusters that include samples from totally different classes totally\ndestroy the homogeneity of the labeling, hence::\n\n  >>> print(\"%.6f\" % v_measure_score([0, 0, 1, 1], [0, 0, 0, 0]))\n  0.0..." .
# 
# https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#ZeroOneLossMethod
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#ZeroOneLossMethod> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/2002/07/owl#Class> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#ZeroOneLossMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#ZeroOneLossMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MetricsModule> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#ZeroOneLossMethod> <http://www.w3.org/2000/01/rdf-schema#subClassOf> <https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PerformanceCalculationMethod> .
<https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#ZeroOneLossMethod> <http://www.w3.org/2000/01/rdf-schema#comment> "Zero-one classification loss.\n\nIf normalize is ``True``, return the fraction of misclassifications\n(float), else it returns the number of misclassifications (int). The best\nperformance is 0.\n\nRead more in the :ref:`User Guide <zero_one_loss>`.\n\nParameters\n----------\ny_true : 1d array-like, or label indicator array / sparse matrix\n    Ground truth (correct) labels.\n\ny_pred : 1d array-like, or label indicator array / sparse matrix\n    Predicted labels, as returned by a classifier.\n\nnormalize : bool, default=True\n    If ``False``, return the number of misclassifications.\n    Otherwise, return the fraction of misclassifications.\n\nsample_weight : array-like of shape (n_samples,), default=None\n    Sample weights.\n\nReturns\n-------\nloss : float or int,\n    If ``normalize == True``, return the fraction of misclassifications\n    (float), else it returns the number of misclassifications (int).\n\nSee Also\n--------\naccuracy_score : Compute the accuracy score. By default, the function will\n    return the fraction of correct predictions divided by the total number\n    of predictions.\nhamming_loss : Compute the average Hamming loss or Hamming distance between\n    two sets of samples.\njaccard_score : Compute the Jaccard similarity coefficient score.\n\nNotes\n-----\nIn multilabel classification, the zero_one_loss function corresponds to\nthe subset zero-one loss: for each sample, the entire set of labels must be\ncorrectly predicted, otherwise the loss for that sample is equal to one.\n\nExamples\n--------\n>>> from sklearn.metrics import zero_one_loss\n>>> y_pred = [1, 2, 3, 4]\n>>> y_true = [2, 2, 3, 4]\n>>> zero_one_loss(y_true, y_pred)\n0.25\n>>> zero_one_loss(y_true, y_pred, normalize=False)\n1.0\n\nIn the multilabel case with binary label indicators:\n\n>>> import numpy as np\n>>> zero_one_loss(np.array([[0, 1], [1, 1]]), np.ones((2, 2)))\n0.5" .
# 
# Generated by the OWL API (version 5.1.18) https://github.com/owlcs/owlapi/
