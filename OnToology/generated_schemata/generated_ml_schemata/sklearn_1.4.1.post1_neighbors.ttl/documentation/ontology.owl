<?xml version="1.0"?>
<rdf:RDF xmlns="http://www.w3.org/2002/07/owl#"
     xml:base="http://www.w3.org/2002/07/owl"
     xmlns:owl="http://www.w3.org/2002/07/owl#"
     xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
     xmlns:xml="http://www.w3.org/XML/1998/namespace"
     xmlns:xsd="http://www.w3.org/2001/XMLSchema#"
     xmlns:rdfs="http://www.w3.org/2000/01/rdf-schema#">
    <Ontology/>
    


    <!-- 
    ///////////////////////////////////////////////////////////////////////////////////////
    //
    // Object Properties
    //
    ///////////////////////////////////////////////////////////////////////////////////////
     -->


    


    <!-- https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasBinaryClassificationMethod -->


    <ObjectProperty rdf:about="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasBinaryClassificationMethod">
        <rdfs:subPropertyOf rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasTrainMethod"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#BinaryClassification"/>
        <rdfs:range rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#KNeighborsClassifierMethod"/>
        <rdfs:range rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#NearestCentroidMethod"/>
        <rdfs:range rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RadiusNeighborsClassifierMethod"/>
    </ObjectProperty>
    


    <!-- https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasClusteringMethod -->


    <ObjectProperty rdf:about="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasClusteringMethod">
        <rdfs:subPropertyOf rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasTrainMethod"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#Clustering"/>
        <rdfs:range rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#BallTreeMethod"/>
        <rdfs:range rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#KDTreeMethod"/>
        <rdfs:range rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#KNeighborsTransformerMethod"/>
        <rdfs:range rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#KernelDensityMethod"/>
        <rdfs:range rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#LocalOutlierFactorMethod"/>
        <rdfs:range rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#NearestNeighborsMethod"/>
        <rdfs:range rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RadiusNeighborsTransformerMethod"/>
    </ObjectProperty>
    


    <!-- https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasDecompositionMethod -->


    <ObjectProperty rdf:about="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasDecompositionMethod">
        <rdfs:subPropertyOf rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPrepareTransformerMethod"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#Decomposition"/>
        <rdfs:range rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#NeighborhoodComponentsAnalysisMethod"/>
    </ObjectProperty>
    


    <!-- https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasInstanceBasedRegressionMethod -->


    <ObjectProperty rdf:about="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasInstanceBasedRegressionMethod">
        <rdfs:subPropertyOf rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasTrainMethod"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#InstanceBasedRegression"/>
        <rdfs:range rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#KNeighborsRegressorMethod"/>
        <rdfs:range rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RadiusNeighborsRegressorMethod"/>
    </ObjectProperty>
    


    <!-- https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasMulticlassClassificationMethod -->


    <ObjectProperty rdf:about="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasMulticlassClassificationMethod">
        <rdfs:subPropertyOf rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasTrainMethod"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MulticlassClassification"/>
        <rdfs:range rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#KNeighborsClassifierMethod"/>
        <rdfs:range rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#NearestCentroidMethod"/>
        <rdfs:range rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RadiusNeighborsClassifierMethod"/>
    </ObjectProperty>
    


    <!-- https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasMultilabelClassificationMethod -->


    <ObjectProperty rdf:about="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasMultilabelClassificationMethod">
        <rdfs:subPropertyOf rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasTrainMethod"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MultilabelClassification"/>
        <rdfs:range rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#KNeighborsClassifierMethod"/>
        <rdfs:range rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RadiusNeighborsClassifierMethod"/>
    </ObjectProperty>
    


    <!-- https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPrepareTransformerMethod -->


    <ObjectProperty rdf:about="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasPrepareTransformerMethod"/>
    


    <!-- https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasTrainMethod -->


    <ObjectProperty rdf:about="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasTrainMethod"/>
    


    <!-- 
    ///////////////////////////////////////////////////////////////////////////////////////
    //
    // Data properties
    //
    ///////////////////////////////////////////////////////////////////////////////////////
     -->


    


    <!-- https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter -->


    <DatatypeProperty rdf:about="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter"/>
    


    <!-- https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamAlgorithm -->


    <DatatypeProperty rdf:about="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamAlgorithm">
        <rdfs:subPropertyOf rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#KNeighborsClassifierMethod"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#KNeighborsRegressorMethod"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#KNeighborsTransformerMethod"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#KernelDensityMethod"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#LocalOutlierFactorMethod"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#NearestNeighborsMethod"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RadiusNeighborsClassifierMethod"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RadiusNeighborsRegressorMethod"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RadiusNeighborsTransformerMethod"/>
        <rdfs:range rdf:resource="http://www.w3.org/2001/XMLSchema#string"/>
    </DatatypeProperty>
    


    <!-- https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamAtol -->


    <DatatypeProperty rdf:about="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamAtol">
        <rdfs:subPropertyOf rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#KernelDensityMethod"/>
        <rdfs:range rdf:resource="http://www.w3.org/2001/XMLSchema#float"/>
        <rdfs:range rdf:resource="http://www.w3.org/2001/XMLSchema#int"/>
    </DatatypeProperty>
    


    <!-- https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamBandwidth -->


    <DatatypeProperty rdf:about="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamBandwidth">
        <rdfs:subPropertyOf rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#KernelDensityMethod"/>
        <rdfs:range rdf:resource="http://www.w3.org/2001/XMLSchema#float"/>
        <rdfs:range rdf:resource="http://www.w3.org/2001/XMLSchema#int"/>
        <rdfs:range rdf:resource="http://www.w3.org/2001/XMLSchema#string"/>
    </DatatypeProperty>
    


    <!-- https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamBreadthFirst -->


    <DatatypeProperty rdf:about="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamBreadthFirst">
        <rdfs:subPropertyOf rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#KernelDensityMethod"/>
        <rdfs:range rdf:resource="http://www.w3.org/2001/XMLSchema#boolean"/>
    </DatatypeProperty>
    


    <!-- https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamCallback -->


    <DatatypeProperty rdf:about="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamCallback">
        <rdfs:subPropertyOf rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#NeighborhoodComponentsAnalysisMethod"/>
        <rdfs:range rdf:resource="http://www.w3.org/2001/XMLSchema#string"/>
    </DatatypeProperty>
    


    <!-- https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamContamination -->


    <DatatypeProperty rdf:about="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamContamination">
        <rdfs:subPropertyOf rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#LocalOutlierFactorMethod"/>
        <rdfs:range rdf:resource="http://www.w3.org/2001/XMLSchema#float"/>
        <rdfs:range rdf:resource="http://www.w3.org/2001/XMLSchema#int"/>
    </DatatypeProperty>
    


    <!-- https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamInit -->


    <DatatypeProperty rdf:about="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamInit">
        <rdfs:subPropertyOf rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#NeighborhoodComponentsAnalysisMethod"/>
        <rdfs:range rdf:resource="http://www.w3.org/2001/XMLSchema#string"/>
    </DatatypeProperty>
    


    <!-- https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamKernel -->


    <DatatypeProperty rdf:about="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamKernel">
        <rdfs:subPropertyOf rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#KernelDensityMethod"/>
        <rdfs:range rdf:resource="http://www.w3.org/2001/XMLSchema#string"/>
    </DatatypeProperty>
    


    <!-- https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamLeafSize -->


    <DatatypeProperty rdf:about="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamLeafSize">
        <rdfs:subPropertyOf rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#KNeighborsClassifierMethod"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#KNeighborsRegressorMethod"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#KNeighborsTransformerMethod"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#KernelDensityMethod"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#LocalOutlierFactorMethod"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#NearestNeighborsMethod"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RadiusNeighborsClassifierMethod"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RadiusNeighborsRegressorMethod"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RadiusNeighborsTransformerMethod"/>
        <rdfs:range rdf:resource="http://www.w3.org/2001/XMLSchema#int"/>
    </DatatypeProperty>
    


    <!-- https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamMaxIter -->


    <DatatypeProperty rdf:about="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamMaxIter">
        <rdfs:subPropertyOf rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#NeighborhoodComponentsAnalysisMethod"/>
        <rdfs:range rdf:resource="http://www.w3.org/2001/XMLSchema#int"/>
    </DatatypeProperty>
    


    <!-- https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamMetric -->


    <DatatypeProperty rdf:about="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamMetric">
        <rdfs:subPropertyOf rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#KNeighborsClassifierMethod"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#KNeighborsRegressorMethod"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#KNeighborsTransformerMethod"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#KernelDensityMethod"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#LocalOutlierFactorMethod"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#NearestCentroidMethod"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#NearestNeighborsMethod"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RadiusNeighborsClassifierMethod"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RadiusNeighborsRegressorMethod"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RadiusNeighborsTransformerMethod"/>
        <rdfs:range rdf:resource="http://www.w3.org/2001/XMLSchema#string"/>
    </DatatypeProperty>
    


    <!-- https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamMetricParams -->


    <DatatypeProperty rdf:about="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamMetricParams">
        <rdfs:subPropertyOf rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#KNeighborsClassifierMethod"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#KNeighborsRegressorMethod"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#KNeighborsTransformerMethod"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#KernelDensityMethod"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#LocalOutlierFactorMethod"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#NearestNeighborsMethod"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RadiusNeighborsClassifierMethod"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RadiusNeighborsRegressorMethod"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RadiusNeighborsTransformerMethod"/>
        <rdfs:range rdf:resource="http://www.w3.org/2001/XMLSchema#string"/>
    </DatatypeProperty>
    


    <!-- https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamMode -->


    <DatatypeProperty rdf:about="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamMode">
        <rdfs:subPropertyOf rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#KNeighborsTransformerMethod"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RadiusNeighborsTransformerMethod"/>
        <rdfs:range rdf:resource="http://www.w3.org/2001/XMLSchema#string"/>
    </DatatypeProperty>
    


    <!-- https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamNComponents -->


    <DatatypeProperty rdf:about="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamNComponents">
        <rdfs:subPropertyOf rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#NeighborhoodComponentsAnalysisMethod"/>
        <rdfs:range rdf:resource="http://www.w3.org/2001/XMLSchema#int"/>
    </DatatypeProperty>
    


    <!-- https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamNJobs -->


    <DatatypeProperty rdf:about="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamNJobs">
        <rdfs:subPropertyOf rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#KNeighborsClassifierMethod"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#KNeighborsRegressorMethod"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#KNeighborsTransformerMethod"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#LocalOutlierFactorMethod"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#NearestNeighborsMethod"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RadiusNeighborsClassifierMethod"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RadiusNeighborsRegressorMethod"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RadiusNeighborsTransformerMethod"/>
        <rdfs:range rdf:resource="http://www.w3.org/2001/XMLSchema#int"/>
    </DatatypeProperty>
    


    <!-- https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamNNeighbors -->


    <DatatypeProperty rdf:about="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamNNeighbors">
        <rdfs:subPropertyOf rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#KNeighborsClassifierMethod"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#KNeighborsRegressorMethod"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#KNeighborsTransformerMethod"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#LocalOutlierFactorMethod"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#NearestNeighborsMethod"/>
        <rdfs:range rdf:resource="http://www.w3.org/2001/XMLSchema#int"/>
    </DatatypeProperty>
    


    <!-- https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamNovelty -->


    <DatatypeProperty rdf:about="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamNovelty">
        <rdfs:subPropertyOf rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#LocalOutlierFactorMethod"/>
        <rdfs:range rdf:resource="http://www.w3.org/2001/XMLSchema#boolean"/>
    </DatatypeProperty>
    


    <!-- https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamOutlierLabel -->


    <DatatypeProperty rdf:about="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamOutlierLabel">
        <rdfs:subPropertyOf rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RadiusNeighborsClassifierMethod"/>
        <rdfs:range rdf:resource="http://www.w3.org/2001/XMLSchema#string"/>
    </DatatypeProperty>
    


    <!-- https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamP -->


    <DatatypeProperty rdf:about="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamP">
        <rdfs:subPropertyOf rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#KNeighborsClassifierMethod"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#KNeighborsRegressorMethod"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#KNeighborsTransformerMethod"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#LocalOutlierFactorMethod"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RadiusNeighborsClassifierMethod"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RadiusNeighborsRegressorMethod"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RadiusNeighborsTransformerMethod"/>
        <rdfs:range rdf:resource="http://www.w3.org/2001/XMLSchema#float"/>
        <rdfs:range rdf:resource="http://www.w3.org/2001/XMLSchema#int"/>
    </DatatypeProperty>
    


    <!-- https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamRadius -->


    <DatatypeProperty rdf:about="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamRadius">
        <rdfs:subPropertyOf rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#NearestNeighborsMethod"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RadiusNeighborsClassifierMethod"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RadiusNeighborsRegressorMethod"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RadiusNeighborsTransformerMethod"/>
        <rdfs:range rdf:resource="http://www.w3.org/2001/XMLSchema#float"/>
        <rdfs:range rdf:resource="http://www.w3.org/2001/XMLSchema#int"/>
    </DatatypeProperty>
    


    <!-- https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamRandomState -->


    <DatatypeProperty rdf:about="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamRandomState">
        <rdfs:subPropertyOf rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#NeighborhoodComponentsAnalysisMethod"/>
        <rdfs:range rdf:resource="http://www.w3.org/2001/XMLSchema#int"/>
        <rdfs:range rdf:resource="http://www.w3.org/2001/XMLSchema#string"/>
    </DatatypeProperty>
    


    <!-- https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamRtol -->


    <DatatypeProperty rdf:about="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamRtol">
        <rdfs:subPropertyOf rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#KernelDensityMethod"/>
        <rdfs:range rdf:resource="http://www.w3.org/2001/XMLSchema#float"/>
        <rdfs:range rdf:resource="http://www.w3.org/2001/XMLSchema#int"/>
    </DatatypeProperty>
    


    <!-- https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamShrinkThreshold -->


    <DatatypeProperty rdf:about="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamShrinkThreshold">
        <rdfs:subPropertyOf rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#NearestCentroidMethod"/>
        <rdfs:range rdf:resource="http://www.w3.org/2001/XMLSchema#float"/>
        <rdfs:range rdf:resource="http://www.w3.org/2001/XMLSchema#int"/>
    </DatatypeProperty>
    


    <!-- https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamTol -->


    <DatatypeProperty rdf:about="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamTol">
        <rdfs:subPropertyOf rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#NeighborhoodComponentsAnalysisMethod"/>
        <rdfs:range rdf:resource="http://www.w3.org/2001/XMLSchema#float"/>
        <rdfs:range rdf:resource="http://www.w3.org/2001/XMLSchema#int"/>
    </DatatypeProperty>
    


    <!-- https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamVerbose -->


    <DatatypeProperty rdf:about="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamVerbose">
        <rdfs:subPropertyOf rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#NeighborhoodComponentsAnalysisMethod"/>
        <rdfs:range rdf:resource="http://www.w3.org/2001/XMLSchema#int"/>
    </DatatypeProperty>
    


    <!-- https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamWarmStart -->


    <DatatypeProperty rdf:about="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamWarmStart">
        <rdfs:subPropertyOf rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#NeighborhoodComponentsAnalysisMethod"/>
        <rdfs:range rdf:resource="http://www.w3.org/2001/XMLSchema#boolean"/>
    </DatatypeProperty>
    


    <!-- https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamWeights -->


    <DatatypeProperty rdf:about="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#hasParamWeights">
        <rdfs:subPropertyOf rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#hasParameter"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#KNeighborsClassifierMethod"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#KNeighborsRegressorMethod"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RadiusNeighborsClassifierMethod"/>
        <rdfs:domain rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RadiusNeighborsRegressorMethod"/>
        <rdfs:range rdf:resource="http://www.w3.org/2001/XMLSchema#string"/>
    </DatatypeProperty>
    


    <!-- 
    ///////////////////////////////////////////////////////////////////////////////////////
    //
    // Classes
    //
    ///////////////////////////////////////////////////////////////////////////////////////
     -->


    


    <!-- https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod -->


    <Class rdf:about="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod"/>
    


    <!-- https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#Module -->


    <Class rdf:about="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#Module"/>
    


    <!-- https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#BallTreeMethod -->


    <Class rdf:about="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#BallTreeMethod">
        <rdfs:subClassOf rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod"/>
        <rdfs:subClassOf rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#NeighborsModule"/>
        <rdfs:subClassOf rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#TrainMethod"/>
        <rdfs:comment></rdfs:comment>
    </Class>
    


    <!-- https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#BinaryClassification -->


    <Class rdf:about="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#BinaryClassification"/>
    


    <!-- https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#Clustering -->


    <Class rdf:about="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#Clustering"/>
    


    <!-- https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#Decomposition -->


    <Class rdf:about="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#Decomposition"/>
    


    <!-- https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#InstanceBasedRegression -->


    <Class rdf:about="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#InstanceBasedRegression"/>
    


    <!-- https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#KDTreeMethod -->


    <Class rdf:about="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#KDTreeMethod">
        <rdfs:subClassOf rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod"/>
        <rdfs:subClassOf rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#NeighborsModule"/>
        <rdfs:subClassOf rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#TrainMethod"/>
        <rdfs:comment></rdfs:comment>
    </Class>
    


    <!-- https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#KNeighborsClassifierMethod -->


    <Class rdf:about="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#KNeighborsClassifierMethod">
        <rdfs:subClassOf rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod"/>
        <rdfs:subClassOf rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#NeighborsModule"/>
        <rdfs:subClassOf rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#TrainMethod"/>
        <rdfs:comment>Classifier implementing the k-nearest neighbors vote.

Read more in the :ref:`User Guide &lt;classification&gt;`.

Parameters
----------
n_neighbors : int, default=5
    Number of neighbors to use by default for :meth:`kneighbors` queries.

weights : {&apos;uniform&apos;, &apos;distance&apos;}, callable or None, default=&apos;uniform&apos;
    Weight function used in prediction.  Possible values:

    - &apos;uniform&apos; : uniform weights.  All points in each neighborhood
      are weighted equally.
    - &apos;distance&apos; : weight points by the inverse of their distance.
      in this case, closer neighbors of a query point will have a
      greater influence than neighbors which are further away.
    - [callable] : a user-defined function which accepts an
      array of distances, and returns an array of the same shape
      containing the weights.

    Refer to the example entitled
    :ref:`sphx_glr_auto_examples_neighbors_plot_classification.py`
    showing the impact of the `weights` parameter on the decision
    boundary.

algorithm : {&apos;auto&apos;, &apos;ball_tree&apos;, &apos;kd_tree&apos;, &apos;brute&apos;}, default=&apos;auto&apos;
    Algorithm used to compute the nearest neighbors:

    - &apos;ball_tree&apos; will use :class:`BallTree`
    - &apos;kd_tree&apos; will use :class:`KDTree`
    - &apos;brute&apos; will use a brute-force search.
    - &apos;auto&apos; will attempt to decide the most appropriate algorithm
      based on the values passed to :meth:`fit` method.

    Note: fitting on sparse input will override the setting of
    this parameter, using brute force.

leaf_size : int, default=30
    Leaf size passed to BallTree or KDTree.  This can affect the
    speed of the construction and query, as well as the memory
    required to store the tree.  The optimal value depends on the
    nature of the problem.

p : float, default=2
    Power parameter for the Minkowski metric. When p = 1, this is equivalent
    to using manhattan_distance (l1), and euclidean_distance (l2) for p = 2.
    For arbitrary p, minkowski_distance (l_p) is used. This parameter is expected
    to be positive.

metric : str or callable, default=&apos;minkowski&apos;
    Metric to use for distance computation. Default is &quot;minkowski&quot;, which
    results in the standard Euclidean distance when p = 2. See the
    documentation of `scipy.spatial.distance
    &lt;https://docs.scipy.org/doc/scipy/reference/spatial.distance.html&gt;`_ and
    the metrics listed in
    :class:`~sklearn.metrics.pairwise.distance_metrics` for valid metric
    values.

    If metric is &quot;precomputed&quot;, X is assumed to be a distance matrix and
    must be square during fit. X may be a :term:`sparse graph`, in which
    case only &quot;nonzero&quot; elements may be considered neighbors.

    If metric is a callable function, it takes two arrays representing 1D
    vectors as inputs and must return one value indicating the distance
    between those vectors. This works for Scipy&apos;s metrics, but is less
    efficient than passing the metric name as a string.

metric_params : dict, default=None
    Additional keyword arguments for the metric function.

n_jobs : int, default=None
    The number of parallel jobs to run for neighbors search.
    ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.
    ``-1`` means using all processors. See :term:`Glossary &lt;n_jobs&gt;`
    for more details.
    Doesn&apos;t affect :meth:`fit` method.

Attributes
----------
classes_ : array of shape (n_classes,)
    Class labels known to the classifier

effective_metric_ : str or callble
    The distance metric used. It will be same as the `metric` parameter
    or a synonym of it, e.g. &apos;euclidean&apos; if the `metric` parameter set to
    &apos;minkowski&apos; and `p` parameter set to 2.

effective_metric_params_ : dict
    Additional keyword arguments for the metric function. For most metrics
    will be same with `metric_params` parameter, but may also contain the
    `p` parameter value if the `effective_metric_` attribute is set to
    &apos;minkowski&apos;.

n_features_in_ : int
    Number of features seen during :term:`fit`.

    .. versionadded:: 0.24

feature_names_in_ : ndarray of shape (`n_features_in_`,)
    Names of features seen during :term:`fit`. Defined only when `X`
    has feature names that are all strings.

    .. versionadded:: 1.0

n_samples_fit_ : int
    Number of samples in the fitted data.

outputs_2d_ : bool
    False when `y`&apos;s shape is (n_samples, ) or (n_samples, 1) during fit
    otherwise True.

See Also
--------
RadiusNeighborsClassifier: Classifier based on neighbors within a fixed radius.
KNeighborsRegressor: Regression based on k-nearest neighbors.
RadiusNeighborsRegressor: Regression based on neighbors within a fixed radius.
NearestNeighbors: Unsupervised learner for implementing neighbor searches.

Notes
-----
See :ref:`Nearest Neighbors &lt;neighbors&gt;` in the online documentation
for a discussion of the choice of ``algorithm`` and ``leaf_size``.

.. warning::

   Regarding the Nearest Neighbors algorithms, if it is found that two
   neighbors, neighbor `k+1` and `k`, have identical distances
   but different labels, the results will depend on the ordering of the
   training data.

https://en.wikipedia.org/wiki/K-nearest_neighbor_algorithm

Examples
--------
&gt;&gt;&gt; X = [[0], [1], [2], [3]]
&gt;&gt;&gt; y = [0, 0, 1, 1]
&gt;&gt;&gt; from sklearn.neighbors import KNeighborsClassifier
&gt;&gt;&gt; neigh = KNeighborsClassifier(n_neighbors=3)
&gt;&gt;&gt; neigh.fit(X, y)
KNeighborsClassifier(...)
&gt;&gt;&gt; print(neigh.predict([[1.1]]))
[0]
&gt;&gt;&gt; print(neigh.predict_proba([[0.9]]))
[[0.666... 0.333...]]</rdfs:comment>
    </Class>
    


    <!-- https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#KNeighborsRegressorMethod -->


    <Class rdf:about="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#KNeighborsRegressorMethod">
        <rdfs:subClassOf rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod"/>
        <rdfs:subClassOf rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#NeighborsModule"/>
        <rdfs:subClassOf rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#TrainMethod"/>
        <rdfs:comment>Regression based on k-nearest neighbors.

The target is predicted by local interpolation of the targets
associated of the nearest neighbors in the training set.

Read more in the :ref:`User Guide &lt;regression&gt;`.

.. versionadded:: 0.9

Parameters
----------
n_neighbors : int, default=5
    Number of neighbors to use by default for :meth:`kneighbors` queries.

weights : {&apos;uniform&apos;, &apos;distance&apos;}, callable or None, default=&apos;uniform&apos;
    Weight function used in prediction.  Possible values:

    - &apos;uniform&apos; : uniform weights.  All points in each neighborhood
      are weighted equally.
    - &apos;distance&apos; : weight points by the inverse of their distance.
      in this case, closer neighbors of a query point will have a
      greater influence than neighbors which are further away.
    - [callable] : a user-defined function which accepts an
      array of distances, and returns an array of the same shape
      containing the weights.

    Uniform weights are used by default.

algorithm : {&apos;auto&apos;, &apos;ball_tree&apos;, &apos;kd_tree&apos;, &apos;brute&apos;}, default=&apos;auto&apos;
    Algorithm used to compute the nearest neighbors:

    - &apos;ball_tree&apos; will use :class:`BallTree`
    - &apos;kd_tree&apos; will use :class:`KDTree`
    - &apos;brute&apos; will use a brute-force search.
    - &apos;auto&apos; will attempt to decide the most appropriate algorithm
      based on the values passed to :meth:`fit` method.

    Note: fitting on sparse input will override the setting of
    this parameter, using brute force.

leaf_size : int, default=30
    Leaf size passed to BallTree or KDTree.  This can affect the
    speed of the construction and query, as well as the memory
    required to store the tree.  The optimal value depends on the
    nature of the problem.

p : float, default=2
    Power parameter for the Minkowski metric. When p = 1, this is
    equivalent to using manhattan_distance (l1), and euclidean_distance
    (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.

metric : str, DistanceMetric object or callable, default=&apos;minkowski&apos;
    Metric to use for distance computation. Default is &quot;minkowski&quot;, which
    results in the standard Euclidean distance when p = 2. See the
    documentation of `scipy.spatial.distance
    &lt;https://docs.scipy.org/doc/scipy/reference/spatial.distance.html&gt;`_ and
    the metrics listed in
    :class:`~sklearn.metrics.pairwise.distance_metrics` for valid metric
    values.

    If metric is &quot;precomputed&quot;, X is assumed to be a distance matrix and
    must be square during fit. X may be a :term:`sparse graph`, in which
    case only &quot;nonzero&quot; elements may be considered neighbors.

    If metric is a callable function, it takes two arrays representing 1D
    vectors as inputs and must return one value indicating the distance
    between those vectors. This works for Scipy&apos;s metrics, but is less
    efficient than passing the metric name as a string.

    If metric is a DistanceMetric object, it will be passed directly to
    the underlying computation routines.

metric_params : dict, default=None
    Additional keyword arguments for the metric function.

n_jobs : int, default=None
    The number of parallel jobs to run for neighbors search.
    ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.
    ``-1`` means using all processors. See :term:`Glossary &lt;n_jobs&gt;`
    for more details.
    Doesn&apos;t affect :meth:`fit` method.

Attributes
----------
effective_metric_ : str or callable
    The distance metric to use. It will be same as the `metric` parameter
    or a synonym of it, e.g. &apos;euclidean&apos; if the `metric` parameter set to
    &apos;minkowski&apos; and `p` parameter set to 2.

effective_metric_params_ : dict
    Additional keyword arguments for the metric function. For most metrics
    will be same with `metric_params` parameter, but may also contain the
    `p` parameter value if the `effective_metric_` attribute is set to
    &apos;minkowski&apos;.

n_features_in_ : int
    Number of features seen during :term:`fit`.

    .. versionadded:: 0.24

feature_names_in_ : ndarray of shape (`n_features_in_`,)
    Names of features seen during :term:`fit`. Defined only when `X`
    has feature names that are all strings.

    .. versionadded:: 1.0

n_samples_fit_ : int
    Number of samples in the fitted data.

See Also
--------
NearestNeighbors : Unsupervised learner for implementing neighbor searches.
RadiusNeighborsRegressor : Regression based on neighbors within a fixed radius.
KNeighborsClassifier : Classifier implementing the k-nearest neighbors vote.
RadiusNeighborsClassifier : Classifier implementing
    a vote among neighbors within a given radius.

Notes
-----
See :ref:`Nearest Neighbors &lt;neighbors&gt;` in the online documentation
for a discussion of the choice of ``algorithm`` and ``leaf_size``.

.. warning::

   Regarding the Nearest Neighbors algorithms, if it is found that two
   neighbors, neighbor `k+1` and `k`, have identical distances but
   different labels, the results will depend on the ordering of the
   training data.

https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm

Examples
--------
&gt;&gt;&gt; X = [[0], [1], [2], [3]]
&gt;&gt;&gt; y = [0, 0, 1, 1]
&gt;&gt;&gt; from sklearn.neighbors import KNeighborsRegressor
&gt;&gt;&gt; neigh = KNeighborsRegressor(n_neighbors=2)
&gt;&gt;&gt; neigh.fit(X, y)
KNeighborsRegressor(...)
&gt;&gt;&gt; print(neigh.predict([[1.5]]))
[0.5]</rdfs:comment>
    </Class>
    


    <!-- https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#KNeighborsTransformerMethod -->


    <Class rdf:about="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#KNeighborsTransformerMethod">
        <rdfs:subClassOf rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod"/>
        <rdfs:subClassOf rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#NeighborsModule"/>
        <rdfs:subClassOf rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#TrainMethod"/>
        <rdfs:comment>Transform X into a (weighted) graph of k nearest neighbors.

The transformed data is a sparse graph as returned by kneighbors_graph.

Read more in the :ref:`User Guide &lt;neighbors_transformer&gt;`.

.. versionadded:: 0.22

Parameters
----------
mode : {&apos;distance&apos;, &apos;connectivity&apos;}, default=&apos;distance&apos;
    Type of returned matrix: &apos;connectivity&apos; will return the connectivity
    matrix with ones and zeros, and &apos;distance&apos; will return the distances
    between neighbors according to the given metric.

n_neighbors : int, default=5
    Number of neighbors for each sample in the transformed sparse graph.
    For compatibility reasons, as each sample is considered as its own
    neighbor, one extra neighbor will be computed when mode == &apos;distance&apos;.
    In this case, the sparse graph contains (n_neighbors + 1) neighbors.

algorithm : {&apos;auto&apos;, &apos;ball_tree&apos;, &apos;kd_tree&apos;, &apos;brute&apos;}, default=&apos;auto&apos;
    Algorithm used to compute the nearest neighbors:

    - &apos;ball_tree&apos; will use :class:`BallTree`
    - &apos;kd_tree&apos; will use :class:`KDTree`
    - &apos;brute&apos; will use a brute-force search.
    - &apos;auto&apos; will attempt to decide the most appropriate algorithm
      based on the values passed to :meth:`fit` method.

    Note: fitting on sparse input will override the setting of
    this parameter, using brute force.

leaf_size : int, default=30
    Leaf size passed to BallTree or KDTree.  This can affect the
    speed of the construction and query, as well as the memory
    required to store the tree.  The optimal value depends on the
    nature of the problem.

metric : str or callable, default=&apos;minkowski&apos;
    Metric to use for distance computation. Default is &quot;minkowski&quot;, which
    results in the standard Euclidean distance when p = 2. See the
    documentation of `scipy.spatial.distance
    &lt;https://docs.scipy.org/doc/scipy/reference/spatial.distance.html&gt;`_ and
    the metrics listed in
    :class:`~sklearn.metrics.pairwise.distance_metrics` for valid metric
    values.

    If metric is a callable function, it takes two arrays representing 1D
    vectors as inputs and must return one value indicating the distance
    between those vectors. This works for Scipy&apos;s metrics, but is less
    efficient than passing the metric name as a string.

    Distance matrices are not supported.

p : float, default=2
    Parameter for the Minkowski metric from
    sklearn.metrics.pairwise.pairwise_distances. When p = 1, this is
    equivalent to using manhattan_distance (l1), and euclidean_distance
    (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.
    This parameter is expected to be positive.

metric_params : dict, default=None
    Additional keyword arguments for the metric function.

n_jobs : int, default=None
    The number of parallel jobs to run for neighbors search.
    If ``-1``, then the number of jobs is set to the number of CPU cores.

Attributes
----------
effective_metric_ : str or callable
    The distance metric used. It will be same as the `metric` parameter
    or a synonym of it, e.g. &apos;euclidean&apos; if the `metric` parameter set to
    &apos;minkowski&apos; and `p` parameter set to 2.

effective_metric_params_ : dict
    Additional keyword arguments for the metric function. For most metrics
    will be same with `metric_params` parameter, but may also contain the
    `p` parameter value if the `effective_metric_` attribute is set to
    &apos;minkowski&apos;.

n_features_in_ : int
    Number of features seen during :term:`fit`.

    .. versionadded:: 0.24

feature_names_in_ : ndarray of shape (`n_features_in_`,)
    Names of features seen during :term:`fit`. Defined only when `X`
    has feature names that are all strings.

    .. versionadded:: 1.0

n_samples_fit_ : int
    Number of samples in the fitted data.

See Also
--------
kneighbors_graph : Compute the weighted graph of k-neighbors for
    points in X.
RadiusNeighborsTransformer : Transform X into a weighted graph of
    neighbors nearer than a radius.

Notes
-----
For an example of using :class:`~sklearn.neighbors.KNeighborsTransformer`
in combination with :class:`~sklearn.manifold.TSNE` see
:ref:`sphx_glr_auto_examples_neighbors_approximate_nearest_neighbors.py`.

Examples
--------
&gt;&gt;&gt; from sklearn.datasets import load_wine
&gt;&gt;&gt; from sklearn.neighbors import KNeighborsTransformer
&gt;&gt;&gt; X, _ = load_wine(return_X_y=True)
&gt;&gt;&gt; X.shape
(178, 13)
&gt;&gt;&gt; transformer = KNeighborsTransformer(n_neighbors=5, mode=&apos;distance&apos;)
&gt;&gt;&gt; X_dist_graph = transformer.fit_transform(X)
&gt;&gt;&gt; X_dist_graph.shape
(178, 178)</rdfs:comment>
    </Class>
    


    <!-- https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#KernelDensityMethod -->


    <Class rdf:about="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#KernelDensityMethod">
        <rdfs:subClassOf rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod"/>
        <rdfs:subClassOf rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#NeighborsModule"/>
        <rdfs:subClassOf rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#TrainMethod"/>
        <rdfs:comment>Kernel Density Estimation.

Read more in the :ref:`User Guide &lt;kernel_density&gt;`.

Parameters
----------
bandwidth : float or {&quot;scott&quot;, &quot;silverman&quot;}, default=1.0
    The bandwidth of the kernel. If bandwidth is a float, it defines the
    bandwidth of the kernel. If bandwidth is a string, one of the estimation
    methods is implemented.

algorithm : {&apos;kd_tree&apos;, &apos;ball_tree&apos;, &apos;auto&apos;}, default=&apos;auto&apos;
    The tree algorithm to use.

kernel : {&apos;gaussian&apos;, &apos;tophat&apos;, &apos;epanechnikov&apos;, &apos;exponential&apos;, &apos;linear&apos;,                  &apos;cosine&apos;}, default=&apos;gaussian&apos;
    The kernel to use.

metric : str, default=&apos;euclidean&apos;
    Metric to use for distance computation. See the
    documentation of `scipy.spatial.distance
    &lt;https://docs.scipy.org/doc/scipy/reference/spatial.distance.html&gt;`_ and
    the metrics listed in
    :class:`~sklearn.metrics.pairwise.distance_metrics` for valid metric
    values.

    Not all metrics are valid with all algorithms: refer to the
    documentation of :class:`BallTree` and :class:`KDTree`. Note that the
    normalization of the density output is correct only for the Euclidean
    distance metric.

atol : float, default=0
    The desired absolute tolerance of the result.  A larger tolerance will
    generally lead to faster execution.

rtol : float, default=0
    The desired relative tolerance of the result.  A larger tolerance will
    generally lead to faster execution.

breadth_first : bool, default=True
    If true (default), use a breadth-first approach to the problem.
    Otherwise use a depth-first approach.

leaf_size : int, default=40
    Specify the leaf size of the underlying tree.  See :class:`BallTree`
    or :class:`KDTree` for details.

metric_params : dict, default=None
    Additional parameters to be passed to the tree for use with the
    metric.  For more information, see the documentation of
    :class:`BallTree` or :class:`KDTree`.

Attributes
----------
n_features_in_ : int
    Number of features seen during :term:`fit`.

    .. versionadded:: 0.24

tree_ : ``BinaryTree`` instance
    The tree algorithm for fast generalized N-point problems.

feature_names_in_ : ndarray of shape (`n_features_in_`,)
    Names of features seen during :term:`fit`. Defined only when `X`
    has feature names that are all strings.

bandwidth_ : float
    Value of the bandwidth, given directly by the bandwidth parameter or
    estimated using the &apos;scott&apos; or &apos;silverman&apos; method.

    .. versionadded:: 1.0

See Also
--------
sklearn.neighbors.KDTree : K-dimensional tree for fast generalized N-point
    problems.
sklearn.neighbors.BallTree : Ball tree for fast generalized N-point
    problems.

Examples
--------
Compute a gaussian kernel density estimate with a fixed bandwidth.

&gt;&gt;&gt; from sklearn.neighbors import KernelDensity
&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; rng = np.random.RandomState(42)
&gt;&gt;&gt; X = rng.random_sample((100, 3))
&gt;&gt;&gt; kde = KernelDensity(kernel=&apos;gaussian&apos;, bandwidth=0.5).fit(X)
&gt;&gt;&gt; log_density = kde.score_samples(X[:3])
&gt;&gt;&gt; log_density
array([-1.52955942, -1.51462041, -1.60244657])</rdfs:comment>
    </Class>
    


    <!-- https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#LocalOutlierFactorMethod -->


    <Class rdf:about="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#LocalOutlierFactorMethod">
        <rdfs:subClassOf rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod"/>
        <rdfs:subClassOf rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#NeighborsModule"/>
        <rdfs:subClassOf rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#TrainMethod"/>
        <rdfs:comment>Unsupervised Outlier Detection using the Local Outlier Factor (LOF).

The anomaly score of each sample is called the Local Outlier Factor.
It measures the local deviation of the density of a given sample with respect
to its neighbors.
It is local in that the anomaly score depends on how isolated the object
is with respect to the surrounding neighborhood.
More precisely, locality is given by k-nearest neighbors, whose distance
is used to estimate the local density.
By comparing the local density of a sample to the local densities of its
neighbors, one can identify samples that have a substantially lower density
than their neighbors. These are considered outliers.

.. versionadded:: 0.19

Parameters
----------
n_neighbors : int, default=20
    Number of neighbors to use by default for :meth:`kneighbors` queries.
    If n_neighbors is larger than the number of samples provided,
    all samples will be used.

algorithm : {&apos;auto&apos;, &apos;ball_tree&apos;, &apos;kd_tree&apos;, &apos;brute&apos;}, default=&apos;auto&apos;
    Algorithm used to compute the nearest neighbors:

    - &apos;ball_tree&apos; will use :class:`BallTree`
    - &apos;kd_tree&apos; will use :class:`KDTree`
    - &apos;brute&apos; will use a brute-force search.
    - &apos;auto&apos; will attempt to decide the most appropriate algorithm
      based on the values passed to :meth:`fit` method.

    Note: fitting on sparse input will override the setting of
    this parameter, using brute force.

leaf_size : int, default=30
    Leaf is size passed to :class:`BallTree` or :class:`KDTree`. This can
    affect the speed of the construction and query, as well as the memory
    required to store the tree. The optimal value depends on the
    nature of the problem.

metric : str or callable, default=&apos;minkowski&apos;
    Metric to use for distance computation. Default is &quot;minkowski&quot;, which
    results in the standard Euclidean distance when p = 2. See the
    documentation of `scipy.spatial.distance
    &lt;https://docs.scipy.org/doc/scipy/reference/spatial.distance.html&gt;`_ and
    the metrics listed in
    :class:`~sklearn.metrics.pairwise.distance_metrics` for valid metric
    values.

    If metric is &quot;precomputed&quot;, X is assumed to be a distance matrix and
    must be square during fit. X may be a :term:`sparse graph`, in which
    case only &quot;nonzero&quot; elements may be considered neighbors.

    If metric is a callable function, it takes two arrays representing 1D
    vectors as inputs and must return one value indicating the distance
    between those vectors. This works for Scipy&apos;s metrics, but is less
    efficient than passing the metric name as a string.

p : float, default=2
    Parameter for the Minkowski metric from
    :func:`sklearn.metrics.pairwise_distances`. When p = 1, this
    is equivalent to using manhattan_distance (l1), and euclidean_distance
    (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.

metric_params : dict, default=None
    Additional keyword arguments for the metric function.

contamination : &apos;auto&apos; or float, default=&apos;auto&apos;
    The amount of contamination of the data set, i.e. the proportion
    of outliers in the data set. When fitting this is used to define the
    threshold on the scores of the samples.

    - if &apos;auto&apos;, the threshold is determined as in the
      original paper,
    - if a float, the contamination should be in the range (0, 0.5].

    .. versionchanged:: 0.22
       The default value of ``contamination`` changed from 0.1
       to ``&apos;auto&apos;``.

novelty : bool, default=False
    By default, LocalOutlierFactor is only meant to be used for outlier
    detection (novelty=False). Set novelty to True if you want to use
    LocalOutlierFactor for novelty detection. In this case be aware that
    you should only use predict, decision_function and score_samples
    on new unseen data and not on the training set; and note that the
    results obtained this way may differ from the standard LOF results.

    .. versionadded:: 0.20

n_jobs : int, default=None
    The number of parallel jobs to run for neighbors search.
    ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.
    ``-1`` means using all processors. See :term:`Glossary &lt;n_jobs&gt;`
    for more details.

Attributes
----------
negative_outlier_factor_ : ndarray of shape (n_samples,)
    The opposite LOF of the training samples. The higher, the more normal.
    Inliers tend to have a LOF score close to 1
    (``negative_outlier_factor_`` close to -1), while outliers tend to have
    a larger LOF score.

    The local outlier factor (LOF) of a sample captures its
    supposed &apos;degree of abnormality&apos;.
    It is the average of the ratio of the local reachability density of
    a sample and those of its k-nearest neighbors.

n_neighbors_ : int
    The actual number of neighbors used for :meth:`kneighbors` queries.

offset_ : float
    Offset used to obtain binary labels from the raw scores.
    Observations having a negative_outlier_factor smaller than `offset_`
    are detected as abnormal.
    The offset is set to -1.5 (inliers score around -1), except when a
    contamination parameter different than &quot;auto&quot; is provided. In that
    case, the offset is defined in such a way we obtain the expected
    number of outliers in training.

    .. versionadded:: 0.20

effective_metric_ : str
    The effective metric used for the distance computation.

effective_metric_params_ : dict
    The effective additional keyword arguments for the metric function.

n_features_in_ : int
    Number of features seen during :term:`fit`.

    .. versionadded:: 0.24

feature_names_in_ : ndarray of shape (`n_features_in_`,)
    Names of features seen during :term:`fit`. Defined only when `X`
    has feature names that are all strings.

    .. versionadded:: 1.0

n_samples_fit_ : int
    It is the number of samples in the fitted data.

See Also
--------
sklearn.svm.OneClassSVM: Unsupervised Outlier Detection using
    Support Vector Machine.

References
----------
.. [1] Breunig, M. M., Kriegel, H. P., Ng, R. T., &amp; Sander, J. (2000, May).
       LOF: identifying density-based local outliers. In ACM sigmod record.

Examples
--------
&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; from sklearn.neighbors import LocalOutlierFactor
&gt;&gt;&gt; X = [[-1.1], [0.2], [101.1], [0.3]]
&gt;&gt;&gt; clf = LocalOutlierFactor(n_neighbors=2)
&gt;&gt;&gt; clf.fit_predict(X)
array([ 1,  1, -1,  1])
&gt;&gt;&gt; clf.negative_outlier_factor_
array([ -0.9821...,  -1.0370..., -73.3697...,  -0.9821...])</rdfs:comment>
    </Class>
    


    <!-- https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MulticlassClassification -->


    <Class rdf:about="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MulticlassClassification"/>
    


    <!-- https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MultilabelClassification -->


    <Class rdf:about="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#MultilabelClassification"/>
    


    <!-- https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#NearestCentroidMethod -->


    <Class rdf:about="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#NearestCentroidMethod">
        <rdfs:subClassOf rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod"/>
        <rdfs:subClassOf rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#NeighborsModule"/>
        <rdfs:subClassOf rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#TrainMethod"/>
        <rdfs:comment>Nearest centroid classifier.

Each class is represented by its centroid, with test samples classified to
the class with the nearest centroid.

Read more in the :ref:`User Guide &lt;nearest_centroid_classifier&gt;`.

Parameters
----------
metric : str or callable, default=&quot;euclidean&quot;
    Metric to use for distance computation. See the documentation of
    `scipy.spatial.distance
    &lt;https://docs.scipy.org/doc/scipy/reference/spatial.distance.html&gt;`_ and
    the metrics listed in
    :class:`~sklearn.metrics.pairwise.distance_metrics` for valid metric
    values. Note that &quot;wminkowski&quot;, &quot;seuclidean&quot; and &quot;mahalanobis&quot; are not
    supported.

    The centroids for the samples corresponding to each class is
    the point from which the sum of the distances (according to the metric)
    of all samples that belong to that particular class are minimized.
    If the `&quot;manhattan&quot;` metric is provided, this centroid is the median
    and for all other metrics, the centroid is now set to be the mean.

    .. deprecated:: 1.3
        Support for metrics other than `euclidean` and `manhattan` and for
        callables was deprecated in version 1.3 and will be removed in
        version 1.5.

    .. versionchanged:: 0.19
        `metric=&apos;precomputed&apos;` was deprecated and now raises an error

shrink_threshold : float, default=None
    Threshold for shrinking centroids to remove features.

Attributes
----------
centroids_ : array-like of shape (n_classes, n_features)
    Centroid of each class.

classes_ : array of shape (n_classes,)
    The unique classes labels.

n_features_in_ : int
    Number of features seen during :term:`fit`.

    .. versionadded:: 0.24

feature_names_in_ : ndarray of shape (`n_features_in_`,)
    Names of features seen during :term:`fit`. Defined only when `X`
    has feature names that are all strings.

    .. versionadded:: 1.0

See Also
--------
KNeighborsClassifier : Nearest neighbors classifier.

Notes
-----
When used for text classification with tf-idf vectors, this classifier is
also known as the Rocchio classifier.

References
----------
Tibshirani, R., Hastie, T., Narasimhan, B., &amp; Chu, G. (2002). Diagnosis of
multiple cancer types by shrunken centroids of gene expression. Proceedings
of the National Academy of Sciences of the United States of America,
99(10), 6567-6572. The National Academy of Sciences.

Examples
--------
&gt;&gt;&gt; from sklearn.neighbors import NearestCentroid
&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])
&gt;&gt;&gt; y = np.array([1, 1, 1, 2, 2, 2])
&gt;&gt;&gt; clf = NearestCentroid()
&gt;&gt;&gt; clf.fit(X, y)
NearestCentroid()
&gt;&gt;&gt; print(clf.predict([[-0.8, -1]]))
[1]</rdfs:comment>
    </Class>
    


    <!-- https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#NearestNeighborsMethod -->


    <Class rdf:about="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#NearestNeighborsMethod">
        <rdfs:subClassOf rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod"/>
        <rdfs:subClassOf rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#NeighborsModule"/>
        <rdfs:subClassOf rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#TrainMethod"/>
        <rdfs:comment>Unsupervised learner for implementing neighbor searches.

Read more in the :ref:`User Guide &lt;unsupervised_neighbors&gt;`.

.. versionadded:: 0.9

Parameters
----------
n_neighbors : int, default=5
    Number of neighbors to use by default for :meth:`kneighbors` queries.

radius : float, default=1.0
    Range of parameter space to use by default for :meth:`radius_neighbors`
    queries.

algorithm : {&apos;auto&apos;, &apos;ball_tree&apos;, &apos;kd_tree&apos;, &apos;brute&apos;}, default=&apos;auto&apos;
    Algorithm used to compute the nearest neighbors:

    - &apos;ball_tree&apos; will use :class:`BallTree`
    - &apos;kd_tree&apos; will use :class:`KDTree`
    - &apos;brute&apos; will use a brute-force search.
    - &apos;auto&apos; will attempt to decide the most appropriate algorithm
      based on the values passed to :meth:`fit` method.

    Note: fitting on sparse input will override the setting of
    this parameter, using brute force.

leaf_size : int, default=30
    Leaf size passed to BallTree or KDTree.  This can affect the
    speed of the construction and query, as well as the memory
    required to store the tree.  The optimal value depends on the
    nature of the problem.

metric : str or callable, default=&apos;minkowski&apos;
    Metric to use for distance computation. Default is &quot;minkowski&quot;, which
    results in the standard Euclidean distance when p = 2. See the
    documentation of `scipy.spatial.distance
    &lt;https://docs.scipy.org/doc/scipy/reference/spatial.distance.html&gt;`_ and
    the metrics listed in
    :class:`~sklearn.metrics.pairwise.distance_metrics` for valid metric
    values.

    If metric is &quot;precomputed&quot;, X is assumed to be a distance matrix and
    must be square during fit. X may be a :term:`sparse graph`, in which
    case only &quot;nonzero&quot; elements may be considered neighbors.

    If metric is a callable function, it takes two arrays representing 1D
    vectors as inputs and must return one value indicating the distance
    between those vectors. This works for Scipy&apos;s metrics, but is less
    efficient than passing the metric name as a string.

p : float (positive), default=2
    Parameter for the Minkowski metric from
    sklearn.metrics.pairwise.pairwise_distances. When p = 1, this is
    equivalent to using manhattan_distance (l1), and euclidean_distance
    (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.

metric_params : dict, default=None
    Additional keyword arguments for the metric function.

n_jobs : int, default=None
    The number of parallel jobs to run for neighbors search.
    ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.
    ``-1`` means using all processors. See :term:`Glossary &lt;n_jobs&gt;`
    for more details.

Attributes
----------
effective_metric_ : str
    Metric used to compute distances to neighbors.

effective_metric_params_ : dict
    Parameters for the metric used to compute distances to neighbors.

n_features_in_ : int
    Number of features seen during :term:`fit`.

    .. versionadded:: 0.24

feature_names_in_ : ndarray of shape (`n_features_in_`,)
    Names of features seen during :term:`fit`. Defined only when `X`
    has feature names that are all strings.

    .. versionadded:: 1.0

n_samples_fit_ : int
    Number of samples in the fitted data.

See Also
--------
KNeighborsClassifier : Classifier implementing the k-nearest neighbors
    vote.
RadiusNeighborsClassifier : Classifier implementing a vote among neighbors
    within a given radius.
KNeighborsRegressor : Regression based on k-nearest neighbors.
RadiusNeighborsRegressor : Regression based on neighbors within a fixed
    radius.
BallTree : Space partitioning data structure for organizing points in a
    multi-dimensional space, used for nearest neighbor search.

Notes
-----
See :ref:`Nearest Neighbors &lt;neighbors&gt;` in the online documentation
for a discussion of the choice of ``algorithm`` and ``leaf_size``.

https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm

Examples
--------
&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; from sklearn.neighbors import NearestNeighbors
&gt;&gt;&gt; samples = [[0, 0, 2], [1, 0, 0], [0, 0, 1]]
&gt;&gt;&gt; neigh = NearestNeighbors(n_neighbors=2, radius=0.4)
&gt;&gt;&gt; neigh.fit(samples)
NearestNeighbors(...)
&gt;&gt;&gt; neigh.kneighbors([[0, 0, 1.3]], 2, return_distance=False)
array([[2, 0]]...)
&gt;&gt;&gt; nbrs = neigh.radius_neighbors(
...    [[0, 0, 1.3]], 0.4, return_distance=False
... )
&gt;&gt;&gt; np.asarray(nbrs[0][0])
array(2)</rdfs:comment>
    </Class>
    


    <!-- https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#NeighborhoodComponentsAnalysisMethod -->


    <Class rdf:about="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#NeighborhoodComponentsAnalysisMethod">
        <rdfs:subClassOf rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod"/>
        <rdfs:subClassOf rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#NeighborsModule"/>
        <rdfs:subClassOf rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PrepareTransformerMethod"/>
        <rdfs:comment>Neighborhood Components Analysis.

Neighborhood Component Analysis (NCA) is a machine learning algorithm for
metric learning. It learns a linear transformation in a supervised fashion
to improve the classification accuracy of a stochastic nearest neighbors
rule in the transformed space.

Read more in the :ref:`User Guide &lt;nca&gt;`.

Parameters
----------
n_components : int, default=None
    Preferred dimensionality of the projected space.
    If None it will be set to `n_features`.

init : {&apos;auto&apos;, &apos;pca&apos;, &apos;lda&apos;, &apos;identity&apos;, &apos;random&apos;} or ndarray of shape             (n_features_a, n_features_b), default=&apos;auto&apos;
    Initialization of the linear transformation. Possible options are
    `&apos;auto&apos;`, `&apos;pca&apos;`, `&apos;lda&apos;`, `&apos;identity&apos;`, `&apos;random&apos;`, and a numpy
    array of shape `(n_features_a, n_features_b)`.

    - `&apos;auto&apos;`
        Depending on `n_components`, the most reasonable initialization
        will be chosen. If `n_components &lt;= n_classes` we use `&apos;lda&apos;`, as
        it uses labels information. If not, but
        `n_components &lt; min(n_features, n_samples)`, we use `&apos;pca&apos;`, as
        it projects data in meaningful directions (those of higher
        variance). Otherwise, we just use `&apos;identity&apos;`.

    - `&apos;pca&apos;`
        `n_components` principal components of the inputs passed
        to :meth:`fit` will be used to initialize the transformation.
        (See :class:`~sklearn.decomposition.PCA`)

    - `&apos;lda&apos;`
        `min(n_components, n_classes)` most discriminative
        components of the inputs passed to :meth:`fit` will be used to
        initialize the transformation. (If `n_components &gt; n_classes`,
        the rest of the components will be zero.) (See
        :class:`~sklearn.discriminant_analysis.LinearDiscriminantAnalysis`)

    - `&apos;identity&apos;`
        If `n_components` is strictly smaller than the
        dimensionality of the inputs passed to :meth:`fit`, the identity
        matrix will be truncated to the first `n_components` rows.

    - `&apos;random&apos;`
        The initial transformation will be a random array of shape
        `(n_components, n_features)`. Each value is sampled from the
        standard normal distribution.

    - numpy array
        `n_features_b` must match the dimensionality of the inputs passed
        to :meth:`fit` and n_features_a must be less than or equal to that.
        If `n_components` is not `None`, `n_features_a` must match it.

warm_start : bool, default=False
    If `True` and :meth:`fit` has been called before, the solution of the
    previous call to :meth:`fit` is used as the initial linear
    transformation (`n_components` and `init` will be ignored).

max_iter : int, default=50
    Maximum number of iterations in the optimization.

tol : float, default=1e-5
    Convergence tolerance for the optimization.

callback : callable, default=None
    If not `None`, this function is called after every iteration of the
    optimizer, taking as arguments the current solution (flattened
    transformation matrix) and the number of iterations. This might be
    useful in case one wants to examine or store the transformation
    found after each iteration.

verbose : int, default=0
    If 0, no progress messages will be printed.
    If 1, progress messages will be printed to stdout.
    If &gt; 1, progress messages will be printed and the `disp`
    parameter of :func:`scipy.optimize.minimize` will be set to
    `verbose - 2`.

random_state : int or numpy.RandomState, default=None
    A pseudo random number generator object or a seed for it if int. If
    `init=&apos;random&apos;`, `random_state` is used to initialize the random
    transformation. If `init=&apos;pca&apos;`, `random_state` is passed as an
    argument to PCA when initializing the transformation. Pass an int
    for reproducible results across multiple function calls.
    See :term:`Glossary &lt;random_state&gt;`.

Attributes
----------
components_ : ndarray of shape (n_components, n_features)
    The linear transformation learned during fitting.

n_features_in_ : int
    Number of features seen during :term:`fit`.

    .. versionadded:: 0.24

n_iter_ : int
    Counts the number of iterations performed by the optimizer.

random_state_ : numpy.RandomState
    Pseudo random number generator object used during initialization.

feature_names_in_ : ndarray of shape (`n_features_in_`,)
    Names of features seen during :term:`fit`. Defined only when `X`
    has feature names that are all strings.

    .. versionadded:: 1.0

See Also
--------
sklearn.discriminant_analysis.LinearDiscriminantAnalysis : Linear
    Discriminant Analysis.
sklearn.decomposition.PCA : Principal component analysis (PCA).

References
----------
.. [1] J. Goldberger, G. Hinton, S. Roweis, R. Salakhutdinov.
       &quot;Neighbourhood Components Analysis&quot;. Advances in Neural Information
       Processing Systems. 17, 513-520, 2005.
       http://www.cs.nyu.edu/~roweis/papers/ncanips.pdf

.. [2] Wikipedia entry on Neighborhood Components Analysis
       https://en.wikipedia.org/wiki/Neighbourhood_components_analysis

Examples
--------
&gt;&gt;&gt; from sklearn.neighbors import NeighborhoodComponentsAnalysis
&gt;&gt;&gt; from sklearn.neighbors import KNeighborsClassifier
&gt;&gt;&gt; from sklearn.datasets import load_iris
&gt;&gt;&gt; from sklearn.model_selection import train_test_split
&gt;&gt;&gt; X, y = load_iris(return_X_y=True)
&gt;&gt;&gt; X_train, X_test, y_train, y_test = train_test_split(X, y,
... stratify=y, test_size=0.7, random_state=42)
&gt;&gt;&gt; nca = NeighborhoodComponentsAnalysis(random_state=42)
&gt;&gt;&gt; nca.fit(X_train, y_train)
NeighborhoodComponentsAnalysis(...)
&gt;&gt;&gt; knn = KNeighborsClassifier(n_neighbors=3)
&gt;&gt;&gt; knn.fit(X_train, y_train)
KNeighborsClassifier(...)
&gt;&gt;&gt; print(knn.score(X_test, y_test))
0.933333...
&gt;&gt;&gt; knn.fit(nca.transform(X_train), y_train)
KNeighborsClassifier(...)
&gt;&gt;&gt; print(knn.score(nca.transform(X_test), y_test))
0.961904...</rdfs:comment>
    </Class>
    


    <!-- https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#NeighborsModule -->


    <Class rdf:about="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#NeighborsModule">
        <rdfs:subClassOf rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#SklearnModule"/>
    </Class>
    


    <!-- https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PrepareTransformerMethod -->


    <Class rdf:about="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#PrepareTransformerMethod"/>
    


    <!-- https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RadiusNeighborsClassifierMethod -->


    <Class rdf:about="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RadiusNeighborsClassifierMethod">
        <rdfs:subClassOf rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod"/>
        <rdfs:subClassOf rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#NeighborsModule"/>
        <rdfs:subClassOf rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#TrainMethod"/>
        <rdfs:comment>Classifier implementing a vote among neighbors within a given radius.

Read more in the :ref:`User Guide &lt;classification&gt;`.

Parameters
----------
radius : float, default=1.0
    Range of parameter space to use by default for :meth:`radius_neighbors`
    queries.

weights : {&apos;uniform&apos;, &apos;distance&apos;}, callable or None, default=&apos;uniform&apos;
    Weight function used in prediction.  Possible values:

    - &apos;uniform&apos; : uniform weights.  All points in each neighborhood
      are weighted equally.
    - &apos;distance&apos; : weight points by the inverse of their distance.
      in this case, closer neighbors of a query point will have a
      greater influence than neighbors which are further away.
    - [callable] : a user-defined function which accepts an
      array of distances, and returns an array of the same shape
      containing the weights.

    Uniform weights are used by default.

algorithm : {&apos;auto&apos;, &apos;ball_tree&apos;, &apos;kd_tree&apos;, &apos;brute&apos;}, default=&apos;auto&apos;
    Algorithm used to compute the nearest neighbors:

    - &apos;ball_tree&apos; will use :class:`BallTree`
    - &apos;kd_tree&apos; will use :class:`KDTree`
    - &apos;brute&apos; will use a brute-force search.
    - &apos;auto&apos; will attempt to decide the most appropriate algorithm
      based on the values passed to :meth:`fit` method.

    Note: fitting on sparse input will override the setting of
    this parameter, using brute force.

leaf_size : int, default=30
    Leaf size passed to BallTree or KDTree.  This can affect the
    speed of the construction and query, as well as the memory
    required to store the tree.  The optimal value depends on the
    nature of the problem.

p : float, default=2
    Power parameter for the Minkowski metric. When p = 1, this is
    equivalent to using manhattan_distance (l1), and euclidean_distance
    (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.
    This parameter is expected to be positive.

metric : str or callable, default=&apos;minkowski&apos;
    Metric to use for distance computation. Default is &quot;minkowski&quot;, which
    results in the standard Euclidean distance when p = 2. See the
    documentation of `scipy.spatial.distance
    &lt;https://docs.scipy.org/doc/scipy/reference/spatial.distance.html&gt;`_ and
    the metrics listed in
    :class:`~sklearn.metrics.pairwise.distance_metrics` for valid metric
    values.

    If metric is &quot;precomputed&quot;, X is assumed to be a distance matrix and
    must be square during fit. X may be a :term:`sparse graph`, in which
    case only &quot;nonzero&quot; elements may be considered neighbors.

    If metric is a callable function, it takes two arrays representing 1D
    vectors as inputs and must return one value indicating the distance
    between those vectors. This works for Scipy&apos;s metrics, but is less
    efficient than passing the metric name as a string.

outlier_label : {manual label, &apos;most_frequent&apos;}, default=None
    Label for outlier samples (samples with no neighbors in given radius).

    - manual label: str or int label (should be the same type as y)
      or list of manual labels if multi-output is used.
    - &apos;most_frequent&apos; : assign the most frequent label of y to outliers.
    - None : when any outlier is detected, ValueError will be raised.

    The outlier label should be selected from among the unique &apos;Y&apos; labels.
    If it is specified with a different value a warning will be raised and
    all class probabilities of outliers will be assigned to be 0.

metric_params : dict, default=None
    Additional keyword arguments for the metric function.

n_jobs : int, default=None
    The number of parallel jobs to run for neighbors search.
    ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.
    ``-1`` means using all processors. See :term:`Glossary &lt;n_jobs&gt;`
    for more details.

Attributes
----------
classes_ : ndarray of shape (n_classes,)
    Class labels known to the classifier.

effective_metric_ : str or callable
    The distance metric used. It will be same as the `metric` parameter
    or a synonym of it, e.g. &apos;euclidean&apos; if the `metric` parameter set to
    &apos;minkowski&apos; and `p` parameter set to 2.

effective_metric_params_ : dict
    Additional keyword arguments for the metric function. For most metrics
    will be same with `metric_params` parameter, but may also contain the
    `p` parameter value if the `effective_metric_` attribute is set to
    &apos;minkowski&apos;.

n_features_in_ : int
    Number of features seen during :term:`fit`.

    .. versionadded:: 0.24

feature_names_in_ : ndarray of shape (`n_features_in_`,)
    Names of features seen during :term:`fit`. Defined only when `X`
    has feature names that are all strings.

    .. versionadded:: 1.0

n_samples_fit_ : int
    Number of samples in the fitted data.

outlier_label_ : int or array-like of shape (n_class,)
    Label which is given for outlier samples (samples with no neighbors
    on given radius).

outputs_2d_ : bool
    False when `y`&apos;s shape is (n_samples, ) or (n_samples, 1) during fit
    otherwise True.

See Also
--------
KNeighborsClassifier : Classifier implementing the k-nearest neighbors
    vote.
RadiusNeighborsRegressor : Regression based on neighbors within a
    fixed radius.
KNeighborsRegressor : Regression based on k-nearest neighbors.
NearestNeighbors : Unsupervised learner for implementing neighbor
    searches.

Notes
-----
See :ref:`Nearest Neighbors &lt;neighbors&gt;` in the online documentation
for a discussion of the choice of ``algorithm`` and ``leaf_size``.

https://en.wikipedia.org/wiki/K-nearest_neighbor_algorithm

Examples
--------
&gt;&gt;&gt; X = [[0], [1], [2], [3]]
&gt;&gt;&gt; y = [0, 0, 1, 1]
&gt;&gt;&gt; from sklearn.neighbors import RadiusNeighborsClassifier
&gt;&gt;&gt; neigh = RadiusNeighborsClassifier(radius=1.0)
&gt;&gt;&gt; neigh.fit(X, y)
RadiusNeighborsClassifier(...)
&gt;&gt;&gt; print(neigh.predict([[1.5]]))
[0]
&gt;&gt;&gt; print(neigh.predict_proba([[1.0]]))
[[0.66666667 0.33333333]]</rdfs:comment>
    </Class>
    


    <!-- https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RadiusNeighborsRegressorMethod -->


    <Class rdf:about="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RadiusNeighborsRegressorMethod">
        <rdfs:subClassOf rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod"/>
        <rdfs:subClassOf rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#NeighborsModule"/>
        <rdfs:subClassOf rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#TrainMethod"/>
        <rdfs:comment>Regression based on neighbors within a fixed radius.

The target is predicted by local interpolation of the targets
associated of the nearest neighbors in the training set.

Read more in the :ref:`User Guide &lt;regression&gt;`.

.. versionadded:: 0.9

Parameters
----------
radius : float, default=1.0
    Range of parameter space to use by default for :meth:`radius_neighbors`
    queries.

weights : {&apos;uniform&apos;, &apos;distance&apos;}, callable or None, default=&apos;uniform&apos;
    Weight function used in prediction.  Possible values:

    - &apos;uniform&apos; : uniform weights.  All points in each neighborhood
      are weighted equally.
    - &apos;distance&apos; : weight points by the inverse of their distance.
      in this case, closer neighbors of a query point will have a
      greater influence than neighbors which are further away.
    - [callable] : a user-defined function which accepts an
      array of distances, and returns an array of the same shape
      containing the weights.

    Uniform weights are used by default.

algorithm : {&apos;auto&apos;, &apos;ball_tree&apos;, &apos;kd_tree&apos;, &apos;brute&apos;}, default=&apos;auto&apos;
    Algorithm used to compute the nearest neighbors:

    - &apos;ball_tree&apos; will use :class:`BallTree`
    - &apos;kd_tree&apos; will use :class:`KDTree`
    - &apos;brute&apos; will use a brute-force search.
    - &apos;auto&apos; will attempt to decide the most appropriate algorithm
      based on the values passed to :meth:`fit` method.

    Note: fitting on sparse input will override the setting of
    this parameter, using brute force.

leaf_size : int, default=30
    Leaf size passed to BallTree or KDTree.  This can affect the
    speed of the construction and query, as well as the memory
    required to store the tree.  The optimal value depends on the
    nature of the problem.

p : float, default=2
    Power parameter for the Minkowski metric. When p = 1, this is
    equivalent to using manhattan_distance (l1), and euclidean_distance
    (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.

metric : str or callable, default=&apos;minkowski&apos;
    Metric to use for distance computation. Default is &quot;minkowski&quot;, which
    results in the standard Euclidean distance when p = 2. See the
    documentation of `scipy.spatial.distance
    &lt;https://docs.scipy.org/doc/scipy/reference/spatial.distance.html&gt;`_ and
    the metrics listed in
    :class:`~sklearn.metrics.pairwise.distance_metrics` for valid metric
    values.

    If metric is &quot;precomputed&quot;, X is assumed to be a distance matrix and
    must be square during fit. X may be a :term:`sparse graph`, in which
    case only &quot;nonzero&quot; elements may be considered neighbors.

    If metric is a callable function, it takes two arrays representing 1D
    vectors as inputs and must return one value indicating the distance
    between those vectors. This works for Scipy&apos;s metrics, but is less
    efficient than passing the metric name as a string.

metric_params : dict, default=None
    Additional keyword arguments for the metric function.

n_jobs : int, default=None
    The number of parallel jobs to run for neighbors search.
    ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.
    ``-1`` means using all processors. See :term:`Glossary &lt;n_jobs&gt;`
    for more details.

Attributes
----------
effective_metric_ : str or callable
    The distance metric to use. It will be same as the `metric` parameter
    or a synonym of it, e.g. &apos;euclidean&apos; if the `metric` parameter set to
    &apos;minkowski&apos; and `p` parameter set to 2.

effective_metric_params_ : dict
    Additional keyword arguments for the metric function. For most metrics
    will be same with `metric_params` parameter, but may also contain the
    `p` parameter value if the `effective_metric_` attribute is set to
    &apos;minkowski&apos;.

n_features_in_ : int
    Number of features seen during :term:`fit`.

    .. versionadded:: 0.24

feature_names_in_ : ndarray of shape (`n_features_in_`,)
    Names of features seen during :term:`fit`. Defined only when `X`
    has feature names that are all strings.

    .. versionadded:: 1.0

n_samples_fit_ : int
    Number of samples in the fitted data.

See Also
--------
NearestNeighbors : Unsupervised learner for implementing neighbor searches.
KNeighborsRegressor : Regression based on k-nearest neighbors.
KNeighborsClassifier : Classifier based on the k-nearest neighbors.
RadiusNeighborsClassifier : Classifier based on neighbors within a given radius.

Notes
-----
See :ref:`Nearest Neighbors &lt;neighbors&gt;` in the online documentation
for a discussion of the choice of ``algorithm`` and ``leaf_size``.

https://en.wikipedia.org/wiki/K-nearest_neighbor_algorithm

Examples
--------
&gt;&gt;&gt; X = [[0], [1], [2], [3]]
&gt;&gt;&gt; y = [0, 0, 1, 1]
&gt;&gt;&gt; from sklearn.neighbors import RadiusNeighborsRegressor
&gt;&gt;&gt; neigh = RadiusNeighborsRegressor(radius=1.0)
&gt;&gt;&gt; neigh.fit(X, y)
RadiusNeighborsRegressor(...)
&gt;&gt;&gt; print(neigh.predict([[1.5]]))
[0.5]</rdfs:comment>
    </Class>
    


    <!-- https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RadiusNeighborsTransformerMethod -->


    <Class rdf:about="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#RadiusNeighborsTransformerMethod">
        <rdfs:subClassOf rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#AtomicMethod"/>
        <rdfs:subClassOf rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#NeighborsModule"/>
        <rdfs:subClassOf rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#TrainMethod"/>
        <rdfs:comment>Transform X into a (weighted) graph of neighbors nearer than a radius.

The transformed data is a sparse graph as returned by
`radius_neighbors_graph`.

Read more in the :ref:`User Guide &lt;neighbors_transformer&gt;`.

.. versionadded:: 0.22

Parameters
----------
mode : {&apos;distance&apos;, &apos;connectivity&apos;}, default=&apos;distance&apos;
    Type of returned matrix: &apos;connectivity&apos; will return the connectivity
    matrix with ones and zeros, and &apos;distance&apos; will return the distances
    between neighbors according to the given metric.

radius : float, default=1.0
    Radius of neighborhood in the transformed sparse graph.

algorithm : {&apos;auto&apos;, &apos;ball_tree&apos;, &apos;kd_tree&apos;, &apos;brute&apos;}, default=&apos;auto&apos;
    Algorithm used to compute the nearest neighbors:

    - &apos;ball_tree&apos; will use :class:`BallTree`
    - &apos;kd_tree&apos; will use :class:`KDTree`
    - &apos;brute&apos; will use a brute-force search.
    - &apos;auto&apos; will attempt to decide the most appropriate algorithm
      based on the values passed to :meth:`fit` method.

    Note: fitting on sparse input will override the setting of
    this parameter, using brute force.

leaf_size : int, default=30
    Leaf size passed to BallTree or KDTree.  This can affect the
    speed of the construction and query, as well as the memory
    required to store the tree.  The optimal value depends on the
    nature of the problem.

metric : str or callable, default=&apos;minkowski&apos;
    Metric to use for distance computation. Default is &quot;minkowski&quot;, which
    results in the standard Euclidean distance when p = 2. See the
    documentation of `scipy.spatial.distance
    &lt;https://docs.scipy.org/doc/scipy/reference/spatial.distance.html&gt;`_ and
    the metrics listed in
    :class:`~sklearn.metrics.pairwise.distance_metrics` for valid metric
    values.

    If metric is a callable function, it takes two arrays representing 1D
    vectors as inputs and must return one value indicating the distance
    between those vectors. This works for Scipy&apos;s metrics, but is less
    efficient than passing the metric name as a string.

    Distance matrices are not supported.

p : float, default=2
    Parameter for the Minkowski metric from
    sklearn.metrics.pairwise.pairwise_distances. When p = 1, this is
    equivalent to using manhattan_distance (l1), and euclidean_distance
    (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.
    This parameter is expected to be positive.

metric_params : dict, default=None
    Additional keyword arguments for the metric function.

n_jobs : int, default=None
    The number of parallel jobs to run for neighbors search.
    If ``-1``, then the number of jobs is set to the number of CPU cores.

Attributes
----------
effective_metric_ : str or callable
    The distance metric used. It will be same as the `metric` parameter
    or a synonym of it, e.g. &apos;euclidean&apos; if the `metric` parameter set to
    &apos;minkowski&apos; and `p` parameter set to 2.

effective_metric_params_ : dict
    Additional keyword arguments for the metric function. For most metrics
    will be same with `metric_params` parameter, but may also contain the
    `p` parameter value if the `effective_metric_` attribute is set to
    &apos;minkowski&apos;.

n_features_in_ : int
    Number of features seen during :term:`fit`.

    .. versionadded:: 0.24

feature_names_in_ : ndarray of shape (`n_features_in_`,)
    Names of features seen during :term:`fit`. Defined only when `X`
    has feature names that are all strings.

    .. versionadded:: 1.0

n_samples_fit_ : int
    Number of samples in the fitted data.

See Also
--------
kneighbors_graph : Compute the weighted graph of k-neighbors for
    points in X.
KNeighborsTransformer : Transform X into a weighted graph of k
    nearest neighbors.

Examples
--------
&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; from sklearn.datasets import load_wine
&gt;&gt;&gt; from sklearn.cluster import DBSCAN
&gt;&gt;&gt; from sklearn.neighbors import RadiusNeighborsTransformer
&gt;&gt;&gt; from sklearn.pipeline import make_pipeline
&gt;&gt;&gt; X, _ = load_wine(return_X_y=True)
&gt;&gt;&gt; estimator = make_pipeline(
...     RadiusNeighborsTransformer(radius=42.0, mode=&apos;distance&apos;),
...     DBSCAN(eps=25.0, metric=&apos;precomputed&apos;))
&gt;&gt;&gt; X_clustered = estimator.fit_predict(X)
&gt;&gt;&gt; clusters, counts = np.unique(X_clustered, return_counts=True)
&gt;&gt;&gt; print(counts)
[ 29  15 111  11  12]</rdfs:comment>
    </Class>
    


    <!-- https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#SklearnModule -->


    <Class rdf:about="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#SklearnModule">
        <rdfs:subClassOf rdf:resource="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ds_exeKGOntology.ttl#Module"/>
    </Class>
    


    <!-- https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#TrainMethod -->


    <Class rdf:about="https://raw.githubusercontent.com/nsai-uio/ExeKGOntology/main/ml_exeKGOntology.ttl#TrainMethod"/>
</rdf:RDF>



<!-- Generated by the OWL API (version 5.1.18) https://github.com/owlcs/owlapi/ -->


